{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Machine Translation\n",
    "\n",
    "Welcome to your first programming assignment for this week! \n",
    "\n",
    "You will build a Neural Machine Translation (NMT) model to translate human readable dates (\"25th of June, 2009\") into machine readable dates (\"2009-06-25\"). You will do this using an attention model, one of the most sophisticated sequence to sequence models. \n",
    "\n",
    "This notebook was produced together with NVIDIA's Deep Learning Institute. \n",
    "\n",
    "Let's load all the packages you will need for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\iamfish\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:72: UserWarning: h5py is running against HDF5 1.10.2 when it was built against 1.10.3, this may cause problems\n",
      "  '{0}.{1}.{2}'.format(*version.hdf5_built_version_tuple)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, Multiply\n",
    "from keras.layers import RepeatVector, Dense, Activation, Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model, Model\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "\n",
    "from faker import Faker\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from babel.dates import format_date\n",
    "from nmt_utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Translating human readable dates into machine readable dates\n",
    "\n",
    "The model you will build here could be used to translate from one language to another, such as translating from English to Hindi. However, language translation requires massive datasets and usually takes days of training on GPUs. To give you a place to experiment with these models even without using massive datasets, we will instead use a simpler \"date translation\" task. \n",
    "\n",
    "The network will input a date written in a variety of possible formats (*e.g. \"the 29th of August 1958\", \"03/30/1968\", \"24 JUNE 1987\"*) and translate them into standardized, machine readable dates (*e.g. \"1958-08-29\", \"1968-03-30\", \"1987-06-24\"*). We will have the network learn to output dates in the common machine-readable format YYYY-MM-DD. \n",
    "\n",
    "\n",
    "\n",
    "<!-- \n",
    "Take a look at [nmt_utils.py](./nmt_utils.py) to see all the formatting. Count and figure out how the formats work, you will need this knowledge later. !--> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 - Dataset\n",
    "\n",
    "We will train the model on a dataset of 10000 human readable dates and their equivalent, standardized, machine readable dates. Let's run the following cells to load the dataset and print some examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 10000/10000 [00:00<00:00, 31331.15it/s]\n"
     ]
    }
   ],
   "source": [
    "m = 10000\n",
    "dataset, human_vocab, machine_vocab, inv_machine_vocab = load_dataset(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('9 may 1998', '1998-05-09'),\n",
       " ('10.09.70', '1970-09-10'),\n",
       " ('4/28/90', '1990-04-28'),\n",
       " ('thursday january 26 1995', '1995-01-26'),\n",
       " ('monday march 7 1983', '1983-03-07'),\n",
       " ('sunday may 22 1988', '1988-05-22'),\n",
       " ('tuesday july 8 2008', '2008-07-08'),\n",
       " ('08 sep 1999', '1999-09-08'),\n",
       " ('1 jan 1981', '1981-01-01'),\n",
       " ('monday may 22 1995', '1995-05-22')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 0,\n",
       " '.': 1,\n",
       " '/': 2,\n",
       " '0': 3,\n",
       " '1': 4,\n",
       " '2': 5,\n",
       " '3': 6,\n",
       " '4': 7,\n",
       " '5': 8,\n",
       " '6': 9,\n",
       " '7': 10,\n",
       " '8': 11,\n",
       " '9': 12,\n",
       " 'a': 13,\n",
       " 'b': 14,\n",
       " 'c': 15,\n",
       " 'd': 16,\n",
       " 'e': 17,\n",
       " 'f': 18,\n",
       " 'g': 19,\n",
       " 'h': 20,\n",
       " 'i': 21,\n",
       " 'j': 22,\n",
       " 'l': 23,\n",
       " 'm': 24,\n",
       " 'n': 25,\n",
       " 'o': 26,\n",
       " 'p': 27,\n",
       " 'r': 28,\n",
       " 's': 29,\n",
       " 't': 30,\n",
       " 'u': 31,\n",
       " 'v': 32,\n",
       " 'w': 33,\n",
       " 'y': 34,\n",
       " '<unk>': 35,\n",
       " '<pad>': 36}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'-': 0,\n",
       " '0': 1,\n",
       " '1': 2,\n",
       " '2': 3,\n",
       " '3': 4,\n",
       " '4': 5,\n",
       " '5': 6,\n",
       " '6': 7,\n",
       " '7': 8,\n",
       " '8': 9,\n",
       " '9': 10}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "machine_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '-',\n",
       " 1: '0',\n",
       " 2: '1',\n",
       " 3: '2',\n",
       " 4: '3',\n",
       " 5: '4',\n",
       " 6: '5',\n",
       " 7: '6',\n",
       " 8: '7',\n",
       " 9: '8',\n",
       " 10: '9'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_machine_vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've loaded:\n",
    "- `dataset`: a list of tuples of (human readable date, machine readable date)\n",
    "- `human_vocab`: a python dictionary mapping all characters used in the human readable dates to an integer-valued index \n",
    "- `machine_vocab`: a python dictionary mapping all characters used in machine readable dates to an integer-valued index. These indices are not necessarily consistent with `human_vocab`. \n",
    "- `inv_machine_vocab`: the inverse dictionary of `machine_vocab`, mapping from indices back to characters. \n",
    "\n",
    "Let's preprocess the data and map the raw text data into the index values. We will also use Tx=30 (which we assume is the maximum length of the human readable date; if we get a longer input, we would have to truncate it) and Ty=10 (since \"YYYY-MM-DD\" is 10 characters long). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (10000, 30)\n",
      "Y.shape: (10000, 10)\n",
      "Xoh.shape: (10000, 30, 37)\n",
      "Yoh.shape: (10000, 10, 11)\n"
     ]
    }
   ],
   "source": [
    "Tx = 30\n",
    "Ty = 10\n",
    "X, Y, Xoh, Yoh = preprocess_data(dataset, human_vocab, machine_vocab, Tx, Ty)\n",
    "\n",
    "print(\"X.shape:\", X.shape)\n",
    "print(\"Y.shape:\", Y.shape)\n",
    "print(\"Xoh.shape:\", Xoh.shape)\n",
    "print(\"Yoh.shape:\", Yoh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('9 may 1998', '1998-05-09')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12,  0, 24, 13, 34,  0,  4, 12, 12, 11, 36, 36, 36, 36, 36, 36, 36,\n",
       "       36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2, 10, 10,  9,  0,  1,  6,  0,  1, 10])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'-': 0,\n",
       " '0': 1,\n",
       " '1': 2,\n",
       " '2': 3,\n",
       " '3': 4,\n",
       " '4': 5,\n",
       " '5': 6,\n",
       " '6': 7,\n",
       " '7': 8,\n",
       " '8': 9,\n",
       " '9': 10}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "machine_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xoh[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yoh[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now have:\n",
    "- `X`: a processed version of the human readable dates in the training set, where each character is replaced by an index mapped to the character via `human_vocab`. Each date is further padded to $T_x$ values with a special character (< pad >). `X.shape = (m, Tx)`\n",
    "- `Y`: a processed version of the machine readable dates in the training set, where each character is replaced by the index it is mapped to in `machine_vocab`. You should have `Y.shape = (m, Ty)`. \n",
    "- `Xoh`: one-hot version of `X`, the \"1\" entry's index is mapped to the character thanks to `human_vocab`. `Xoh.shape = (m, Tx, len(human_vocab))`\n",
    "- `Yoh`: one-hot version of `Y`, the \"1\" entry's index is mapped to the character thanks to `machine_vocab`. `Yoh.shape = (m, Tx, len(machine_vocab))`. Here, `len(machine_vocab) = 11` since there are 11 characters ('-' as well as 0-9). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets also look at some examples of preprocessed training examples. Feel free to play with `index` in the cell below to navigate the dataset and see how source/target dates are preprocessed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source date: 9 may 1998\n",
      "Target date: 1998-05-09\n",
      "\n",
      "Source after preprocessing (indices): [12  0 24 13 34  0  4 12 12 11 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "Target after preprocessing (indices): [ 2 10 10  9  0  1  6  0  1 10]\n",
      "\n",
      "Source after preprocessing (one-hot): [[0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n",
      "Target after preprocessing (one-hot): [[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "print(\"Source date:\", dataset[index][0])\n",
    "print(\"Target date:\", dataset[index][1])\n",
    "print()\n",
    "print(\"Source after preprocessing (indices):\", X[index])\n",
    "print(\"Target after preprocessing (indices):\", Y[index])\n",
    "print()\n",
    "print(\"Source after preprocessing (one-hot):\", Xoh[index])\n",
    "print(\"Target after preprocessing (one-hot):\", Yoh[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Neural machine translation with attention\n",
    "\n",
    "If you had to translate a book's paragraph from French to English, you would not read the whole paragraph, then close the book and translate. Even during the translation process, you would read/re-read and focus on the parts of the French paragraph corresponding to the parts of the English you are writing down. \n",
    "\n",
    "The attention mechanism tells a Neural Machine Translation model where it should pay attention to at any step. \n",
    "\n",
    "\n",
    "### 2.1 - Attention mechanism\n",
    "\n",
    "In this part, you will implement the attention mechanism presented in the lecture videos. Here is a figure to remind you how the model works. The diagram on the left shows the attention model. The diagram on the right shows what one \"Attention\" step does to calculate the attention variables $\\alpha^{\\langle t, t' \\rangle}$, which are used to compute the context variable $context^{\\langle t \\rangle}$ for each timestep in the output ($t=1, \\ldots, T_y$). \n",
    "\n",
    "<table>\n",
    "<td> \n",
    "<img src=\"images/attn_model.png\" style=\"width:500;height:500px;\"> <br>\n",
    "</td> \n",
    "<td> \n",
    "<img src=\"images/attn_mechanism.png\" style=\"width:500;height:500px;\"> <br>\n",
    "</td> \n",
    "</table>\n",
    "<caption><center> **Figure 1**: Neural machine translation with attention</center></caption>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Here are some properties of the model that you may notice: \n",
    "\n",
    "- There are two separate LSTMs in this model (see diagram on the left). Because the one at the bottom of the picture is a Bi-directional LSTM and comes *before* the attention mechanism, we will call it *pre-attention* Bi-LSTM. The LSTM at the top of the diagram comes *after* the attention mechanism, so we will call it the *post-attention* LSTM. The pre-attention Bi-LSTM goes through $T_x$ time steps; the post-attention LSTM goes through $T_y$ time steps. \n",
    "\n",
    "- The post-attention LSTM passes $s^{\\langle t \\rangle}, c^{\\langle t \\rangle}$ from one time step to the next. In the lecture videos, we were using only a basic RNN for the post-activation sequence model, so the state captured by the RNN output activations $s^{\\langle t\\rangle}$. But since we are using an LSTM here, the LSTM has both the output activation $s^{\\langle t\\rangle}$ and the hidden cell state $c^{\\langle t\\rangle}$. However, unlike previous text generation examples (such as Dinosaurus in week 1), in this model the post-activation LSTM at time $t$ does will not take the specific generated $y^{\\langle t-1 \\rangle}$ as input; it only takes $s^{\\langle t\\rangle}$ and $c^{\\langle t\\rangle}$ as input. We have designed the model this way, because (unlike language generation where adjacent characters are highly correlated) there isn't as strong a dependency between the previous character and the next character in a YYYY-MM-DD date. \n",
    "\n",
    "- We use $a^{\\langle t \\rangle} = [\\overrightarrow{a}^{\\langle t \\rangle}; \\overleftarrow{a}^{\\langle t \\rangle}]$ to represent the concatenation of the activations of both the forward-direction and backward-directions of the pre-attention Bi-LSTM. \n",
    "\n",
    "- The diagram on the right uses a `RepeatVector` node to copy $s^{\\langle t-1 \\rangle}$'s value $T_x$ times, and then `Concatenation` to concatenate $s^{\\langle t-1 \\rangle}$ and $a^{\\langle t \\rangle}$ to compute $e^{\\langle t, t'}$, which is then passed through a softmax to compute $\\alpha^{\\langle t, t' \\rangle}$. We'll explain how to use `RepeatVector` and `Concatenation` in Keras below. \n",
    "\n",
    "Lets implement this model. You will start by implementing two functions: `one_step_attention()` and `model()`.\n",
    "\n",
    "**1) `one_step_attention()`**: At step $t$, given all the hidden states of the Bi-LSTM ($[a^{<1>},a^{<2>}, ..., a^{<T_x>}]$) and the previous hidden state of the second LSTM ($s^{<t-1>}$), `one_step_attention()` will compute the attention weights ($[\\alpha^{<t,1>},\\alpha^{<t,2>}, ..., \\alpha^{<t,T_x>}]$) and output the context vector (see Figure  1 (right) for details):\n",
    "$$context^{<t>} = \\sum_{t' = 0}^{T_x} \\alpha^{<t,t'>}a^{<t'>}\\tag{1}$$ \n",
    "\n",
    "Note that we are denoting the attention in this notebook $context^{\\langle t \\rangle}$. In the lecture videos, the context was denoted $c^{\\langle t \\rangle}$, but here we are calling it $context^{\\langle t \\rangle}$ to avoid confusion with the (post-attention) LSTM's internal memory cell variable, which is sometimes also denoted $c^{\\langle t \\rangle}$. \n",
    "  \n",
    "**2) `model()`**: Implements the entire model. It first runs the input through a Bi-LSTM to get back $[a^{<1>},a^{<2>}, ..., a^{<T_x>}]$. Then, it calls `one_step_attention()` $T_y$ times (`for` loop). At each iteration of this loop, it gives the computed context vector $c^{<t>}$ to the second LSTM, and runs the output of the LSTM through a dense layer with softmax activation to generate a prediction $\\hat{y}^{<t>}$. \n",
    "\n",
    "\n",
    "\n",
    "**Exercise**: Implement `one_step_attention()`. The function `model()` will call the layers in `one_step_attention()` $T_y$ using a for-loop, and it is important that all $T_y$ copies have the same weights. I.e., it should not re-initiaiize the weights every time. In other words, all $T_y$ steps should have shared weights. Here's how you can implement layers with shareable weights in Keras:\n",
    "1. Define the layer objects (as global variables for examples).\n",
    "2. Call these objects when propagating the input.\n",
    "\n",
    "We have defined the layers you need as global variables. Please run the following cells to create them. Please check the Keras documentation to make sure you understand what these layers are: [RepeatVector()](https://keras.io/layers/core/#repeatvector), [Concatenate()](https://keras.io/layers/merge/#concatenate), [Dense()](https://keras.io/layers/core/#dense), [Activation()](https://keras.io/layers/core/#activation), [Dot()](https://keras.io/layers/merge/#dot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defined shared layers as global variables\n",
    "repeator = RepeatVector(Tx)\n",
    "concatenator = Concatenate(axis=-1)\n",
    "densor1 = Dense(10, activation = \"tanh\")\n",
    "densor2 = Dense(1, activation = \"relu\")\n",
    "activator = Activation(softmax, name='attention_weights') # We are using a custom softmax(axis = 1) loaded in this notebook\n",
    "dotor = Dot(axes = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can use these layers to implement `one_step_attention()`. In order to propagate a Keras tensor object X through one of these layers, use `layer(X)` (or `layer([X,Y])` if it requires multiple inputs.), e.g. `densor(X)` will propagate X through the `Dense(1)` layer defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: one_step_attention\n",
    "\n",
    "def one_step_attention(a, s_prev):\n",
    "    \"\"\"\n",
    "    Performs one step of attention: Outputs a context vector computed as a dot product of the attention weights\n",
    "    \"alphas\" and the hidden states \"a\" of the Bi-LSTM.\n",
    "    \n",
    "    Arguments:\n",
    "    a -- hidden state output of the Bi-LSTM, numpy-array of shape (m, Tx, 2*n_a)\n",
    "    s_prev -- previous hidden state of the (post-attention) LSTM, numpy-array of shape (m, n_s)\n",
    "    \n",
    "    Returns:\n",
    "    context -- context vector, input of the next (post-attetion) LSTM cell\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Use repeator to repeat s_prev to be of shape (m, Tx, n_s) so that you can concatenate it with all hidden states \"a\" (≈ 1 line)\n",
    "    s_prev = repeator(s_prev)\n",
    "    # Use concatenator to concatenate a and s_prev on the last axis (≈ 1 line)\n",
    "    concat = concatenator([a, s_prev])\n",
    "    # Use densor1 to propagate concat through a small fully-connected neural network to compute the \"intermediate energies\" variable e. (≈1 lines)\n",
    "    e = densor1(concat)\n",
    "    # Use densor2 to propagate e through a small fully-connected neural network to compute the \"energies\" variable energies. (≈1 lines)\n",
    "    energies = densor2(e)\n",
    "    # Use \"activator\" on \"energies\" to compute the attention weights \"alphas\" (≈ 1 line)\n",
    "    alphas = activator(energies)\n",
    "    # Use dotor together with \"alphas\" and \"a\" to compute the context vector to be given to the next (post-attention) LSTM-cell (≈ 1 line)\n",
    "    context = dotor([alphas, a])\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will be able to check the expected output of `one_step_attention()` after you've coded the `model()` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Implement `model()` as explained in figure 2 and the text above. Again, we have defined global layers that will share weights to be used in `model()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_a = 32\n",
    "n_s = 64\n",
    "post_activation_LSTM_cell = LSTM(n_s, return_state = True)\n",
    "output_layer = Dense(len(machine_vocab), activation=softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can use these layers $T_y$ times in a `for` loop to generate the outputs, and their parameters will not be reinitialized. You will have to carry out the following steps: \n",
    "\n",
    "1. Propagate the input into a [Bidirectional](https://keras.io/layers/wrappers/#bidirectional) [LSTM](https://keras.io/layers/recurrent/#lstm)\n",
    "2. Iterate for $t = 0, \\dots, T_y-1$: \n",
    "    1. Call `one_step_attention()` on $[\\alpha^{<t,1>},\\alpha^{<t,2>}, ..., \\alpha^{<t,T_x>}]$ and $s^{<t-1>}$ to get the context vector $context^{<t>}$.\n",
    "    2. Give $context^{<t>}$ to the post-attention LSTM cell. Remember pass in the previous hidden-state $s^{\\langle t-1\\rangle}$ and cell-states $c^{\\langle t-1\\rangle}$ of this LSTM using `initial_state= [previous hidden state, previous cell state]`. Get back the new hidden state $s^{<t>}$ and the new cell state $c^{<t>}$.\n",
    "    3. Apply a softmax layer to $s^{<t>}$, get the output. \n",
    "    4. Save the output by adding it to the list of outputs.\n",
    "\n",
    "3. Create your Keras model instance, it should have three inputs (\"inputs\", $s^{<0>}$ and $c^{<0>}$) and output the list of \"outputs\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: model\n",
    "\n",
    "def model(Tx, Ty, n_a, n_s, human_vocab_size, machine_vocab_size):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    Tx -- length of the input sequence\n",
    "    Ty -- length of the output sequence\n",
    "    n_a -- hidden state size of the Bi-LSTM\n",
    "    n_s -- hidden state size of the post-attention LSTM\n",
    "    human_vocab_size -- size of the python dictionary \"human_vocab\"\n",
    "    machine_vocab_size -- size of the python dictionary \"machine_vocab\"\n",
    "\n",
    "    Returns:\n",
    "    model -- Keras model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the inputs of your model with a shape (Tx,)\n",
    "    # Define s0 and c0, initial hidden state for the decoder LSTM of shape (n_s,)\n",
    "    X = Input(shape=(Tx, human_vocab_size))\n",
    "    s0 = Input(shape=(n_s,), name='s0')\n",
    "    c0 = Input(shape=(n_s,), name='c0')\n",
    "    s = s0\n",
    "    c = c0\n",
    "    \n",
    "    # Initialize empty list of outputs\n",
    "    outputs = []\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # Step 1: Define your pre-attention Bi-LSTM. Remember to use return_sequences=True. (≈ 1 line)\n",
    "    a = Bidirectional(LSTM(n_a, return_sequences=True))(X)\n",
    "    \n",
    "    # Step 2: Iterate for Ty steps\n",
    "    for t in range(Ty):\n",
    "    \n",
    "        # Step 2.A: Perform one step of the attention mechanism to get back the context vector at step t (≈ 1 line)\n",
    "        context = one_step_attention(a, s)\n",
    "        \n",
    "        # Step 2.B: Apply the post-attention LSTM cell to the \"context\" vector.\n",
    "        # Don't forget to pass: initial_state = [hidden state, cell state] (≈ 1 line)\n",
    "        s, _, c = post_activation_LSTM_cell(context, initial_state = [s, c])\n",
    "        \n",
    "        # Step 2.C: Apply Dense layer to the hidden state output of the post-attention LSTM (≈ 1 line)\n",
    "        out = output_layer(s)\n",
    "        \n",
    "        # Step 2.D: Append \"out\" to the \"outputs\" list (≈ 1 line)\n",
    "        outputs.append(out)\n",
    "    \n",
    "    # Step 3: Create model instance taking three inputs and returning the list of outputs. (≈ 1 line)\n",
    "    model = Model(inputs=[X, s0, c0], outputs=outputs)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to create your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Users\\iamfish\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = model(Tx, Ty, n_a, n_s, len(human_vocab), len(machine_vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a summary of the model to check if it matches the expected output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 30, 37)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "s0 (InputLayer)                 (None, 64)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 30, 64)       17920       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_1 (RepeatVector)  (None, 30, 64)       0           s0[0][0]                         \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 lstm_1[1][0]                     \n",
      "                                                                 lstm_1[2][0]                     \n",
      "                                                                 lstm_1[3][0]                     \n",
      "                                                                 lstm_1[4][0]                     \n",
      "                                                                 lstm_1[5][0]                     \n",
      "                                                                 lstm_1[6][0]                     \n",
      "                                                                 lstm_1[7][0]                     \n",
      "                                                                 lstm_1[8][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 30, 128)      0           bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[0][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[1][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[2][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[3][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[4][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[5][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[6][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[7][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[8][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[9][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 30, 10)       1290        concatenate_1[0][0]              \n",
      "                                                                 concatenate_1[1][0]              \n",
      "                                                                 concatenate_1[2][0]              \n",
      "                                                                 concatenate_1[3][0]              \n",
      "                                                                 concatenate_1[4][0]              \n",
      "                                                                 concatenate_1[5][0]              \n",
      "                                                                 concatenate_1[6][0]              \n",
      "                                                                 concatenate_1[7][0]              \n",
      "                                                                 concatenate_1[8][0]              \n",
      "                                                                 concatenate_1[9][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 30, 1)        11          dense_1[0][0]                    \n",
      "                                                                 dense_1[1][0]                    \n",
      "                                                                 dense_1[2][0]                    \n",
      "                                                                 dense_1[3][0]                    \n",
      "                                                                 dense_1[4][0]                    \n",
      "                                                                 dense_1[5][0]                    \n",
      "                                                                 dense_1[6][0]                    \n",
      "                                                                 dense_1[7][0]                    \n",
      "                                                                 dense_1[8][0]                    \n",
      "                                                                 dense_1[9][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_weights (Activation)  (None, 30, 1)        0           dense_2[0][0]                    \n",
      "                                                                 dense_2[1][0]                    \n",
      "                                                                 dense_2[2][0]                    \n",
      "                                                                 dense_2[3][0]                    \n",
      "                                                                 dense_2[4][0]                    \n",
      "                                                                 dense_2[5][0]                    \n",
      "                                                                 dense_2[6][0]                    \n",
      "                                                                 dense_2[7][0]                    \n",
      "                                                                 dense_2[8][0]                    \n",
      "                                                                 dense_2[9][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 1, 64)        0           attention_weights[0][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[1][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[2][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[3][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 attention_weights[4][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[5][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[6][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[7][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[8][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[9][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "c0 (InputLayer)                 (None, 64)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 64), (None,  33024       dot_1[0][0]                      \n",
      "                                                                 s0[0][0]                         \n",
      "                                                                 c0[0][0]                         \n",
      "                                                                 dot_1[1][0]                      \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "                                                                 dot_1[2][0]                      \n",
      "                                                                 lstm_1[1][0]                     \n",
      "                                                                 lstm_1[1][2]                     \n",
      "                                                                 dot_1[3][0]                      \n",
      "                                                                 lstm_1[2][0]                     \n",
      "                                                                 lstm_1[2][2]                     \n",
      "                                                                 dot_1[4][0]                      \n",
      "                                                                 lstm_1[3][0]                     \n",
      "                                                                 lstm_1[3][2]                     \n",
      "                                                                 dot_1[5][0]                      \n",
      "                                                                 lstm_1[4][0]                     \n",
      "                                                                 lstm_1[4][2]                     \n",
      "                                                                 dot_1[6][0]                      \n",
      "                                                                 lstm_1[5][0]                     \n",
      "                                                                 lstm_1[5][2]                     \n",
      "                                                                 dot_1[7][0]                      \n",
      "                                                                 lstm_1[6][0]                     \n",
      "                                                                 lstm_1[6][2]                     \n",
      "                                                                 dot_1[8][0]                      \n",
      "                                                                 lstm_1[7][0]                     \n",
      "                                                                 lstm_1[7][2]                     \n",
      "                                                                 dot_1[9][0]                      \n",
      "                                                                 lstm_1[8][0]                     \n",
      "                                                                 lstm_1[8][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 11)           715         lstm_1[0][0]                     \n",
      "                                                                 lstm_1[1][0]                     \n",
      "                                                                 lstm_1[2][0]                     \n",
      "                                                                 lstm_1[3][0]                     \n",
      "                                                                 lstm_1[4][0]                     \n",
      "                                                                 lstm_1[5][0]                     \n",
      "                                                                 lstm_1[6][0]                     \n",
      "                                                                 lstm_1[7][0]                     \n",
      "                                                                 lstm_1[8][0]                     \n",
      "                                                                 lstm_1[9][0]                     \n",
      "==================================================================================================\n",
      "Total params: 52,960\n",
      "Trainable params: 52,960\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "Here is the summary you should see\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **Total params:**\n",
    "        </td>\n",
    "        <td>\n",
    "         52,960\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **Trainable params:**\n",
    "        </td>\n",
    "        <td>\n",
    "         52,960\n",
    "        </td>\n",
    "    </tr>\n",
    "            <tr>\n",
    "        <td>\n",
    "            **Non-trainable params:**\n",
    "        </td>\n",
    "        <td>\n",
    "         0\n",
    "        </td>\n",
    "    </tr>\n",
    "                    <tr>\n",
    "        <td>\n",
    "            **bidirectional_1's output shape **\n",
    "        </td>\n",
    "        <td>\n",
    "         (None, 30, 64)  \n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **repeat_vector_1's output shape **\n",
    "        </td>\n",
    "        <td>\n",
    "         (None, 30, 64) \n",
    "        </td>\n",
    "    </tr>\n",
    "                <tr>\n",
    "        <td>\n",
    "            **concatenate_1's output shape **\n",
    "        </td>\n",
    "        <td>\n",
    "         (None, 30, 128) \n",
    "        </td>\n",
    "    </tr>\n",
    "            <tr>\n",
    "        <td>\n",
    "            **attention_weights's output shape **\n",
    "        </td>\n",
    "        <td>\n",
    "         (None, 30, 1)  \n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **dot_1's output shape **\n",
    "        </td>\n",
    "        <td>\n",
    "         (None, 1, 64)\n",
    "        </td>\n",
    "    </tr>\n",
    "           <tr>\n",
    "        <td>\n",
    "            **dense_3's output shape **\n",
    "        </td>\n",
    "        <td>\n",
    "         (None, 11) \n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, after creating your model in Keras, you need to compile it and define what loss, optimizer and metrics your are want to use. Compile your model using `categorical_crossentropy` loss, a custom [Adam](https://keras.io/optimizers/#adam) [optimizer](https://keras.io/optimizers/#usage-of-optimizers) (`learning rate = 0.005`, $\\beta_1 = 0.9$, $\\beta_2 = 0.999$, `decay = 0.01`)  and `['accuracy']` metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ### (≈2 lines)\n",
    "opt = Adam(lr=0.005, beta_1=0.9, beta_2=0.999, decay=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step is to define all your inputs and outputs to fit the model:\n",
    "- You already have X of shape $(m = 10000, T_x = 30)$ containing the training examples.\n",
    "- You need to create `s0` and `c0` to initialize your `post_activation_LSTM_cell` with 0s.\n",
    "- Given the `model()` you coded, you need the \"outputs\" to be a list of 11 elements of shape (m, T_y). So that: `outputs[i][0], ..., outputs[i][Ty]` represent the true labels (characters) corresponding to the $i^{th}$ training example (`X[i]`). More generally, `outputs[i][j]` is the true label of the $j^{th}$ character in the $i^{th}$ training example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0 = np.zeros((m, n_s))\n",
    "c0 = np.zeros((m, n_s))\n",
    "outputs = list(Yoh.swapaxes(0,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now fit the model and run it for one epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "session_config = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))\n",
    "sess = tf.Session(config=session_config)\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Users\\iamfish\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From D:\\Users\\iamfish\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2900/10000 [=======>......................] - ETA: 13:07 - loss: 23.9724 - dense_3_loss: 2.3980 - dense_3_acc: 0.0500 - dense_3_acc_1: 0.1200 - dense_3_acc_2: 0.1200 - dense_3_acc_3: 0.1000 - dense_3_acc_4: 0.0000e+00 - dense_3_acc_5: 0.6300 - dense_3_acc_6: 0.1300 - dense_3_acc_7: 0.0000e+00 - dense_3_acc_8: 0.3100 - dense_3_acc_9: 0.07 - ETA: 6:35 - loss: 23.7667 - dense_3_loss: 2.4039 - dense_3_acc: 0.0350 - dense_3_acc_1: 0.2350 - dense_3_acc_2: 0.1500 - dense_3_acc_3: 0.0800 - dense_3_acc_4: 0.0000e+00 - dense_3_acc_5: 0.7250 - dense_3_acc_6: 0.0850 - dense_3_acc_7: 0.0000e+00 - dense_3_acc_8: 0.2900 - dense_3_acc_9: 0.0850 - ETA: 4:25 - loss: 23.5312 - dense_3_loss: 2.4083 - dense_3_acc: 0.0367 - dense_3_acc_1: 0.2767 - dense_3_acc_2: 0.1733 - dense_3_acc_3: 0.1000 - dense_3_acc_4: 0.0000e+00 - dense_3_acc_5: 0.7100 - dense_3_acc_6: 0.0967 - dense_3_acc_7: 0.0000e+00 - dense_3_acc_8: 0.2767 - dense_3_acc_9: 0.093 - ETA: 3:20 - loss: 23.2664 - dense_3_loss: 2.4406 - dense_3_acc: 0.0450 - dense_3_acc_1: 0.3125 - dense_3_acc_2: 0.1975 - dense_3_acc_3: 0.1025 - dense_3_acc_4: 0.0000e+00 - dense_3_acc_5: 0.7250 - dense_3_acc_6: 0.0900 - dense_3_acc_7: 0.0000e+00 - dense_3_acc_8: 0.2800 - dense_3_acc_9: 0.097 - ETA: 2:40 - loss: 23.0063 - dense_3_loss: 2.5061 - dense_3_acc: 0.0360 - dense_3_acc_1: 0.3260 - dense_3_acc_2: 0.1960 - dense_3_acc_3: 0.1100 - dense_3_acc_4: 0.0000e+00 - dense_3_acc_5: 0.7200 - dense_3_acc_6: 0.0940 - dense_3_acc_7: 0.0000e+00 - dense_3_acc_8: 0.2860 - dense_3_acc_9: 0.100 - ETA: 2:14 - loss: 22.8554 - dense_3_loss: 2.6478 - dense_3_acc: 0.0300 - dense_3_acc_1: 0.3167 - dense_3_acc_2: 0.1867 - dense_3_acc_3: 0.0917 - dense_3_acc_4: 0.1667 - dense_3_acc_5: 0.6000 - dense_3_acc_6: 0.0783 - dense_3_acc_7: 0.1667 - dense_3_acc_8: 0.2383 - dense_3_acc_9: 0.0833        - ETA: 1:55 - loss: 22.7007 - dense_3_loss: 2.7448 - dense_3_acc: 0.0257 - dense_3_acc_1: 0.2714 - dense_3_acc_2: 0.1600 - dense_3_acc_3: 0.0786 - dense_3_acc_4: 0.2857 - dense_3_acc_5: 0.5143 - dense_3_acc_6: 0.0671 - dense_3_acc_7: 0.2857 - dense_3_acc_8: 0.2043 - dense_3_acc_9: 0.071 - ETA: 1:41 - loss: 22.6012 - dense_3_loss: 2.8075 - dense_3_acc: 0.0225 - dense_3_acc_1: 0.2375 - dense_3_acc_2: 0.1400 - dense_3_acc_3: 0.0688 - dense_3_acc_4: 0.3750 - dense_3_acc_5: 0.4500 - dense_3_acc_6: 0.0587 - dense_3_acc_7: 0.3750 - dense_3_acc_8: 0.1788 - dense_3_acc_9: 0.062 - ETA: 1:30 - loss: 22.4619 - dense_3_loss: 2.8324 - dense_3_acc: 0.0200 - dense_3_acc_1: 0.2533 - dense_3_acc_2: 0.1244 - dense_3_acc_3: 0.0611 - dense_3_acc_4: 0.4444 - dense_3_acc_5: 0.4000 - dense_3_acc_6: 0.0522 - dense_3_acc_7: 0.4444 - dense_3_acc_8: 0.1589 - dense_3_acc_9: 0.055 - ETA: 1:21 - loss: 22.3445 - dense_3_loss: 2.8464 - dense_3_acc: 0.0180 - dense_3_acc_1: 0.2650 - dense_3_acc_2: 0.1300 - dense_3_acc_3: 0.0570 - dense_3_acc_4: 0.5000 - dense_3_acc_5: 0.3600 - dense_3_acc_6: 0.0470 - dense_3_acc_7: 0.5000 - dense_3_acc_8: 0.1430 - dense_3_acc_9: 0.050 - ETA: 1:14 - loss: 22.2652 - dense_3_loss: 2.8394 - dense_3_acc: 0.0164 - dense_3_acc_1: 0.2736 - dense_3_acc_2: 0.1318 - dense_3_acc_3: 0.0582 - dense_3_acc_4: 0.4809 - dense_3_acc_5: 0.3282 - dense_3_acc_6: 0.0427 - dense_3_acc_7: 0.5455 - dense_3_acc_8: 0.1300 - dense_3_acc_9: 0.045 - ETA: 1:08 - loss: 22.2019 - dense_3_loss: 2.8391 - dense_3_acc: 0.0150 - dense_3_acc_1: 0.2808 - dense_3_acc_2: 0.1367 - dense_3_acc_3: 0.0642 - dense_3_acc_4: 0.4467 - dense_3_acc_5: 0.3233 - dense_3_acc_6: 0.0392 - dense_3_acc_7: 0.5833 - dense_3_acc_8: 0.1192 - dense_3_acc_9: 0.041 - ETA: 1:03 - loss: 22.1268 - dense_3_loss: 2.8254 - dense_3_acc: 0.0138 - dense_3_acc_1: 0.2846 - dense_3_acc_2: 0.1408 - dense_3_acc_3: 0.0654 - dense_3_acc_4: 0.4238 - dense_3_acc_5: 0.3077 - dense_3_acc_6: 0.0362 - dense_3_acc_7: 0.6154 - dense_3_acc_8: 0.1100 - dense_3_acc_9: 0.038 - ETA: 58s - loss: 22.0555 - dense_3_loss: 2.8129 - dense_3_acc: 0.0129 - dense_3_acc_1: 0.2943 - dense_3_acc_2: 0.1450 - dense_3_acc_3: 0.0657 - dense_3_acc_4: 0.4550 - dense_3_acc_5: 0.2857 - dense_3_acc_6: 0.0336 - dense_3_acc_7: 0.6429 - dense_3_acc_8: 0.1021 - dense_3_acc_9: 0.035 - ETA: 55s - loss: 21.9916 - dense_3_loss: 2.8077 - dense_3_acc: 0.0120 - dense_3_acc_1: 0.2967 - dense_3_acc_2: 0.1487 - dense_3_acc_3: 0.0693 - dense_3_acc_4: 0.4913 - dense_3_acc_5: 0.2667 - dense_3_acc_6: 0.0313 - dense_3_acc_7: 0.6667 - dense_3_acc_8: 0.0953 - dense_3_acc_9: 0.03 - ETA: 51s - loss: 21.9307 - dense_3_loss: 2.8090 - dense_3_acc: 0.0112 - dense_3_acc_1: 0.3019 - dense_3_acc_2: 0.1494 - dense_3_acc_3: 0.0675 - dense_3_acc_4: 0.5231 - dense_3_acc_5: 0.2500 - dense_3_acc_6: 0.0294 - dense_3_acc_7: 0.6875 - dense_3_acc_8: 0.0894 - dense_3_acc_9: 0.03 - ETA: 48s - loss: 21.8621 - dense_3_loss: 2.8087 - dense_3_acc: 0.0106 - dense_3_acc_1: 0.3141 - dense_3_acc_2: 0.1553 - dense_3_acc_3: 0.0671 - dense_3_acc_4: 0.5512 - dense_3_acc_5: 0.2353 - dense_3_acc_6: 0.0276 - dense_3_acc_7: 0.7059 - dense_3_acc_8: 0.0841 - dense_3_acc_9: 0.02 - ETA: 46s - loss: 21.8035 - dense_3_loss: 2.8144 - dense_3_acc: 0.0100 - dense_3_acc_1: 0.3200 - dense_3_acc_2: 0.1594 - dense_3_acc_3: 0.0683 - dense_3_acc_4: 0.5761 - dense_3_acc_5: 0.2222 - dense_3_acc_6: 0.0261 - dense_3_acc_7: 0.7222 - dense_3_acc_8: 0.0794 - dense_3_acc_9: 0.02 - ETA: 43s - loss: 21.7393 - dense_3_loss: 2.8164 - dense_3_acc: 0.0095 - dense_3_acc_1: 0.3168 - dense_3_acc_2: 0.1568 - dense_3_acc_3: 0.0726 - dense_3_acc_4: 0.5511 - dense_3_acc_5: 0.2105 - dense_3_acc_6: 0.0247 - dense_3_acc_7: 0.7368 - dense_3_acc_8: 0.0753 - dense_3_acc_9: 0.02 - ETA: 41s - loss: 21.6780 - dense_3_loss: 2.8131 - dense_3_acc: 0.0090 - dense_3_acc_1: 0.3190 - dense_3_acc_2: 0.1575 - dense_3_acc_3: 0.0755 - dense_3_acc_4: 0.5305 - dense_3_acc_5: 0.2000 - dense_3_acc_6: 0.0235 - dense_3_acc_7: 0.7500 - dense_3_acc_8: 0.0715 - dense_3_acc_9: 0.02 - ETA: 39s - loss: 21.6175 - dense_3_loss: 2.8164 - dense_3_acc: 0.0086 - dense_3_acc_1: 0.3200 - dense_3_acc_2: 0.1600 - dense_3_acc_3: 0.0786 - dense_3_acc_4: 0.5410 - dense_3_acc_5: 0.1905 - dense_3_acc_6: 0.0224 - dense_3_acc_7: 0.7619 - dense_3_acc_8: 0.0681 - dense_3_acc_9: 0.02 - ETA: 37s - loss: 21.5630 - dense_3_loss: 2.8189 - dense_3_acc: 0.0082 - dense_3_acc_1: 0.3241 - dense_3_acc_2: 0.1627 - dense_3_acc_3: 0.0791 - dense_3_acc_4: 0.5618 - dense_3_acc_5: 0.1818 - dense_3_acc_6: 0.0214 - dense_3_acc_7: 0.7727 - dense_3_acc_8: 0.0650 - dense_3_acc_9: 0.02 - ETA: 35s - loss: 21.5002 - dense_3_loss: 2.8226 - dense_3_acc: 0.0078 - dense_3_acc_1: 0.3326 - dense_3_acc_2: 0.1652 - dense_3_acc_3: 0.0774 - dense_3_acc_4: 0.5809 - dense_3_acc_5: 0.1739 - dense_3_acc_6: 0.0204 - dense_3_acc_7: 0.7826 - dense_3_acc_8: 0.0622 - dense_3_acc_9: 0.02 - ETA: 34s - loss: 21.4405 - dense_3_loss: 2.8221 - dense_3_acc: 0.0075 - dense_3_acc_1: 0.3438 - dense_3_acc_2: 0.1667 - dense_3_acc_3: 0.0783 - dense_3_acc_4: 0.5983 - dense_3_acc_5: 0.1667 - dense_3_acc_6: 0.0196 - dense_3_acc_7: 0.7917 - dense_3_acc_8: 0.0596 - dense_3_acc_9: 0.02 - ETA: 32s - loss: 21.3894 - dense_3_loss: 2.8198 - dense_3_acc: 0.0072 - dense_3_acc_1: 0.3544 - dense_3_acc_2: 0.1688 - dense_3_acc_3: 0.0772 - dense_3_acc_4: 0.6144 - dense_3_acc_5: 0.1600 - dense_3_acc_6: 0.0188 - dense_3_acc_7: 0.8000 - dense_3_acc_8: 0.0572 - dense_3_acc_9: 0.02 - ETA: 31s - loss: 21.3289 - dense_3_loss: 2.8130 - dense_3_acc: 0.0069 - dense_3_acc_1: 0.3654 - dense_3_acc_2: 0.1738 - dense_3_acc_3: 0.0754 - dense_3_acc_4: 0.6292 - dense_3_acc_5: 0.1538 - dense_3_acc_6: 0.0181 - dense_3_acc_7: 0.8077 - dense_3_acc_8: 0.0550 - dense_3_acc_9: 0.02 - ETA: 30s - loss: 21.2796 - dense_3_loss: 2.8094 - dense_3_acc: 0.0067 - dense_3_acc_1: 0.3737 - dense_3_acc_2: 0.1741 - dense_3_acc_3: 0.0730 - dense_3_acc_4: 0.6430 - dense_3_acc_5: 0.1481 - dense_3_acc_6: 0.0174 - dense_3_acc_7: 0.8148 - dense_3_acc_8: 0.0567 - dense_3_acc_9: 0.02 - ETA: 29s - loss: 21.2241 - dense_3_loss: 2.8062 - dense_3_acc: 0.0064 - dense_3_acc_1: 0.3818 - dense_3_acc_2: 0.1757 - dense_3_acc_3: 0.0704 - dense_3_acc_4: 0.6557 - dense_3_acc_5: 0.1429 - dense_3_acc_6: 0.0168 - dense_3_acc_7: 0.8193 - dense_3_acc_8: 0.0575 - dense_3_acc_9: 0.02 - ETA: 28s - loss: 21.1638 - dense_3_loss: 2.8037 - dense_3_acc: 0.0062 - dense_3_acc_1: 0.3886 - dense_3_acc_2: 0.1800 - dense_3_acc_3: 0.0679 - dense_3_acc_4: 0.6676 - dense_3_acc_5: 0.1379 - dense_3_acc_6: 0.0162 - dense_3_acc_7: 0.8203 - dense_3_acc_8: 0.0597 - dense_3_acc_9: 0.0303"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5800/10000 [================>.............] - ETA: 27s - loss: 21.1003 - dense_3_loss: 2.7961 - dense_3_acc: 0.0060 - dense_3_acc_1: 0.3963 - dense_3_acc_2: 0.1887 - dense_3_acc_3: 0.0657 - dense_3_acc_4: 0.6787 - dense_3_acc_5: 0.1333 - dense_3_acc_6: 0.0157 - dense_3_acc_7: 0.8207 - dense_3_acc_8: 0.0630 - dense_3_acc_9: 0.03 - ETA: 26s - loss: 21.0422 - dense_3_loss: 2.7958 - dense_3_acc: 0.0058 - dense_3_acc_1: 0.4026 - dense_3_acc_2: 0.1923 - dense_3_acc_3: 0.0635 - dense_3_acc_4: 0.6890 - dense_3_acc_5: 0.1290 - dense_3_acc_6: 0.0155 - dense_3_acc_7: 0.8161 - dense_3_acc_8: 0.0687 - dense_3_acc_9: 0.04 - ETA: 25s - loss: 20.9904 - dense_3_loss: 2.7975 - dense_3_acc: 0.0056 - dense_3_acc_1: 0.4084 - dense_3_acc_2: 0.1931 - dense_3_acc_3: 0.0628 - dense_3_acc_4: 0.6988 - dense_3_acc_5: 0.1250 - dense_3_acc_6: 0.0156 - dense_3_acc_7: 0.8006 - dense_3_acc_8: 0.0769 - dense_3_acc_9: 0.04 - ETA: 24s - loss: 20.9319 - dense_3_loss: 2.8015 - dense_3_acc: 0.0055 - dense_3_acc_1: 0.4152 - dense_3_acc_2: 0.1955 - dense_3_acc_3: 0.0618 - dense_3_acc_4: 0.7079 - dense_3_acc_5: 0.1212 - dense_3_acc_6: 0.0155 - dense_3_acc_7: 0.7964 - dense_3_acc_8: 0.0858 - dense_3_acc_9: 0.04 - ETA: 23s - loss: 20.8805 - dense_3_loss: 2.8054 - dense_3_acc: 0.0053 - dense_3_acc_1: 0.4188 - dense_3_acc_2: 0.2006 - dense_3_acc_3: 0.0609 - dense_3_acc_4: 0.7165 - dense_3_acc_5: 0.1176 - dense_3_acc_6: 0.0150 - dense_3_acc_7: 0.7994 - dense_3_acc_8: 0.0882 - dense_3_acc_9: 0.04 - ETA: 22s - loss: 20.8207 - dense_3_loss: 2.8005 - dense_3_acc: 0.0163 - dense_3_acc_1: 0.4271 - dense_3_acc_2: 0.2009 - dense_3_acc_3: 0.0603 - dense_3_acc_4: 0.7246 - dense_3_acc_5: 0.1143 - dense_3_acc_6: 0.0146 - dense_3_acc_7: 0.7989 - dense_3_acc_8: 0.0914 - dense_3_acc_9: 0.05 - ETA: 21s - loss: 20.7554 - dense_3_loss: 2.8045 - dense_3_acc: 0.0350 - dense_3_acc_1: 0.4344 - dense_3_acc_2: 0.2042 - dense_3_acc_3: 0.0617 - dense_3_acc_4: 0.7322 - dense_3_acc_5: 0.1111 - dense_3_acc_6: 0.0142 - dense_3_acc_7: 0.7950 - dense_3_acc_8: 0.0944 - dense_3_acc_9: 0.05 - ETA: 21s - loss: 20.6966 - dense_3_loss: 2.8012 - dense_3_acc: 0.0495 - dense_3_acc_1: 0.4381 - dense_3_acc_2: 0.2059 - dense_3_acc_3: 0.0614 - dense_3_acc_4: 0.7395 - dense_3_acc_5: 0.1081 - dense_3_acc_6: 0.0138 - dense_3_acc_7: 0.7892 - dense_3_acc_8: 0.0984 - dense_3_acc_9: 0.05 - ETA: 20s - loss: 20.6384 - dense_3_loss: 2.8043 - dense_3_acc: 0.0647 - dense_3_acc_1: 0.4432 - dense_3_acc_2: 0.2092 - dense_3_acc_3: 0.0605 - dense_3_acc_4: 0.7463 - dense_3_acc_5: 0.1053 - dense_3_acc_6: 0.0147 - dense_3_acc_7: 0.7805 - dense_3_acc_8: 0.1032 - dense_3_acc_9: 0.05 - ETA: 19s - loss: 20.5796 - dense_3_loss: 2.8056 - dense_3_acc: 0.0790 - dense_3_acc_1: 0.4477 - dense_3_acc_2: 0.2108 - dense_3_acc_3: 0.0590 - dense_3_acc_4: 0.7528 - dense_3_acc_5: 0.1026 - dense_3_acc_6: 0.0144 - dense_3_acc_7: 0.7756 - dense_3_acc_8: 0.1079 - dense_3_acc_9: 0.05 - ETA: 19s - loss: 20.5159 - dense_3_loss: 2.8065 - dense_3_acc: 0.0932 - dense_3_acc_1: 0.4527 - dense_3_acc_2: 0.2130 - dense_3_acc_3: 0.0575 - dense_3_acc_4: 0.7590 - dense_3_acc_5: 0.1000 - dense_3_acc_6: 0.0140 - dense_3_acc_7: 0.7755 - dense_3_acc_8: 0.1090 - dense_3_acc_9: 0.06 - ETA: 18s - loss: 20.4533 - dense_3_loss: 2.8032 - dense_3_acc: 0.1061 - dense_3_acc_1: 0.4568 - dense_3_acc_2: 0.2139 - dense_3_acc_3: 0.0561 - dense_3_acc_4: 0.7649 - dense_3_acc_5: 0.0976 - dense_3_acc_6: 0.0137 - dense_3_acc_7: 0.7746 - dense_3_acc_8: 0.1105 - dense_3_acc_9: 0.06 - ETA: 18s - loss: 20.3946 - dense_3_loss: 2.8042 - dense_3_acc: 0.1176 - dense_3_acc_1: 0.4600 - dense_3_acc_2: 0.2160 - dense_3_acc_3: 0.0557 - dense_3_acc_4: 0.7705 - dense_3_acc_5: 0.0952 - dense_3_acc_6: 0.0140 - dense_3_acc_7: 0.7714 - dense_3_acc_8: 0.1140 - dense_3_acc_9: 0.06 - ETA: 17s - loss: 20.3287 - dense_3_loss: 2.8027 - dense_3_acc: 0.1300 - dense_3_acc_1: 0.4644 - dense_3_acc_2: 0.2186 - dense_3_acc_3: 0.0551 - dense_3_acc_4: 0.7758 - dense_3_acc_5: 0.0935 - dense_3_acc_6: 0.0144 - dense_3_acc_7: 0.7647 - dense_3_acc_8: 0.1188 - dense_3_acc_9: 0.06 - ETA: 16s - loss: 20.2707 - dense_3_loss: 2.8046 - dense_3_acc: 0.1420 - dense_3_acc_1: 0.4689 - dense_3_acc_2: 0.2207 - dense_3_acc_3: 0.0550 - dense_3_acc_4: 0.7809 - dense_3_acc_5: 0.0936 - dense_3_acc_6: 0.0141 - dense_3_acc_7: 0.7605 - dense_3_acc_8: 0.1223 - dense_3_acc_9: 0.06 - ETA: 16s - loss: 20.2026 - dense_3_loss: 2.8031 - dense_3_acc: 0.1544 - dense_3_acc_1: 0.4740 - dense_3_acc_2: 0.2224 - dense_3_acc_3: 0.0538 - dense_3_acc_4: 0.7858 - dense_3_acc_5: 0.0936 - dense_3_acc_6: 0.0142 - dense_3_acc_7: 0.7560 - dense_3_acc_8: 0.1264 - dense_3_acc_9: 0.06 - ETA: 15s - loss: 20.1455 - dense_3_loss: 2.8023 - dense_3_acc: 0.1635 - dense_3_acc_1: 0.4761 - dense_3_acc_2: 0.2265 - dense_3_acc_3: 0.0528 - dense_3_acc_4: 0.7904 - dense_3_acc_5: 0.0915 - dense_3_acc_6: 0.0148 - dense_3_acc_7: 0.7502 - dense_3_acc_8: 0.1293 - dense_3_acc_9: 0.07 - ETA: 15s - loss: 20.0916 - dense_3_loss: 2.8046 - dense_3_acc: 0.1717 - dense_3_acc_1: 0.4781 - dense_3_acc_2: 0.2309 - dense_3_acc_3: 0.0523 - dense_3_acc_4: 0.7949 - dense_3_acc_5: 0.0949 - dense_3_acc_6: 0.0151 - dense_3_acc_7: 0.7485 - dense_3_acc_8: 0.1309 - dense_3_acc_9: 0.07 - ETA: 14s - loss: 20.0347 - dense_3_loss: 2.8038 - dense_3_acc: 0.1808 - dense_3_acc_1: 0.4850 - dense_3_acc_2: 0.2329 - dense_3_acc_3: 0.0519 - dense_3_acc_4: 0.7992 - dense_3_acc_5: 0.1019 - dense_3_acc_6: 0.0150 - dense_3_acc_7: 0.7452 - dense_3_acc_8: 0.1335 - dense_3_acc_9: 0.07 - ETA: 14s - loss: 19.9693 - dense_3_loss: 2.8035 - dense_3_acc: 0.1908 - dense_3_acc_1: 0.4896 - dense_3_acc_2: 0.2357 - dense_3_acc_3: 0.0520 - dense_3_acc_4: 0.8033 - dense_3_acc_5: 0.1035 - dense_3_acc_6: 0.0149 - dense_3_acc_7: 0.7453 - dense_3_acc_8: 0.1347 - dense_3_acc_9: 0.07 - ETA: 14s - loss: 19.9064 - dense_3_loss: 2.8042 - dense_3_acc: 0.2000 - dense_3_acc_1: 0.4928 - dense_3_acc_2: 0.2392 - dense_3_acc_3: 0.0524 - dense_3_acc_4: 0.8072 - dense_3_acc_5: 0.1028 - dense_3_acc_6: 0.0148 - dense_3_acc_7: 0.7458 - dense_3_acc_8: 0.1378 - dense_3_acc_9: 0.07 - ETA: 13s - loss: 19.8422 - dense_3_loss: 2.8033 - dense_3_acc: 0.2080 - dense_3_acc_1: 0.4961 - dense_3_acc_2: 0.2425 - dense_3_acc_3: 0.0520 - dense_3_acc_4: 0.8110 - dense_3_acc_5: 0.1051 - dense_3_acc_6: 0.0145 - dense_3_acc_7: 0.7457 - dense_3_acc_8: 0.1402 - dense_3_acc_9: 0.07 - ETA: 13s - loss: 19.7791 - dense_3_loss: 2.8008 - dense_3_acc: 0.2158 - dense_3_acc_1: 0.5021 - dense_3_acc_2: 0.2460 - dense_3_acc_3: 0.0521 - dense_3_acc_4: 0.8137 - dense_3_acc_5: 0.1117 - dense_3_acc_6: 0.0150 - dense_3_acc_7: 0.7437 - dense_3_acc_8: 0.1433 - dense_3_acc_9: 0.07 - ETA: 12s - loss: 19.7161 - dense_3_loss: 2.7973 - dense_3_acc: 0.2228 - dense_3_acc_1: 0.5064 - dense_3_acc_2: 0.2477 - dense_3_acc_3: 0.0528 - dense_3_acc_4: 0.8170 - dense_3_acc_5: 0.1198 - dense_3_acc_6: 0.0157 - dense_3_acc_7: 0.7421 - dense_3_acc_8: 0.1462 - dense_3_acc_9: 0.07 - ETA: 12s - loss: 19.6447 - dense_3_loss: 2.7922 - dense_3_acc: 0.2302 - dense_3_acc_1: 0.5120 - dense_3_acc_2: 0.2519 - dense_3_acc_3: 0.0531 - dense_3_acc_4: 0.8204 - dense_3_acc_5: 0.1281 - dense_3_acc_6: 0.0167 - dense_3_acc_7: 0.7444 - dense_3_acc_8: 0.1480 - dense_3_acc_9: 0.07 - ETA: 11s - loss: 19.5695 - dense_3_loss: 2.7896 - dense_3_acc: 0.2382 - dense_3_acc_1: 0.5178 - dense_3_acc_2: 0.2553 - dense_3_acc_3: 0.0540 - dense_3_acc_4: 0.8236 - dense_3_acc_5: 0.1380 - dense_3_acc_6: 0.0173 - dense_3_acc_7: 0.7487 - dense_3_acc_8: 0.1505 - dense_3_acc_9: 0.08 - ETA: 11s - loss: 19.4987 - dense_3_loss: 2.7864 - dense_3_acc: 0.2450 - dense_3_acc_1: 0.5212 - dense_3_acc_2: 0.2573 - dense_3_acc_3: 0.0541 - dense_3_acc_4: 0.8268 - dense_3_acc_5: 0.1473 - dense_3_acc_6: 0.0173 - dense_3_acc_7: 0.7532 - dense_3_acc_8: 0.1529 - dense_3_acc_9: 0.08 - ETA: 11s - loss: 19.4233 - dense_3_loss: 2.7805 - dense_3_acc: 0.2507 - dense_3_acc_1: 0.5253 - dense_3_acc_2: 0.2600 - dense_3_acc_3: 0.0539 - dense_3_acc_4: 0.8298 - dense_3_acc_5: 0.1581 - dense_3_acc_6: 0.0174 - dense_3_acc_7: 0.7575 - dense_3_acc_8: 0.1561 - dense_3_acc_9: 0.08 - ETA: 10s - loss: 19.3517 - dense_3_loss: 2.7765 - dense_3_acc: 0.2560 - dense_3_acc_1: 0.5316 - dense_3_acc_2: 0.2610 - dense_3_acc_3: 0.0541 - dense_3_acc_4: 0.8328 - dense_3_acc_5: 0.1697 - dense_3_acc_6: 0.0174 - dense_3_acc_7: 0.7610 - dense_3_acc_8: 0.1603 - dense_3_acc_9: 0.0848"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8700/10000 [=========================>....] - ETA: 10s - loss: 19.2701 - dense_3_loss: 2.7708 - dense_3_acc: 0.2631 - dense_3_acc_1: 0.5346 - dense_3_acc_2: 0.2620 - dense_3_acc_3: 0.0536 - dense_3_acc_4: 0.8356 - dense_3_acc_5: 0.1803 - dense_3_acc_6: 0.0176 - dense_3_acc_7: 0.7651 - dense_3_acc_8: 0.1634 - dense_3_acc_9: 0.08 - ETA: 10s - loss: 19.1937 - dense_3_loss: 2.7650 - dense_3_acc: 0.2677 - dense_3_acc_1: 0.5357 - dense_3_acc_2: 0.2633 - dense_3_acc_3: 0.0527 - dense_3_acc_4: 0.8383 - dense_3_acc_5: 0.1892 - dense_3_acc_6: 0.0175 - dense_3_acc_7: 0.7690 - dense_3_acc_8: 0.1653 - dense_3_acc_9: 0.08 - ETA: 9s - loss: 19.1051 - dense_3_loss: 2.7597 - dense_3_acc: 0.2736 - dense_3_acc_1: 0.5416 - dense_3_acc_2: 0.2666 - dense_3_acc_3: 0.0521 - dense_3_acc_4: 0.8410 - dense_3_acc_5: 0.1990 - dense_3_acc_6: 0.0177 - dense_3_acc_7: 0.7728 - dense_3_acc_8: 0.1682 - dense_3_acc_9: 0.0880 - ETA: 9s - loss: 19.0196 - dense_3_loss: 2.7547 - dense_3_acc: 0.2781 - dense_3_acc_1: 0.5481 - dense_3_acc_2: 0.2690 - dense_3_acc_3: 0.0534 - dense_3_acc_4: 0.8435 - dense_3_acc_5: 0.2092 - dense_3_acc_6: 0.0189 - dense_3_acc_7: 0.7765 - dense_3_acc_8: 0.1724 - dense_3_acc_9: 0.088 - ETA: 9s - loss: 18.9297 - dense_3_loss: 2.7490 - dense_3_acc: 0.2854 - dense_3_acc_1: 0.5548 - dense_3_acc_2: 0.2703 - dense_3_acc_3: 0.0538 - dense_3_acc_4: 0.8460 - dense_3_acc_5: 0.2195 - dense_3_acc_6: 0.0197 - dense_3_acc_7: 0.7800 - dense_3_acc_8: 0.1735 - dense_3_acc_9: 0.089 - ETA: 8s - loss: 18.8402 - dense_3_loss: 2.7436 - dense_3_acc: 0.2908 - dense_3_acc_1: 0.5589 - dense_3_acc_2: 0.2723 - dense_3_acc_3: 0.0547 - dense_3_acc_4: 0.8484 - dense_3_acc_5: 0.2297 - dense_3_acc_6: 0.0197 - dense_3_acc_7: 0.7834 - dense_3_acc_8: 0.1763 - dense_3_acc_9: 0.090 - ETA: 8s - loss: 18.7490 - dense_3_loss: 2.7386 - dense_3_acc: 0.2980 - dense_3_acc_1: 0.5637 - dense_3_acc_2: 0.2734 - dense_3_acc_3: 0.0557 - dense_3_acc_4: 0.8508 - dense_3_acc_5: 0.2388 - dense_3_acc_6: 0.0211 - dense_3_acc_7: 0.7868 - dense_3_acc_8: 0.1786 - dense_3_acc_9: 0.090 - ETA: 8s - loss: 18.6544 - dense_3_loss: 2.7322 - dense_3_acc: 0.3065 - dense_3_acc_1: 0.5702 - dense_3_acc_2: 0.2758 - dense_3_acc_3: 0.0565 - dense_3_acc_4: 0.8530 - dense_3_acc_5: 0.2483 - dense_3_acc_6: 0.0220 - dense_3_acc_7: 0.7900 - dense_3_acc_8: 0.1826 - dense_3_acc_9: 0.092 - ETA: 7s - loss: 18.5604 - dense_3_loss: 2.7271 - dense_3_acc: 0.3160 - dense_3_acc_1: 0.5754 - dense_3_acc_2: 0.2763 - dense_3_acc_3: 0.0573 - dense_3_acc_4: 0.8552 - dense_3_acc_5: 0.2578 - dense_3_acc_6: 0.0236 - dense_3_acc_7: 0.7931 - dense_3_acc_8: 0.1858 - dense_3_acc_9: 0.093 - ETA: 7s - loss: 18.4661 - dense_3_loss: 2.7210 - dense_3_acc: 0.3235 - dense_3_acc_1: 0.5809 - dense_3_acc_2: 0.2776 - dense_3_acc_3: 0.0582 - dense_3_acc_4: 0.8574 - dense_3_acc_5: 0.2666 - dense_3_acc_6: 0.0249 - dense_3_acc_7: 0.7962 - dense_3_acc_8: 0.1894 - dense_3_acc_9: 0.094 - ETA: 7s - loss: 18.3763 - dense_3_loss: 2.7145 - dense_3_acc: 0.3301 - dense_3_acc_1: 0.5854 - dense_3_acc_2: 0.2800 - dense_3_acc_3: 0.0588 - dense_3_acc_4: 0.8594 - dense_3_acc_5: 0.2739 - dense_3_acc_6: 0.0262 - dense_3_acc_7: 0.7991 - dense_3_acc_8: 0.1926 - dense_3_acc_9: 0.095 - ETA: 7s - loss: 18.2879 - dense_3_loss: 2.7091 - dense_3_acc: 0.3363 - dense_3_acc_1: 0.5899 - dense_3_acc_2: 0.2806 - dense_3_acc_3: 0.0591 - dense_3_acc_4: 0.8614 - dense_3_acc_5: 0.2811 - dense_3_acc_6: 0.0277 - dense_3_acc_7: 0.8020 - dense_3_acc_8: 0.1951 - dense_3_acc_9: 0.095 - ETA: 6s - loss: 18.1980 - dense_3_loss: 2.7039 - dense_3_acc: 0.3446 - dense_3_acc_1: 0.5952 - dense_3_acc_2: 0.2814 - dense_3_acc_3: 0.0604 - dense_3_acc_4: 0.8634 - dense_3_acc_5: 0.2890 - dense_3_acc_6: 0.0293 - dense_3_acc_7: 0.8048 - dense_3_acc_8: 0.1983 - dense_3_acc_9: 0.096 - ETA: 6s - loss: 18.1094 - dense_3_loss: 2.7004 - dense_3_acc: 0.3529 - dense_3_acc_1: 0.5996 - dense_3_acc_2: 0.2839 - dense_3_acc_3: 0.0611 - dense_3_acc_4: 0.8653 - dense_3_acc_5: 0.2968 - dense_3_acc_6: 0.0317 - dense_3_acc_7: 0.8075 - dense_3_acc_8: 0.2010 - dense_3_acc_9: 0.096 - ETA: 6s - loss: 18.0189 - dense_3_loss: 2.6944 - dense_3_acc: 0.3600 - dense_3_acc_1: 0.6042 - dense_3_acc_2: 0.2849 - dense_3_acc_3: 0.0621 - dense_3_acc_4: 0.8671 - dense_3_acc_5: 0.3055 - dense_3_acc_6: 0.0333 - dense_3_acc_7: 0.8101 - dense_3_acc_8: 0.2045 - dense_3_acc_9: 0.097 - ETA: 5s - loss: 17.9298 - dense_3_loss: 2.6879 - dense_3_acc: 0.3661 - dense_3_acc_1: 0.6085 - dense_3_acc_2: 0.2854 - dense_3_acc_3: 0.0619 - dense_3_acc_4: 0.8689 - dense_3_acc_5: 0.3132 - dense_3_acc_6: 0.0357 - dense_3_acc_7: 0.8127 - dense_3_acc_8: 0.2066 - dense_3_acc_9: 0.098 - ETA: 5s - loss: 17.8420 - dense_3_loss: 2.6824 - dense_3_acc: 0.3723 - dense_3_acc_1: 0.6127 - dense_3_acc_2: 0.2863 - dense_3_acc_3: 0.0628 - dense_3_acc_4: 0.8707 - dense_3_acc_5: 0.3200 - dense_3_acc_6: 0.0379 - dense_3_acc_7: 0.8152 - dense_3_acc_8: 0.2096 - dense_3_acc_9: 0.098 - ETA: 5s - loss: 17.7539 - dense_3_loss: 2.6765 - dense_3_acc: 0.3799 - dense_3_acc_1: 0.6167 - dense_3_acc_2: 0.2893 - dense_3_acc_3: 0.0633 - dense_3_acc_4: 0.8724 - dense_3_acc_5: 0.3261 - dense_3_acc_6: 0.0391 - dense_3_acc_7: 0.8176 - dense_3_acc_8: 0.2129 - dense_3_acc_9: 0.099 - ETA: 5s - loss: 17.6668 - dense_3_loss: 2.6717 - dense_3_acc: 0.3869 - dense_3_acc_1: 0.6210 - dense_3_acc_2: 0.2913 - dense_3_acc_3: 0.0651 - dense_3_acc_4: 0.8740 - dense_3_acc_5: 0.3322 - dense_3_acc_6: 0.0410 - dense_3_acc_7: 0.8200 - dense_3_acc_8: 0.2160 - dense_3_acc_9: 0.100 - ETA: 4s - loss: 17.5853 - dense_3_loss: 2.6663 - dense_3_acc: 0.3929 - dense_3_acc_1: 0.6251 - dense_3_acc_2: 0.2933 - dense_3_acc_3: 0.0660 - dense_3_acc_4: 0.8756 - dense_3_acc_5: 0.3386 - dense_3_acc_6: 0.0423 - dense_3_acc_7: 0.8223 - dense_3_acc_8: 0.2169 - dense_3_acc_9: 0.101 - ETA: 4s - loss: 17.5010 - dense_3_loss: 2.6616 - dense_3_acc: 0.3994 - dense_3_acc_1: 0.6291 - dense_3_acc_2: 0.2971 - dense_3_acc_3: 0.0668 - dense_3_acc_4: 0.8772 - dense_3_acc_5: 0.3452 - dense_3_acc_6: 0.0453 - dense_3_acc_7: 0.8246 - dense_3_acc_8: 0.2194 - dense_3_acc_9: 0.102 - ETA: 4s - loss: 17.4205 - dense_3_loss: 2.6563 - dense_3_acc: 0.4055 - dense_3_acc_1: 0.6325 - dense_3_acc_2: 0.2976 - dense_3_acc_3: 0.0675 - dense_3_acc_4: 0.8788 - dense_3_acc_5: 0.3522 - dense_3_acc_6: 0.0465 - dense_3_acc_7: 0.8267 - dense_3_acc_8: 0.2210 - dense_3_acc_9: 0.102 - ETA: 4s - loss: 17.3366 - dense_3_loss: 2.6507 - dense_3_acc: 0.4115 - dense_3_acc_1: 0.6362 - dense_3_acc_2: 0.2996 - dense_3_acc_3: 0.0684 - dense_3_acc_4: 0.8802 - dense_3_acc_5: 0.3588 - dense_3_acc_6: 0.0485 - dense_3_acc_7: 0.8289 - dense_3_acc_8: 0.2236 - dense_3_acc_9: 0.103 - ETA: 3s - loss: 17.2563 - dense_3_loss: 2.6464 - dense_3_acc: 0.4177 - dense_3_acc_1: 0.6401 - dense_3_acc_2: 0.3012 - dense_3_acc_3: 0.0694 - dense_3_acc_4: 0.8817 - dense_3_acc_5: 0.3656 - dense_3_acc_6: 0.0509 - dense_3_acc_7: 0.8310 - dense_3_acc_8: 0.2255 - dense_3_acc_9: 0.104 - ETA: 3s - loss: 17.1759 - dense_3_loss: 2.6408 - dense_3_acc: 0.4237 - dense_3_acc_1: 0.6437 - dense_3_acc_2: 0.3037 - dense_3_acc_3: 0.0702 - dense_3_acc_4: 0.8831 - dense_3_acc_5: 0.3713 - dense_3_acc_6: 0.0531 - dense_3_acc_7: 0.8330 - dense_3_acc_8: 0.2269 - dense_3_acc_9: 0.105 - ETA: 3s - loss: 17.0961 - dense_3_loss: 2.6359 - dense_3_acc: 0.4296 - dense_3_acc_1: 0.6474 - dense_3_acc_2: 0.3050 - dense_3_acc_3: 0.0710 - dense_3_acc_4: 0.8845 - dense_3_acc_5: 0.3774 - dense_3_acc_6: 0.0549 - dense_3_acc_7: 0.8350 - dense_3_acc_8: 0.2289 - dense_3_acc_9: 0.107 - ETA: 3s - loss: 17.0221 - dense_3_loss: 2.6315 - dense_3_acc: 0.4345 - dense_3_acc_1: 0.6505 - dense_3_acc_2: 0.3066 - dense_3_acc_3: 0.0713 - dense_3_acc_4: 0.8859 - dense_3_acc_5: 0.3833 - dense_3_acc_6: 0.0560 - dense_3_acc_7: 0.8369 - dense_3_acc_8: 0.2305 - dense_3_acc_9: 0.107 - ETA: 3s - loss: 16.9500 - dense_3_loss: 2.6266 - dense_3_acc: 0.4406 - dense_3_acc_1: 0.6541 - dense_3_acc_2: 0.3090 - dense_3_acc_3: 0.0723 - dense_3_acc_4: 0.8872 - dense_3_acc_5: 0.3885 - dense_3_acc_6: 0.0578 - dense_3_acc_7: 0.8388 - dense_3_acc_8: 0.2319 - dense_3_acc_9: 0.109 - ETA: 2s - loss: 16.8725 - dense_3_loss: 2.6210 - dense_3_acc: 0.4469 - dense_3_acc_1: 0.6576 - dense_3_acc_2: 0.3115 - dense_3_acc_3: 0.0728 - dense_3_acc_4: 0.8885 - dense_3_acc_5: 0.3939 - dense_3_acc_6: 0.0591 - dense_3_acc_7: 0.8407 - dense_3_acc_8: 0.2344 - dense_3_acc_9: 0.1110"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - ETA: 2s - loss: 16.8007 - dense_3_loss: 2.6165 - dense_3_acc: 0.4510 - dense_3_acc_1: 0.6603 - dense_3_acc_2: 0.3138 - dense_3_acc_3: 0.0734 - dense_3_acc_4: 0.8898 - dense_3_acc_5: 0.3991 - dense_3_acc_6: 0.0606 - dense_3_acc_7: 0.8425 - dense_3_acc_8: 0.2350 - dense_3_acc_9: 0.111 - ETA: 2s - loss: 16.7294 - dense_3_loss: 2.6125 - dense_3_acc: 0.4566 - dense_3_acc_1: 0.6635 - dense_3_acc_2: 0.3134 - dense_3_acc_3: 0.0746 - dense_3_acc_4: 0.8910 - dense_3_acc_5: 0.4042 - dense_3_acc_6: 0.0616 - dense_3_acc_7: 0.8443 - dense_3_acc_8: 0.2366 - dense_3_acc_9: 0.112 - ETA: 2s - loss: 16.6590 - dense_3_loss: 2.6080 - dense_3_acc: 0.4620 - dense_3_acc_1: 0.6663 - dense_3_acc_2: 0.3141 - dense_3_acc_3: 0.0752 - dense_3_acc_4: 0.8922 - dense_3_acc_5: 0.4091 - dense_3_acc_6: 0.0633 - dense_3_acc_7: 0.8460 - dense_3_acc_8: 0.2388 - dense_3_acc_9: 0.113 - ETA: 1s - loss: 16.5888 - dense_3_loss: 2.6049 - dense_3_acc: 0.4671 - dense_3_acc_1: 0.6696 - dense_3_acc_2: 0.3160 - dense_3_acc_3: 0.0766 - dense_3_acc_4: 0.8934 - dense_3_acc_5: 0.4143 - dense_3_acc_6: 0.0649 - dense_3_acc_7: 0.8477 - dense_3_acc_8: 0.2396 - dense_3_acc_9: 0.114 - ETA: 1s - loss: 16.5214 - dense_3_loss: 2.6013 - dense_3_acc: 0.4725 - dense_3_acc_1: 0.6727 - dense_3_acc_2: 0.3172 - dense_3_acc_3: 0.0771 - dense_3_acc_4: 0.8946 - dense_3_acc_5: 0.4193 - dense_3_acc_6: 0.0660 - dense_3_acc_7: 0.8493 - dense_3_acc_8: 0.2413 - dense_3_acc_9: 0.114 - ETA: 1s - loss: 16.4518 - dense_3_loss: 2.5975 - dense_3_acc: 0.4778 - dense_3_acc_1: 0.6760 - dense_3_acc_2: 0.3194 - dense_3_acc_3: 0.0774 - dense_3_acc_4: 0.8957 - dense_3_acc_5: 0.4239 - dense_3_acc_6: 0.0681 - dense_3_acc_7: 0.8510 - dense_3_acc_8: 0.2435 - dense_3_acc_9: 0.115 - ETA: 1s - loss: 16.3845 - dense_3_loss: 2.5941 - dense_3_acc: 0.4832 - dense_3_acc_1: 0.6793 - dense_3_acc_2: 0.3212 - dense_3_acc_3: 0.0777 - dense_3_acc_4: 0.8968 - dense_3_acc_5: 0.4284 - dense_3_acc_6: 0.0688 - dense_3_acc_7: 0.8526 - dense_3_acc_8: 0.2465 - dense_3_acc_9: 0.116 - ETA: 1s - loss: 16.3192 - dense_3_loss: 2.5904 - dense_3_acc: 0.4882 - dense_3_acc_1: 0.6822 - dense_3_acc_2: 0.3233 - dense_3_acc_3: 0.0783 - dense_3_acc_4: 0.8979 - dense_3_acc_5: 0.4337 - dense_3_acc_6: 0.0704 - dense_3_acc_7: 0.8541 - dense_3_acc_8: 0.2485 - dense_3_acc_9: 0.116 - ETA: 0s - loss: 16.2565 - dense_3_loss: 2.5869 - dense_3_acc: 0.4930 - dense_3_acc_1: 0.6848 - dense_3_acc_2: 0.3241 - dense_3_acc_3: 0.0784 - dense_3_acc_4: 0.8990 - dense_3_acc_5: 0.4369 - dense_3_acc_6: 0.0718 - dense_3_acc_7: 0.8556 - dense_3_acc_8: 0.2507 - dense_3_acc_9: 0.117 - ETA: 0s - loss: 16.1909 - dense_3_loss: 2.5831 - dense_3_acc: 0.4979 - dense_3_acc_1: 0.6877 - dense_3_acc_2: 0.3261 - dense_3_acc_3: 0.0792 - dense_3_acc_4: 0.9000 - dense_3_acc_5: 0.4405 - dense_3_acc_6: 0.0726 - dense_3_acc_7: 0.8571 - dense_3_acc_8: 0.2526 - dense_3_acc_9: 0.118 - ETA: 0s - loss: 16.1264 - dense_3_loss: 2.5802 - dense_3_acc: 0.5028 - dense_3_acc_1: 0.6905 - dense_3_acc_2: 0.3288 - dense_3_acc_3: 0.0800 - dense_3_acc_4: 0.9010 - dense_3_acc_5: 0.4450 - dense_3_acc_6: 0.0737 - dense_3_acc_7: 0.8586 - dense_3_acc_8: 0.2546 - dense_3_acc_9: 0.118 - ETA: 0s - loss: 16.0639 - dense_3_loss: 2.5772 - dense_3_acc: 0.5077 - dense_3_acc_1: 0.6934 - dense_3_acc_2: 0.3304 - dense_3_acc_3: 0.0804 - dense_3_acc_4: 0.9020 - dense_3_acc_5: 0.4501 - dense_3_acc_6: 0.0746 - dense_3_acc_7: 0.8600 - dense_3_acc_8: 0.2558 - dense_3_acc_9: 0.119 - 20s 2ms/step - loss: 16.0019 - dense_3_loss: 2.5735 - dense_3_acc: 0.5124 - dense_3_acc_1: 0.6962 - dense_3_acc_2: 0.3327 - dense_3_acc_3: 0.0806 - dense_3_acc_4: 0.9030 - dense_3_acc_5: 0.4539 - dense_3_acc_6: 0.0761 - dense_3_acc_7: 0.8614 - dense_3_acc_8: 0.2578 - dense_3_acc_9: 0.1199\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2900/10000 [=======>......................] - ETA: 11s - loss: 10.0042 - dense_3_loss: 2.3005 - dense_3_acc: 0.9400 - dense_3_acc_1: 0.9700 - dense_3_acc_2: 0.5100 - dense_3_acc_3: 0.1400 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.8200 - dense_3_acc_6: 0.2500 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4700 - dense_3_acc_9: 0.13 - ETA: 11s - loss: 9.9568 - dense_3_loss: 2.2912 - dense_3_acc: 0.9500 - dense_3_acc_1: 0.9650 - dense_3_acc_2: 0.4500 - dense_3_acc_3: 0.1550 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.8600 - dense_3_acc_6: 0.2750 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.3950 - dense_3_acc_9: 0.1400 - ETA: 11s - loss: 9.8370 - dense_3_loss: 2.2795 - dense_3_acc: 0.9600 - dense_3_acc_1: 0.9733 - dense_3_acc_2: 0.4833 - dense_3_acc_3: 0.1500 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.8800 - dense_3_acc_6: 0.2400 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4167 - dense_3_acc_9: 0.146 - ETA: 11s - loss: 9.7756 - dense_3_loss: 2.2616 - dense_3_acc: 0.9625 - dense_3_acc_1: 0.9700 - dense_3_acc_2: 0.4600 - dense_3_acc_3: 0.1425 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9050 - dense_3_acc_6: 0.2200 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4175 - dense_3_acc_9: 0.150 - ETA: 11s - loss: 9.7870 - dense_3_loss: 2.2524 - dense_3_acc: 0.9620 - dense_3_acc_1: 0.9680 - dense_3_acc_2: 0.4480 - dense_3_acc_3: 0.1400 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.8880 - dense_3_acc_6: 0.2240 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4020 - dense_3_acc_9: 0.152 - ETA: 11s - loss: 9.7902 - dense_3_loss: 2.2387 - dense_3_acc: 0.9667 - dense_3_acc_1: 0.9683 - dense_3_acc_2: 0.4850 - dense_3_acc_3: 0.1333 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.8750 - dense_3_acc_6: 0.2300 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.3983 - dense_3_acc_9: 0.166 - ETA: 11s - loss: 9.7505 - dense_3_loss: 2.2323 - dense_3_acc: 0.9700 - dense_3_acc_1: 0.9714 - dense_3_acc_2: 0.4943 - dense_3_acc_3: 0.1286 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.8843 - dense_3_acc_6: 0.2286 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4071 - dense_3_acc_9: 0.170 - ETA: 11s - loss: 9.7457 - dense_3_loss: 2.2359 - dense_3_acc: 0.9700 - dense_3_acc_1: 0.9738 - dense_3_acc_2: 0.5062 - dense_3_acc_3: 0.1313 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.8813 - dense_3_acc_6: 0.2250 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4050 - dense_3_acc_9: 0.170 - ETA: 10s - loss: 9.7407 - dense_3_loss: 2.2501 - dense_3_acc: 0.9678 - dense_3_acc_1: 0.9711 - dense_3_acc_2: 0.4989 - dense_3_acc_3: 0.1300 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.8856 - dense_3_acc_6: 0.2244 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4078 - dense_3_acc_9: 0.158 - ETA: 10s - loss: 9.7366 - dense_3_loss: 2.2526 - dense_3_acc: 0.9650 - dense_3_acc_1: 0.9680 - dense_3_acc_2: 0.5100 - dense_3_acc_3: 0.1340 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.8830 - dense_3_acc_6: 0.2210 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4120 - dense_3_acc_9: 0.157 - ETA: 10s - loss: 9.7261 - dense_3_loss: 2.2551 - dense_3_acc: 0.9636 - dense_3_acc_1: 0.9664 - dense_3_acc_2: 0.5127 - dense_3_acc_3: 0.1373 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.8864 - dense_3_acc_6: 0.2227 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4064 - dense_3_acc_9: 0.157 - ETA: 10s - loss: 9.7077 - dense_3_loss: 2.2582 - dense_3_acc: 0.9650 - dense_3_acc_1: 0.9675 - dense_3_acc_2: 0.5192 - dense_3_acc_3: 0.1367 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.8883 - dense_3_acc_6: 0.2258 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4050 - dense_3_acc_9: 0.155 - ETA: 10s - loss: 9.6847 - dense_3_loss: 2.2573 - dense_3_acc: 0.9623 - dense_3_acc_1: 0.9669 - dense_3_acc_2: 0.5185 - dense_3_acc_3: 0.1431 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.8892 - dense_3_acc_6: 0.2238 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4038 - dense_3_acc_9: 0.156 - ETA: 10s - loss: 9.6713 - dense_3_loss: 2.2574 - dense_3_acc: 0.9614 - dense_3_acc_1: 0.9636 - dense_3_acc_2: 0.5243 - dense_3_acc_3: 0.1471 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.8879 - dense_3_acc_6: 0.2279 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4114 - dense_3_acc_9: 0.156 - ETA: 10s - loss: 9.6842 - dense_3_loss: 2.2573 - dense_3_acc: 0.9620 - dense_3_acc_1: 0.9633 - dense_3_acc_2: 0.5233 - dense_3_acc_3: 0.1467 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.8840 - dense_3_acc_6: 0.2220 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4140 - dense_3_acc_9: 0.160 - ETA: 10s - loss: 9.6955 - dense_3_loss: 2.2562 - dense_3_acc: 0.9594 - dense_3_acc_1: 0.9606 - dense_3_acc_2: 0.5269 - dense_3_acc_3: 0.1463 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.8831 - dense_3_acc_6: 0.2262 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4125 - dense_3_acc_9: 0.158 - ETA: 10s - loss: 9.6853 - dense_3_loss: 2.2547 - dense_3_acc: 0.9594 - dense_3_acc_1: 0.9600 - dense_3_acc_2: 0.5265 - dense_3_acc_3: 0.1459 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.8871 - dense_3_acc_6: 0.2265 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4141 - dense_3_acc_9: 0.161 - ETA: 9s - loss: 9.6766 - dense_3_loss: 2.2527 - dense_3_acc: 0.9594 - dense_3_acc_1: 0.9600 - dense_3_acc_2: 0.5256 - dense_3_acc_3: 0.1472 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.8883 - dense_3_acc_6: 0.2261 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4139 - dense_3_acc_9: 0.165 - ETA: 9s - loss: 9.6527 - dense_3_loss: 2.2506 - dense_3_acc: 0.9600 - dense_3_acc_1: 0.9621 - dense_3_acc_2: 0.5268 - dense_3_acc_3: 0.1453 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.8863 - dense_3_acc_6: 0.2268 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4174 - dense_3_acc_9: 0.16 - ETA: 9s - loss: 9.6409 - dense_3_loss: 2.2481 - dense_3_acc: 0.9605 - dense_3_acc_1: 0.9620 - dense_3_acc_2: 0.5310 - dense_3_acc_3: 0.1505 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.8840 - dense_3_acc_6: 0.2295 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4115 - dense_3_acc_9: 0.16 - ETA: 9s - loss: 9.6221 - dense_3_loss: 2.2491 - dense_3_acc: 0.9619 - dense_3_acc_1: 0.9633 - dense_3_acc_2: 0.5319 - dense_3_acc_3: 0.1524 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.8833 - dense_3_acc_6: 0.2319 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4095 - dense_3_acc_9: 0.16 - ETA: 9s - loss: 9.6015 - dense_3_loss: 2.2496 - dense_3_acc: 0.9627 - dense_3_acc_1: 0.9641 - dense_3_acc_2: 0.5336 - dense_3_acc_3: 0.1505 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.8855 - dense_3_acc_6: 0.2345 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4109 - dense_3_acc_9: 0.16 - ETA: 9s - loss: 9.5885 - dense_3_loss: 2.2502 - dense_3_acc: 0.9639 - dense_3_acc_1: 0.9648 - dense_3_acc_2: 0.5300 - dense_3_acc_3: 0.1517 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.8861 - dense_3_acc_6: 0.2335 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4122 - dense_3_acc_9: 0.16 - ETA: 9s - loss: 9.5688 - dense_3_loss: 2.2451 - dense_3_acc: 0.9646 - dense_3_acc_1: 0.9650 - dense_3_acc_2: 0.5300 - dense_3_acc_3: 0.1513 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.8867 - dense_3_acc_6: 0.2371 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4150 - dense_3_acc_9: 0.16 - ETA: 9s - loss: 9.5502 - dense_3_loss: 2.2460 - dense_3_acc: 0.9652 - dense_3_acc_1: 0.9664 - dense_3_acc_2: 0.5324 - dense_3_acc_3: 0.1516 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.8880 - dense_3_acc_6: 0.2356 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4188 - dense_3_acc_9: 0.16 - ETA: 8s - loss: 9.5365 - dense_3_loss: 2.2457 - dense_3_acc: 0.9654 - dense_3_acc_1: 0.9669 - dense_3_acc_2: 0.5327 - dense_3_acc_3: 0.1531 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.8881 - dense_3_acc_6: 0.2342 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4223 - dense_3_acc_9: 0.16 - ETA: 8s - loss: 9.5284 - dense_3_loss: 2.2441 - dense_3_acc: 0.9652 - dense_3_acc_1: 0.9667 - dense_3_acc_2: 0.5322 - dense_3_acc_3: 0.1559 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.8885 - dense_3_acc_6: 0.2344 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4193 - dense_3_acc_9: 0.16 - ETA: 8s - loss: 9.5221 - dense_3_loss: 2.2448 - dense_3_acc: 0.9664 - dense_3_acc_1: 0.9675 - dense_3_acc_2: 0.5346 - dense_3_acc_3: 0.1571 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.8900 - dense_3_acc_6: 0.2364 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4154 - dense_3_acc_9: 0.16 - ETA: 8s - loss: 9.5126 - dense_3_loss: 2.2431 - dense_3_acc: 0.9662 - dense_3_acc_1: 0.9672 - dense_3_acc_2: 0.5366 - dense_3_acc_3: 0.1586 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.8917 - dense_3_acc_6: 0.2369 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4100 - dense_3_acc_9: 0.1652"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5800/10000 [================>.............] - ETA: 8s - loss: 9.5086 - dense_3_loss: 2.2430 - dense_3_acc: 0.9660 - dense_3_acc_1: 0.9677 - dense_3_acc_2: 0.5367 - dense_3_acc_3: 0.1560 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.8933 - dense_3_acc_6: 0.2357 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4093 - dense_3_acc_9: 0.16 - ETA: 8s - loss: 9.4946 - dense_3_loss: 2.2423 - dense_3_acc: 0.9665 - dense_3_acc_1: 0.9684 - dense_3_acc_2: 0.5345 - dense_3_acc_3: 0.1552 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.8952 - dense_3_acc_6: 0.2355 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4100 - dense_3_acc_9: 0.16 - ETA: 8s - loss: 9.4869 - dense_3_loss: 2.2414 - dense_3_acc: 0.9659 - dense_3_acc_1: 0.9681 - dense_3_acc_2: 0.5369 - dense_3_acc_3: 0.1569 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.8966 - dense_3_acc_6: 0.2353 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4097 - dense_3_acc_9: 0.16 - ETA: 8s - loss: 9.4817 - dense_3_loss: 2.2418 - dense_3_acc: 0.9655 - dense_3_acc_1: 0.9676 - dense_3_acc_2: 0.5385 - dense_3_acc_3: 0.1576 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.8964 - dense_3_acc_6: 0.2370 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4091 - dense_3_acc_9: 0.16 - ETA: 7s - loss: 9.4725 - dense_3_loss: 2.2422 - dense_3_acc: 0.9656 - dense_3_acc_1: 0.9671 - dense_3_acc_2: 0.5385 - dense_3_acc_3: 0.1594 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.8971 - dense_3_acc_6: 0.2388 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4085 - dense_3_acc_9: 0.16 - ETA: 7s - loss: 9.4594 - dense_3_loss: 2.2404 - dense_3_acc: 0.9654 - dense_3_acc_1: 0.9669 - dense_3_acc_2: 0.5380 - dense_3_acc_3: 0.1609 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.8986 - dense_3_acc_6: 0.2383 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4074 - dense_3_acc_9: 0.16 - ETA: 7s - loss: 9.4536 - dense_3_loss: 2.2402 - dense_3_acc: 0.9644 - dense_3_acc_1: 0.9664 - dense_3_acc_2: 0.5394 - dense_3_acc_3: 0.1611 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.8994 - dense_3_acc_6: 0.2408 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4075 - dense_3_acc_9: 0.16 - ETA: 7s - loss: 9.4520 - dense_3_loss: 2.2412 - dense_3_acc: 0.9641 - dense_3_acc_1: 0.9651 - dense_3_acc_2: 0.5392 - dense_3_acc_3: 0.1630 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.8997 - dense_3_acc_6: 0.2414 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4092 - dense_3_acc_9: 0.17 - ETA: 7s - loss: 9.4399 - dense_3_loss: 2.2404 - dense_3_acc: 0.9647 - dense_3_acc_1: 0.9658 - dense_3_acc_2: 0.5416 - dense_3_acc_3: 0.1653 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9013 - dense_3_acc_6: 0.2411 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4084 - dense_3_acc_9: 0.16 - ETA: 7s - loss: 9.4336 - dense_3_loss: 2.2401 - dense_3_acc: 0.9638 - dense_3_acc_1: 0.9651 - dense_3_acc_2: 0.5423 - dense_3_acc_3: 0.1651 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9023 - dense_3_acc_6: 0.2413 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4100 - dense_3_acc_9: 0.16 - ETA: 7s - loss: 9.4225 - dense_3_loss: 2.2399 - dense_3_acc: 0.9645 - dense_3_acc_1: 0.9660 - dense_3_acc_2: 0.5412 - dense_3_acc_3: 0.1670 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9005 - dense_3_acc_6: 0.2442 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4092 - dense_3_acc_9: 0.16 - ETA: 7s - loss: 9.4120 - dense_3_loss: 2.2390 - dense_3_acc: 0.9646 - dense_3_acc_1: 0.9659 - dense_3_acc_2: 0.5429 - dense_3_acc_3: 0.1676 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9007 - dense_3_acc_6: 0.2466 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4090 - dense_3_acc_9: 0.17 - ETA: 7s - loss: 9.4076 - dense_3_loss: 2.2394 - dense_3_acc: 0.9640 - dense_3_acc_1: 0.9650 - dense_3_acc_2: 0.5421 - dense_3_acc_3: 0.1671 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9021 - dense_3_acc_6: 0.2464 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4083 - dense_3_acc_9: 0.17 - ETA: 6s - loss: 9.4008 - dense_3_loss: 2.2408 - dense_3_acc: 0.9642 - dense_3_acc_1: 0.9651 - dense_3_acc_2: 0.5414 - dense_3_acc_3: 0.1681 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9030 - dense_3_acc_6: 0.2460 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4091 - dense_3_acc_9: 0.16 - ETA: 6s - loss: 9.3898 - dense_3_loss: 2.2404 - dense_3_acc: 0.9641 - dense_3_acc_1: 0.9650 - dense_3_acc_2: 0.5423 - dense_3_acc_3: 0.1686 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9043 - dense_3_acc_6: 0.2480 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4093 - dense_3_acc_9: 0.16 - ETA: 6s - loss: 9.3786 - dense_3_loss: 2.2388 - dense_3_acc: 0.9644 - dense_3_acc_1: 0.9653 - dense_3_acc_2: 0.5436 - dense_3_acc_3: 0.1682 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9049 - dense_3_acc_6: 0.2480 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4104 - dense_3_acc_9: 0.16 - ETA: 6s - loss: 9.3690 - dense_3_loss: 2.2376 - dense_3_acc: 0.9641 - dense_3_acc_1: 0.9648 - dense_3_acc_2: 0.5426 - dense_3_acc_3: 0.1685 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9054 - dense_3_acc_6: 0.2489 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4091 - dense_3_acc_9: 0.16 - ETA: 6s - loss: 9.3640 - dense_3_loss: 2.2378 - dense_3_acc: 0.9643 - dense_3_acc_1: 0.9649 - dense_3_acc_2: 0.5436 - dense_3_acc_3: 0.1670 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9045 - dense_3_acc_6: 0.2515 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4087 - dense_3_acc_9: 0.16 - ETA: 6s - loss: 9.3588 - dense_3_loss: 2.2375 - dense_3_acc: 0.9638 - dense_3_acc_1: 0.9640 - dense_3_acc_2: 0.5435 - dense_3_acc_3: 0.1681 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9050 - dense_3_acc_6: 0.2517 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4115 - dense_3_acc_9: 0.16 - ETA: 6s - loss: 9.3508 - dense_3_loss: 2.2372 - dense_3_acc: 0.9637 - dense_3_acc_1: 0.9641 - dense_3_acc_2: 0.5457 - dense_3_acc_3: 0.1686 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9059 - dense_3_acc_6: 0.2539 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4096 - dense_3_acc_9: 0.16 - ETA: 6s - loss: 9.3422 - dense_3_loss: 2.2366 - dense_3_acc: 0.9638 - dense_3_acc_1: 0.9640 - dense_3_acc_2: 0.5476 - dense_3_acc_3: 0.1700 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9070 - dense_3_acc_6: 0.2532 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4104 - dense_3_acc_9: 0.16 - ETA: 5s - loss: 9.3360 - dense_3_loss: 2.2358 - dense_3_acc: 0.9637 - dense_3_acc_1: 0.9641 - dense_3_acc_2: 0.5486 - dense_3_acc_3: 0.1702 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9075 - dense_3_acc_6: 0.2543 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4092 - dense_3_acc_9: 0.16 - ETA: 5s - loss: 9.3244 - dense_3_loss: 2.2351 - dense_3_acc: 0.9640 - dense_3_acc_1: 0.9644 - dense_3_acc_2: 0.5492 - dense_3_acc_3: 0.1715 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9077 - dense_3_acc_6: 0.2552 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4088 - dense_3_acc_9: 0.16 - ETA: 5s - loss: 9.3153 - dense_3_loss: 2.2357 - dense_3_acc: 0.9642 - dense_3_acc_1: 0.9645 - dense_3_acc_2: 0.5494 - dense_3_acc_3: 0.1738 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9085 - dense_3_acc_6: 0.2549 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4104 - dense_3_acc_9: 0.16 - ETA: 5s - loss: 9.3077 - dense_3_loss: 2.2357 - dense_3_acc: 0.9641 - dense_3_acc_1: 0.9644 - dense_3_acc_2: 0.5507 - dense_3_acc_3: 0.1743 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9094 - dense_3_acc_6: 0.2546 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4098 - dense_3_acc_9: 0.16 - ETA: 5s - loss: 9.2964 - dense_3_loss: 2.2349 - dense_3_acc: 0.9644 - dense_3_acc_1: 0.9645 - dense_3_acc_2: 0.5522 - dense_3_acc_3: 0.1755 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9096 - dense_3_acc_6: 0.2540 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4095 - dense_3_acc_9: 0.16 - ETA: 5s - loss: 9.2895 - dense_3_loss: 2.2333 - dense_3_acc: 0.9638 - dense_3_acc_1: 0.9638 - dense_3_acc_2: 0.5518 - dense_3_acc_3: 0.1768 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9100 - dense_3_acc_6: 0.2543 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4120 - dense_3_acc_9: 0.16 - ETA: 5s - loss: 9.2818 - dense_3_loss: 2.2340 - dense_3_acc: 0.9639 - dense_3_acc_1: 0.9637 - dense_3_acc_2: 0.5525 - dense_3_acc_3: 0.1772 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9112 - dense_3_acc_6: 0.2577 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4116 - dense_3_acc_9: 0.16 - ETA: 5s - loss: 9.2770 - dense_3_loss: 2.2331 - dense_3_acc: 0.9643 - dense_3_acc_1: 0.9641 - dense_3_acc_2: 0.5510 - dense_3_acc_3: 0.1778 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9107 - dense_3_acc_6: 0.2586 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4110 - dense_3_acc_9: 0.1693"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8700/10000 [=========================>....] - ETA: 4s - loss: 9.2680 - dense_3_loss: 2.2331 - dense_3_acc: 0.9647 - dense_3_acc_1: 0.9646 - dense_3_acc_2: 0.5519 - dense_3_acc_3: 0.1788 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9107 - dense_3_acc_6: 0.2581 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4114 - dense_3_acc_9: 0.16 - ETA: 4s - loss: 9.2579 - dense_3_loss: 2.2307 - dense_3_acc: 0.9648 - dense_3_acc_1: 0.9647 - dense_3_acc_2: 0.5532 - dense_3_acc_3: 0.1788 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9113 - dense_3_acc_6: 0.2597 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4100 - dense_3_acc_9: 0.17 - ETA: 4s - loss: 9.2570 - dense_3_loss: 2.2304 - dense_3_acc: 0.9641 - dense_3_acc_1: 0.9638 - dense_3_acc_2: 0.5525 - dense_3_acc_3: 0.1800 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9115 - dense_3_acc_6: 0.2602 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4095 - dense_3_acc_9: 0.17 - ETA: 4s - loss: 9.2500 - dense_3_loss: 2.2306 - dense_3_acc: 0.9644 - dense_3_acc_1: 0.9640 - dense_3_acc_2: 0.5532 - dense_3_acc_3: 0.1806 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9121 - dense_3_acc_6: 0.2619 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4098 - dense_3_acc_9: 0.17 - ETA: 4s - loss: 9.2416 - dense_3_loss: 2.2300 - dense_3_acc: 0.9649 - dense_3_acc_1: 0.9646 - dense_3_acc_2: 0.5548 - dense_3_acc_3: 0.1811 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9125 - dense_3_acc_6: 0.2643 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4105 - dense_3_acc_9: 0.17 - ETA: 4s - loss: 9.2339 - dense_3_loss: 2.2295 - dense_3_acc: 0.9650 - dense_3_acc_1: 0.9647 - dense_3_acc_2: 0.5553 - dense_3_acc_3: 0.1809 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9131 - dense_3_acc_6: 0.2652 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4108 - dense_3_acc_9: 0.17 - ETA: 4s - loss: 9.2289 - dense_3_loss: 2.2296 - dense_3_acc: 0.9648 - dense_3_acc_1: 0.9646 - dense_3_acc_2: 0.5558 - dense_3_acc_3: 0.1809 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9134 - dense_3_acc_6: 0.2655 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4114 - dense_3_acc_9: 0.17 - ETA: 4s - loss: 9.2178 - dense_3_loss: 2.2304 - dense_3_acc: 0.9645 - dense_3_acc_1: 0.9648 - dense_3_acc_2: 0.5567 - dense_3_acc_3: 0.1818 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9136 - dense_3_acc_6: 0.2676 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4123 - dense_3_acc_9: 0.17 - ETA: 4s - loss: 9.2134 - dense_3_loss: 2.2301 - dense_3_acc: 0.9645 - dense_3_acc_1: 0.9648 - dense_3_acc_2: 0.5572 - dense_3_acc_3: 0.1810 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9140 - dense_3_acc_6: 0.2675 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4124 - dense_3_acc_9: 0.17 - ETA: 3s - loss: 9.2138 - dense_3_loss: 2.2310 - dense_3_acc: 0.9643 - dense_3_acc_1: 0.9644 - dense_3_acc_2: 0.5578 - dense_3_acc_3: 0.1819 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9137 - dense_3_acc_6: 0.2666 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4115 - dense_3_acc_9: 0.16 - ETA: 3s - loss: 9.2119 - dense_3_loss: 2.2305 - dense_3_acc: 0.9638 - dense_3_acc_1: 0.9639 - dense_3_acc_2: 0.5580 - dense_3_acc_3: 0.1823 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9139 - dense_3_acc_6: 0.2687 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4122 - dense_3_acc_9: 0.16 - ETA: 3s - loss: 9.2070 - dense_3_loss: 2.2316 - dense_3_acc: 0.9640 - dense_3_acc_1: 0.9640 - dense_3_acc_2: 0.5589 - dense_3_acc_3: 0.1831 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9134 - dense_3_acc_6: 0.2693 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4130 - dense_3_acc_9: 0.16 - ETA: 3s - loss: 9.1983 - dense_3_loss: 2.2316 - dense_3_acc: 0.9641 - dense_3_acc_1: 0.9641 - dense_3_acc_2: 0.5601 - dense_3_acc_3: 0.1845 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9138 - dense_3_acc_6: 0.2701 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4131 - dense_3_acc_9: 0.16 - ETA: 3s - loss: 9.1912 - dense_3_loss: 2.2317 - dense_3_acc: 0.9644 - dense_3_acc_1: 0.9644 - dense_3_acc_2: 0.5615 - dense_3_acc_3: 0.1849 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9144 - dense_3_acc_6: 0.2704 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4125 - dense_3_acc_9: 0.16 - ETA: 3s - loss: 9.1881 - dense_3_loss: 2.2317 - dense_3_acc: 0.9645 - dense_3_acc_1: 0.9644 - dense_3_acc_2: 0.5610 - dense_3_acc_3: 0.1845 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9147 - dense_3_acc_6: 0.2712 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4129 - dense_3_acc_9: 0.16 - ETA: 3s - loss: 9.1830 - dense_3_loss: 2.2304 - dense_3_acc: 0.9645 - dense_3_acc_1: 0.9643 - dense_3_acc_2: 0.5623 - dense_3_acc_3: 0.1845 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9146 - dense_3_acc_6: 0.2715 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4132 - dense_3_acc_9: 0.16 - ETA: 3s - loss: 9.1786 - dense_3_loss: 2.2304 - dense_3_acc: 0.9640 - dense_3_acc_1: 0.9640 - dense_3_acc_2: 0.5620 - dense_3_acc_3: 0.1860 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9141 - dense_3_acc_6: 0.2732 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4131 - dense_3_acc_9: 0.16 - ETA: 2s - loss: 9.1712 - dense_3_loss: 2.2305 - dense_3_acc: 0.9641 - dense_3_acc_1: 0.9641 - dense_3_acc_2: 0.5622 - dense_3_acc_3: 0.1882 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9146 - dense_3_acc_6: 0.2736 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4133 - dense_3_acc_9: 0.16 - ETA: 2s - loss: 9.1641 - dense_3_loss: 2.2301 - dense_3_acc: 0.9640 - dense_3_acc_1: 0.9640 - dense_3_acc_2: 0.5630 - dense_3_acc_3: 0.1884 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9155 - dense_3_acc_6: 0.2735 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4136 - dense_3_acc_9: 0.16 - ETA: 2s - loss: 9.1583 - dense_3_loss: 2.2297 - dense_3_acc: 0.9640 - dense_3_acc_1: 0.9638 - dense_3_acc_2: 0.5633 - dense_3_acc_3: 0.1887 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9154 - dense_3_acc_6: 0.2737 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4146 - dense_3_acc_9: 0.16 - ETA: 2s - loss: 9.1509 - dense_3_loss: 2.2295 - dense_3_acc: 0.9642 - dense_3_acc_1: 0.9642 - dense_3_acc_2: 0.5639 - dense_3_acc_3: 0.1894 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9149 - dense_3_acc_6: 0.2742 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4144 - dense_3_acc_9: 0.16 - ETA: 2s - loss: 9.1460 - dense_3_loss: 2.2295 - dense_3_acc: 0.9641 - dense_3_acc_1: 0.9641 - dense_3_acc_2: 0.5645 - dense_3_acc_3: 0.1902 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9153 - dense_3_acc_6: 0.2750 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4145 - dense_3_acc_9: 0.16 - ETA: 2s - loss: 9.1387 - dense_3_loss: 2.2293 - dense_3_acc: 0.9641 - dense_3_acc_1: 0.9641 - dense_3_acc_2: 0.5652 - dense_3_acc_3: 0.1909 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9163 - dense_3_acc_6: 0.2765 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4137 - dense_3_acc_9: 0.16 - ETA: 2s - loss: 9.1329 - dense_3_loss: 2.2289 - dense_3_acc: 0.9638 - dense_3_acc_1: 0.9639 - dense_3_acc_2: 0.5666 - dense_3_acc_3: 0.1921 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9163 - dense_3_acc_6: 0.2771 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4137 - dense_3_acc_9: 0.16 - ETA: 2s - loss: 9.1258 - dense_3_loss: 2.2283 - dense_3_acc: 0.9641 - dense_3_acc_1: 0.9641 - dense_3_acc_2: 0.5673 - dense_3_acc_3: 0.1923 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9171 - dense_3_acc_6: 0.2772 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4141 - dense_3_acc_9: 0.16 - ETA: 1s - loss: 9.1183 - dense_3_loss: 2.2273 - dense_3_acc: 0.9642 - dense_3_acc_1: 0.9638 - dense_3_acc_2: 0.5679 - dense_3_acc_3: 0.1930 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9170 - dense_3_acc_6: 0.2777 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4157 - dense_3_acc_9: 0.16 - ETA: 1s - loss: 9.1107 - dense_3_loss: 2.2267 - dense_3_acc: 0.9645 - dense_3_acc_1: 0.9641 - dense_3_acc_2: 0.5689 - dense_3_acc_3: 0.1934 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9175 - dense_3_acc_6: 0.2778 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4162 - dense_3_acc_9: 0.16 - ETA: 1s - loss: 9.1047 - dense_3_loss: 2.2263 - dense_3_acc: 0.9648 - dense_3_acc_1: 0.9644 - dense_3_acc_2: 0.5706 - dense_3_acc_3: 0.1930 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9178 - dense_3_acc_6: 0.2769 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4160 - dense_3_acc_9: 0.16 - ETA: 1s - loss: 9.0964 - dense_3_loss: 2.2267 - dense_3_acc: 0.9651 - dense_3_acc_1: 0.9647 - dense_3_acc_2: 0.5717 - dense_3_acc_3: 0.1938 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9180 - dense_3_acc_6: 0.2775 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4156 - dense_3_acc_9: 0.1667"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - ETA: 1s - loss: 9.0905 - dense_3_loss: 2.2259 - dense_3_acc: 0.9650 - dense_3_acc_1: 0.9648 - dense_3_acc_2: 0.5726 - dense_3_acc_3: 0.1940 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9185 - dense_3_acc_6: 0.2787 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4152 - dense_3_acc_9: 0.16 - ETA: 1s - loss: 9.0843 - dense_3_loss: 2.2253 - dense_3_acc: 0.9647 - dense_3_acc_1: 0.9645 - dense_3_acc_2: 0.5726 - dense_3_acc_3: 0.1951 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9190 - dense_3_acc_6: 0.2796 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4149 - dense_3_acc_9: 0.16 - ETA: 1s - loss: 9.0781 - dense_3_loss: 2.2255 - dense_3_acc: 0.9651 - dense_3_acc_1: 0.9649 - dense_3_acc_2: 0.5731 - dense_3_acc_3: 0.1956 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9194 - dense_3_acc_6: 0.2801 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4149 - dense_3_acc_9: 0.16 - ETA: 1s - loss: 9.0737 - dense_3_loss: 2.2246 - dense_3_acc: 0.9646 - dense_3_acc_1: 0.9645 - dense_3_acc_2: 0.5726 - dense_3_acc_3: 0.1962 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9199 - dense_3_acc_6: 0.2808 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4154 - dense_3_acc_9: 0.16 - ETA: 0s - loss: 9.0667 - dense_3_loss: 2.2242 - dense_3_acc: 0.9646 - dense_3_acc_1: 0.9645 - dense_3_acc_2: 0.5735 - dense_3_acc_3: 0.1964 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9201 - dense_3_acc_6: 0.2814 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4155 - dense_3_acc_9: 0.16 - ETA: 0s - loss: 9.0612 - dense_3_loss: 2.2238 - dense_3_acc: 0.9648 - dense_3_acc_1: 0.9646 - dense_3_acc_2: 0.5749 - dense_3_acc_3: 0.1977 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9199 - dense_3_acc_6: 0.2818 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4148 - dense_3_acc_9: 0.16 - ETA: 0s - loss: 9.0560 - dense_3_loss: 2.2234 - dense_3_acc: 0.9648 - dense_3_acc_1: 0.9647 - dense_3_acc_2: 0.5761 - dense_3_acc_3: 0.1990 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9203 - dense_3_acc_6: 0.2819 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4137 - dense_3_acc_9: 0.16 - ETA: 0s - loss: 9.0507 - dense_3_loss: 2.2230 - dense_3_acc: 0.9646 - dense_3_acc_1: 0.9645 - dense_3_acc_2: 0.5771 - dense_3_acc_3: 0.1992 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9204 - dense_3_acc_6: 0.2821 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4139 - dense_3_acc_9: 0.16 - ETA: 0s - loss: 9.0437 - dense_3_loss: 2.2229 - dense_3_acc: 0.9649 - dense_3_acc_1: 0.9648 - dense_3_acc_2: 0.5769 - dense_3_acc_3: 0.2000 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9206 - dense_3_acc_6: 0.2830 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4142 - dense_3_acc_9: 0.16 - ETA: 0s - loss: 9.0390 - dense_3_loss: 2.2228 - dense_3_acc: 0.9648 - dense_3_acc_1: 0.9649 - dense_3_acc_2: 0.5778 - dense_3_acc_3: 0.2001 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9209 - dense_3_acc_6: 0.2838 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4145 - dense_3_acc_9: 0.16 - ETA: 0s - loss: 9.0335 - dense_3_loss: 2.2225 - dense_3_acc: 0.9648 - dense_3_acc_1: 0.9649 - dense_3_acc_2: 0.5785 - dense_3_acc_3: 0.2008 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9212 - dense_3_acc_6: 0.2843 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4151 - dense_3_acc_9: 0.16 - ETA: 0s - loss: 9.0263 - dense_3_loss: 2.2223 - dense_3_acc: 0.9651 - dense_3_acc_1: 0.9652 - dense_3_acc_2: 0.5796 - dense_3_acc_3: 0.2012 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9215 - dense_3_acc_6: 0.2846 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4151 - dense_3_acc_9: 0.16 - 12s 1ms/step - loss: 9.0224 - dense_3_loss: 2.2216 - dense_3_acc: 0.9649 - dense_3_acc_1: 0.9649 - dense_3_acc_2: 0.5806 - dense_3_acc_3: 0.2018 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9213 - dense_3_acc_6: 0.2850 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4151 - dense_3_acc_9: 0.1699\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2900/10000 [=======>......................] - ETA: 11s - loss: 8.2050 - dense_3_loss: 2.1349 - dense_3_acc: 1.0000 - dense_3_acc_1: 1.0000 - dense_3_acc_2: 0.7000 - dense_3_acc_3: 0.3200 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9300 - dense_3_acc_6: 0.2600 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.3600 - dense_3_acc_9: 0.200 - ETA: 11s - loss: 8.2870 - dense_3_loss: 2.1621 - dense_3_acc: 0.9800 - dense_3_acc_1: 0.9850 - dense_3_acc_2: 0.6750 - dense_3_acc_3: 0.2650 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9250 - dense_3_acc_6: 0.3200 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.3750 - dense_3_acc_9: 0.155 - ETA: 11s - loss: 8.4187 - dense_3_loss: 2.1548 - dense_3_acc: 0.9600 - dense_3_acc_1: 0.9633 - dense_3_acc_2: 0.6900 - dense_3_acc_3: 0.2333 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9300 - dense_3_acc_6: 0.3433 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.3900 - dense_3_acc_9: 0.176 - ETA: 11s - loss: 8.3570 - dense_3_loss: 2.1561 - dense_3_acc: 0.9675 - dense_3_acc_1: 0.9675 - dense_3_acc_2: 0.6675 - dense_3_acc_3: 0.2500 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9375 - dense_3_acc_6: 0.3575 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.3975 - dense_3_acc_9: 0.197 - ETA: 11s - loss: 8.3590 - dense_3_loss: 2.1659 - dense_3_acc: 0.9700 - dense_3_acc_1: 0.9700 - dense_3_acc_2: 0.6540 - dense_3_acc_3: 0.2480 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9400 - dense_3_acc_6: 0.3440 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.3900 - dense_3_acc_9: 0.194 - ETA: 11s - loss: 8.3510 - dense_3_loss: 2.1700 - dense_3_acc: 0.9717 - dense_3_acc_1: 0.9717 - dense_3_acc_2: 0.6667 - dense_3_acc_3: 0.2450 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9450 - dense_3_acc_6: 0.3367 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4033 - dense_3_acc_9: 0.191 - ETA: 11s - loss: 8.3644 - dense_3_loss: 2.1797 - dense_3_acc: 0.9743 - dense_3_acc_1: 0.9743 - dense_3_acc_2: 0.6700 - dense_3_acc_3: 0.2443 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9429 - dense_3_acc_6: 0.3314 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4057 - dense_3_acc_9: 0.182 - ETA: 10s - loss: 8.3642 - dense_3_loss: 2.1783 - dense_3_acc: 0.9738 - dense_3_acc_1: 0.9713 - dense_3_acc_2: 0.6675 - dense_3_acc_3: 0.2412 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9488 - dense_3_acc_6: 0.3275 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4150 - dense_3_acc_9: 0.187 - ETA: 10s - loss: 8.3821 - dense_3_loss: 2.1776 - dense_3_acc: 0.9711 - dense_3_acc_1: 0.9700 - dense_3_acc_2: 0.6711 - dense_3_acc_3: 0.2456 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9433 - dense_3_acc_6: 0.3311 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4100 - dense_3_acc_9: 0.183 - ETA: 10s - loss: 8.3762 - dense_3_loss: 2.1754 - dense_3_acc: 0.9720 - dense_3_acc_1: 0.9720 - dense_3_acc_2: 0.6740 - dense_3_acc_3: 0.2500 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9410 - dense_3_acc_6: 0.3310 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4170 - dense_3_acc_9: 0.188 - ETA: 10s - loss: 8.3793 - dense_3_loss: 2.1729 - dense_3_acc: 0.9718 - dense_3_acc_1: 0.9718 - dense_3_acc_2: 0.6745 - dense_3_acc_3: 0.2436 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9391 - dense_3_acc_6: 0.3400 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4218 - dense_3_acc_9: 0.190 - ETA: 10s - loss: 8.3756 - dense_3_loss: 2.1732 - dense_3_acc: 0.9717 - dense_3_acc_1: 0.9717 - dense_3_acc_2: 0.6750 - dense_3_acc_3: 0.2475 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9392 - dense_3_acc_6: 0.3383 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4267 - dense_3_acc_9: 0.193 - ETA: 10s - loss: 8.3499 - dense_3_loss: 2.1748 - dense_3_acc: 0.9731 - dense_3_acc_1: 0.9731 - dense_3_acc_2: 0.6762 - dense_3_acc_3: 0.2462 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9392 - dense_3_acc_6: 0.3392 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4308 - dense_3_acc_9: 0.187 - ETA: 10s - loss: 8.3635 - dense_3_loss: 2.1720 - dense_3_acc: 0.9700 - dense_3_acc_1: 0.9693 - dense_3_acc_2: 0.6757 - dense_3_acc_3: 0.2471 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9386 - dense_3_acc_6: 0.3407 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4329 - dense_3_acc_9: 0.190 - ETA: 10s - loss: 8.3670 - dense_3_loss: 2.1718 - dense_3_acc: 0.9687 - dense_3_acc_1: 0.9687 - dense_3_acc_2: 0.6793 - dense_3_acc_3: 0.2513 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9407 - dense_3_acc_6: 0.3400 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4313 - dense_3_acc_9: 0.188 - ETA: 10s - loss: 8.3555 - dense_3_loss: 2.1655 - dense_3_acc: 0.9694 - dense_3_acc_1: 0.9694 - dense_3_acc_2: 0.6763 - dense_3_acc_3: 0.2500 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9419 - dense_3_acc_6: 0.3419 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4256 - dense_3_acc_9: 0.190 - ETA: 10s - loss: 8.3518 - dense_3_loss: 2.1614 - dense_3_acc: 0.9700 - dense_3_acc_1: 0.9700 - dense_3_acc_2: 0.6771 - dense_3_acc_3: 0.2518 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9400 - dense_3_acc_6: 0.3382 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4229 - dense_3_acc_9: 0.191 - ETA: 9s - loss: 8.3572 - dense_3_loss: 2.1633 - dense_3_acc: 0.9683 - dense_3_acc_1: 0.9689 - dense_3_acc_2: 0.6739 - dense_3_acc_3: 0.2500 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9417 - dense_3_acc_6: 0.3378 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4222 - dense_3_acc_9: 0.190 - ETA: 9s - loss: 8.3573 - dense_3_loss: 2.1604 - dense_3_acc: 0.9679 - dense_3_acc_1: 0.9689 - dense_3_acc_2: 0.6711 - dense_3_acc_3: 0.2484 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9437 - dense_3_acc_6: 0.3389 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4274 - dense_3_acc_9: 0.19 - ETA: 9s - loss: 8.3439 - dense_3_loss: 2.1586 - dense_3_acc: 0.9685 - dense_3_acc_1: 0.9695 - dense_3_acc_2: 0.6700 - dense_3_acc_3: 0.2550 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9445 - dense_3_acc_6: 0.3405 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4280 - dense_3_acc_9: 0.19 - ETA: 9s - loss: 8.3360 - dense_3_loss: 2.1581 - dense_3_acc: 0.9690 - dense_3_acc_1: 0.9700 - dense_3_acc_2: 0.6676 - dense_3_acc_3: 0.2586 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9457 - dense_3_acc_6: 0.3386 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4290 - dense_3_acc_9: 0.19 - ETA: 9s - loss: 8.3352 - dense_3_loss: 2.1604 - dense_3_acc: 0.9691 - dense_3_acc_1: 0.9691 - dense_3_acc_2: 0.6673 - dense_3_acc_3: 0.2618 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9455 - dense_3_acc_6: 0.3441 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4277 - dense_3_acc_9: 0.19 - ETA: 9s - loss: 8.3247 - dense_3_loss: 2.1568 - dense_3_acc: 0.9691 - dense_3_acc_1: 0.9691 - dense_3_acc_2: 0.6674 - dense_3_acc_3: 0.2639 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9430 - dense_3_acc_6: 0.3478 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4274 - dense_3_acc_9: 0.19 - ETA: 9s - loss: 8.3177 - dense_3_loss: 2.1558 - dense_3_acc: 0.9692 - dense_3_acc_1: 0.9696 - dense_3_acc_2: 0.6704 - dense_3_acc_3: 0.2629 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9442 - dense_3_acc_6: 0.3467 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4275 - dense_3_acc_9: 0.19 - ETA: 9s - loss: 8.3246 - dense_3_loss: 2.1546 - dense_3_acc: 0.9692 - dense_3_acc_1: 0.9692 - dense_3_acc_2: 0.6684 - dense_3_acc_3: 0.2644 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9440 - dense_3_acc_6: 0.3456 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4264 - dense_3_acc_9: 0.19 - ETA: 9s - loss: 8.3159 - dense_3_loss: 2.1543 - dense_3_acc: 0.9696 - dense_3_acc_1: 0.9696 - dense_3_acc_2: 0.6688 - dense_3_acc_3: 0.2669 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9446 - dense_3_acc_6: 0.3488 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4258 - dense_3_acc_9: 0.20 - ETA: 8s - loss: 8.3106 - dense_3_loss: 2.1544 - dense_3_acc: 0.9704 - dense_3_acc_1: 0.9700 - dense_3_acc_2: 0.6689 - dense_3_acc_3: 0.2700 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9459 - dense_3_acc_6: 0.3507 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4259 - dense_3_acc_9: 0.20 - ETA: 8s - loss: 8.3016 - dense_3_loss: 2.1514 - dense_3_acc: 0.9707 - dense_3_acc_1: 0.9700 - dense_3_acc_2: 0.6696 - dense_3_acc_3: 0.2746 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9457 - dense_3_acc_6: 0.3518 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4246 - dense_3_acc_9: 0.20 - ETA: 8s - loss: 8.3002 - dense_3_loss: 2.1516 - dense_3_acc: 0.9707 - dense_3_acc_1: 0.9700 - dense_3_acc_2: 0.6686 - dense_3_acc_3: 0.2738 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9462 - dense_3_acc_6: 0.3497 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4248 - dense_3_acc_9: 0.2028"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5800/10000 [================>.............] - ETA: 8s - loss: 8.2978 - dense_3_loss: 2.1536 - dense_3_acc: 0.9710 - dense_3_acc_1: 0.9703 - dense_3_acc_2: 0.6683 - dense_3_acc_3: 0.2733 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9463 - dense_3_acc_6: 0.3470 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4247 - dense_3_acc_9: 0.20 - ETA: 8s - loss: 8.2939 - dense_3_loss: 2.1522 - dense_3_acc: 0.9706 - dense_3_acc_1: 0.9700 - dense_3_acc_2: 0.6645 - dense_3_acc_3: 0.2723 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9468 - dense_3_acc_6: 0.3487 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4248 - dense_3_acc_9: 0.20 - ETA: 8s - loss: 8.2807 - dense_3_loss: 2.1494 - dense_3_acc: 0.9716 - dense_3_acc_1: 0.9709 - dense_3_acc_2: 0.6647 - dense_3_acc_3: 0.2728 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9475 - dense_3_acc_6: 0.3497 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4253 - dense_3_acc_9: 0.20 - ETA: 8s - loss: 8.2830 - dense_3_loss: 2.1474 - dense_3_acc: 0.9715 - dense_3_acc_1: 0.9709 - dense_3_acc_2: 0.6661 - dense_3_acc_3: 0.2712 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9476 - dense_3_acc_6: 0.3491 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4255 - dense_3_acc_9: 0.20 - ETA: 8s - loss: 8.2797 - dense_3_loss: 2.1490 - dense_3_acc: 0.9715 - dense_3_acc_1: 0.9706 - dense_3_acc_2: 0.6656 - dense_3_acc_3: 0.2706 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9479 - dense_3_acc_6: 0.3503 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4282 - dense_3_acc_9: 0.20 - ETA: 7s - loss: 8.2708 - dense_3_loss: 2.1479 - dense_3_acc: 0.9720 - dense_3_acc_1: 0.9709 - dense_3_acc_2: 0.6666 - dense_3_acc_3: 0.2703 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9469 - dense_3_acc_6: 0.3529 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4317 - dense_3_acc_9: 0.20 - ETA: 7s - loss: 8.2655 - dense_3_loss: 2.1480 - dense_3_acc: 0.9722 - dense_3_acc_1: 0.9711 - dense_3_acc_2: 0.6667 - dense_3_acc_3: 0.2700 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9475 - dense_3_acc_6: 0.3514 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4325 - dense_3_acc_9: 0.20 - ETA: 7s - loss: 8.2635 - dense_3_loss: 2.1473 - dense_3_acc: 0.9722 - dense_3_acc_1: 0.9708 - dense_3_acc_2: 0.6659 - dense_3_acc_3: 0.2700 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9468 - dense_3_acc_6: 0.3519 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4330 - dense_3_acc_9: 0.20 - ETA: 7s - loss: 8.2571 - dense_3_loss: 2.1467 - dense_3_acc: 0.9724 - dense_3_acc_1: 0.9713 - dense_3_acc_2: 0.6655 - dense_3_acc_3: 0.2700 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9476 - dense_3_acc_6: 0.3516 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4342 - dense_3_acc_9: 0.20 - ETA: 7s - loss: 8.2519 - dense_3_loss: 2.1455 - dense_3_acc: 0.9718 - dense_3_acc_1: 0.9708 - dense_3_acc_2: 0.6664 - dense_3_acc_3: 0.2695 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9479 - dense_3_acc_6: 0.3541 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4349 - dense_3_acc_9: 0.20 - ETA: 7s - loss: 8.2493 - dense_3_loss: 2.1451 - dense_3_acc: 0.9715 - dense_3_acc_1: 0.9710 - dense_3_acc_2: 0.6670 - dense_3_acc_3: 0.2703 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9470 - dense_3_acc_6: 0.3560 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4352 - dense_3_acc_9: 0.20 - ETA: 7s - loss: 8.2408 - dense_3_loss: 2.1429 - dense_3_acc: 0.9720 - dense_3_acc_1: 0.9712 - dense_3_acc_2: 0.6668 - dense_3_acc_3: 0.2712 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9473 - dense_3_acc_6: 0.3578 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4354 - dense_3_acc_9: 0.20 - ETA: 7s - loss: 8.2380 - dense_3_loss: 2.1431 - dense_3_acc: 0.9726 - dense_3_acc_1: 0.9719 - dense_3_acc_2: 0.6674 - dense_3_acc_3: 0.2714 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9471 - dense_3_acc_6: 0.3598 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4336 - dense_3_acc_9: 0.20 - ETA: 7s - loss: 8.2385 - dense_3_loss: 2.1419 - dense_3_acc: 0.9728 - dense_3_acc_1: 0.9721 - dense_3_acc_2: 0.6693 - dense_3_acc_3: 0.2700 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9472 - dense_3_acc_6: 0.3579 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4335 - dense_3_acc_9: 0.20 - ETA: 6s - loss: 8.2345 - dense_3_loss: 2.1421 - dense_3_acc: 0.9723 - dense_3_acc_1: 0.9718 - dense_3_acc_2: 0.6700 - dense_3_acc_3: 0.2700 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9468 - dense_3_acc_6: 0.3582 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4350 - dense_3_acc_9: 0.20 - ETA: 6s - loss: 8.2308 - dense_3_loss: 2.1427 - dense_3_acc: 0.9722 - dense_3_acc_1: 0.9718 - dense_3_acc_2: 0.6718 - dense_3_acc_3: 0.2718 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9464 - dense_3_acc_6: 0.3593 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4369 - dense_3_acc_9: 0.20 - ETA: 6s - loss: 8.2328 - dense_3_loss: 2.1429 - dense_3_acc: 0.9720 - dense_3_acc_1: 0.9715 - dense_3_acc_2: 0.6722 - dense_3_acc_3: 0.2711 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9470 - dense_3_acc_6: 0.3585 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4357 - dense_3_acc_9: 0.20 - ETA: 6s - loss: 8.2346 - dense_3_loss: 2.1435 - dense_3_acc: 0.9715 - dense_3_acc_1: 0.9711 - dense_3_acc_2: 0.6721 - dense_3_acc_3: 0.2706 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9477 - dense_3_acc_6: 0.3587 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4351 - dense_3_acc_9: 0.20 - ETA: 6s - loss: 8.2257 - dense_3_loss: 2.1441 - dense_3_acc: 0.9719 - dense_3_acc_1: 0.9715 - dense_3_acc_2: 0.6723 - dense_3_acc_3: 0.2713 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9477 - dense_3_acc_6: 0.3617 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4369 - dense_3_acc_9: 0.20 - ETA: 6s - loss: 8.2295 - dense_3_loss: 2.1436 - dense_3_acc: 0.9716 - dense_3_acc_1: 0.9712 - dense_3_acc_2: 0.6724 - dense_3_acc_3: 0.2720 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9473 - dense_3_acc_6: 0.3602 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4365 - dense_3_acc_9: 0.20 - ETA: 6s - loss: 8.2224 - dense_3_loss: 2.1428 - dense_3_acc: 0.9718 - dense_3_acc_1: 0.9716 - dense_3_acc_2: 0.6740 - dense_3_acc_3: 0.2726 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9480 - dense_3_acc_6: 0.3588 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4370 - dense_3_acc_9: 0.20 - ETA: 6s - loss: 8.2230 - dense_3_loss: 2.1412 - dense_3_acc: 0.9712 - dense_3_acc_1: 0.9710 - dense_3_acc_2: 0.6737 - dense_3_acc_3: 0.2747 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9482 - dense_3_acc_6: 0.3590 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4376 - dense_3_acc_9: 0.20 - ETA: 5s - loss: 8.2174 - dense_3_loss: 2.1407 - dense_3_acc: 0.9712 - dense_3_acc_1: 0.9710 - dense_3_acc_2: 0.6742 - dense_3_acc_3: 0.2756 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9481 - dense_3_acc_6: 0.3610 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4369 - dense_3_acc_9: 0.20 - ETA: 5s - loss: 8.2061 - dense_3_loss: 2.1394 - dense_3_acc: 0.9715 - dense_3_acc_1: 0.9709 - dense_3_acc_2: 0.6745 - dense_3_acc_3: 0.2772 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9491 - dense_3_acc_6: 0.3617 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4377 - dense_3_acc_9: 0.20 - ETA: 5s - loss: 8.1969 - dense_3_loss: 2.1373 - dense_3_acc: 0.9720 - dense_3_acc_1: 0.9715 - dense_3_acc_2: 0.6744 - dense_3_acc_3: 0.2783 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9493 - dense_3_acc_6: 0.3617 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4383 - dense_3_acc_9: 0.20 - ETA: 5s - loss: 8.1971 - dense_3_loss: 2.1348 - dense_3_acc: 0.9716 - dense_3_acc_1: 0.9711 - dense_3_acc_2: 0.6747 - dense_3_acc_3: 0.2778 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9496 - dense_3_acc_6: 0.3616 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4387 - dense_3_acc_9: 0.20 - ETA: 5s - loss: 8.1933 - dense_3_loss: 2.1343 - dense_3_acc: 0.9720 - dense_3_acc_1: 0.9714 - dense_3_acc_2: 0.6745 - dense_3_acc_3: 0.2784 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9498 - dense_3_acc_6: 0.3616 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4389 - dense_3_acc_9: 0.20 - ETA: 5s - loss: 8.1878 - dense_3_loss: 2.1336 - dense_3_acc: 0.9721 - dense_3_acc_1: 0.9716 - dense_3_acc_2: 0.6746 - dense_3_acc_3: 0.2779 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9502 - dense_3_acc_6: 0.3630 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4384 - dense_3_acc_9: 0.21 - ETA: 5s - loss: 8.1829 - dense_3_loss: 2.1340 - dense_3_acc: 0.9719 - dense_3_acc_1: 0.9716 - dense_3_acc_2: 0.6759 - dense_3_acc_3: 0.2776 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9505 - dense_3_acc_6: 0.3636 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4384 - dense_3_acc_9: 0.2097"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8700/10000 [=========================>....] - ETA: 5s - loss: 8.1809 - dense_3_loss: 2.1332 - dense_3_acc: 0.9720 - dense_3_acc_1: 0.9717 - dense_3_acc_2: 0.6761 - dense_3_acc_3: 0.2781 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9510 - dense_3_acc_6: 0.3624 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4380 - dense_3_acc_9: 0.21 - ETA: 4s - loss: 8.1731 - dense_3_loss: 2.1325 - dense_3_acc: 0.9725 - dense_3_acc_1: 0.9722 - dense_3_acc_2: 0.6765 - dense_3_acc_3: 0.2780 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9517 - dense_3_acc_6: 0.3630 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4397 - dense_3_acc_9: 0.21 - ETA: 4s - loss: 8.1684 - dense_3_loss: 2.1313 - dense_3_acc: 0.9725 - dense_3_acc_1: 0.9723 - dense_3_acc_2: 0.6751 - dense_3_acc_3: 0.2785 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9520 - dense_3_acc_6: 0.3630 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4408 - dense_3_acc_9: 0.21 - ETA: 4s - loss: 8.1603 - dense_3_loss: 2.1308 - dense_3_acc: 0.9727 - dense_3_acc_1: 0.9727 - dense_3_acc_2: 0.6766 - dense_3_acc_3: 0.2802 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9519 - dense_3_acc_6: 0.3635 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4410 - dense_3_acc_9: 0.21 - ETA: 4s - loss: 8.1543 - dense_3_loss: 2.1281 - dense_3_acc: 0.9730 - dense_3_acc_1: 0.9730 - dense_3_acc_2: 0.6757 - dense_3_acc_3: 0.2817 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9521 - dense_3_acc_6: 0.3644 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4403 - dense_3_acc_9: 0.21 - ETA: 4s - loss: 8.1484 - dense_3_loss: 2.1273 - dense_3_acc: 0.9733 - dense_3_acc_1: 0.9734 - dense_3_acc_2: 0.6752 - dense_3_acc_3: 0.2808 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9522 - dense_3_acc_6: 0.3659 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4400 - dense_3_acc_9: 0.21 - ETA: 4s - loss: 8.1467 - dense_3_loss: 2.1269 - dense_3_acc: 0.9731 - dense_3_acc_1: 0.9731 - dense_3_acc_2: 0.6749 - dense_3_acc_3: 0.2805 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9528 - dense_3_acc_6: 0.3669 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4408 - dense_3_acc_9: 0.21 - ETA: 4s - loss: 8.1415 - dense_3_loss: 2.1267 - dense_3_acc: 0.9727 - dense_3_acc_1: 0.9732 - dense_3_acc_2: 0.6761 - dense_3_acc_3: 0.2806 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9529 - dense_3_acc_6: 0.3673 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4411 - dense_3_acc_9: 0.21 - ETA: 4s - loss: 8.1343 - dense_3_loss: 2.1245 - dense_3_acc: 0.9730 - dense_3_acc_1: 0.9736 - dense_3_acc_2: 0.6767 - dense_3_acc_3: 0.2812 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9531 - dense_3_acc_6: 0.3681 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4403 - dense_3_acc_9: 0.22 - ETA: 3s - loss: 8.1326 - dense_3_loss: 2.1238 - dense_3_acc: 0.9726 - dense_3_acc_1: 0.9732 - dense_3_acc_2: 0.6762 - dense_3_acc_3: 0.2812 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9531 - dense_3_acc_6: 0.3685 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4412 - dense_3_acc_9: 0.22 - ETA: 3s - loss: 8.1293 - dense_3_loss: 2.1237 - dense_3_acc: 0.9726 - dense_3_acc_1: 0.9730 - dense_3_acc_2: 0.6752 - dense_3_acc_3: 0.2817 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9535 - dense_3_acc_6: 0.3691 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4412 - dense_3_acc_9: 0.21 - ETA: 3s - loss: 8.1237 - dense_3_loss: 2.1232 - dense_3_acc: 0.9726 - dense_3_acc_1: 0.9730 - dense_3_acc_2: 0.6749 - dense_3_acc_3: 0.2829 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9537 - dense_3_acc_6: 0.3697 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4426 - dense_3_acc_9: 0.21 - ETA: 3s - loss: 8.1197 - dense_3_loss: 2.1218 - dense_3_acc: 0.9724 - dense_3_acc_1: 0.9728 - dense_3_acc_2: 0.6759 - dense_3_acc_3: 0.2835 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9539 - dense_3_acc_6: 0.3692 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4437 - dense_3_acc_9: 0.21 - ETA: 3s - loss: 8.1143 - dense_3_loss: 2.1202 - dense_3_acc: 0.9721 - dense_3_acc_1: 0.9726 - dense_3_acc_2: 0.6757 - dense_3_acc_3: 0.2843 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9544 - dense_3_acc_6: 0.3686 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4446 - dense_3_acc_9: 0.22 - ETA: 3s - loss: 8.1090 - dense_3_loss: 2.1189 - dense_3_acc: 0.9721 - dense_3_acc_1: 0.9726 - dense_3_acc_2: 0.6762 - dense_3_acc_3: 0.2848 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9545 - dense_3_acc_6: 0.3686 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4462 - dense_3_acc_9: 0.22 - ETA: 3s - loss: 8.1053 - dense_3_loss: 2.1176 - dense_3_acc: 0.9722 - dense_3_acc_1: 0.9726 - dense_3_acc_2: 0.6766 - dense_3_acc_3: 0.2859 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9547 - dense_3_acc_6: 0.3681 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4465 - dense_3_acc_9: 0.22 - ETA: 3s - loss: 8.1005 - dense_3_loss: 2.1150 - dense_3_acc: 0.9721 - dense_3_acc_1: 0.9724 - dense_3_acc_2: 0.6772 - dense_3_acc_3: 0.2856 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9544 - dense_3_acc_6: 0.3695 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4465 - dense_3_acc_9: 0.22 - ETA: 2s - loss: 8.0934 - dense_3_loss: 2.1137 - dense_3_acc: 0.9724 - dense_3_acc_1: 0.9726 - dense_3_acc_2: 0.6778 - dense_3_acc_3: 0.2863 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9546 - dense_3_acc_6: 0.3693 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4474 - dense_3_acc_9: 0.22 - ETA: 2s - loss: 8.0891 - dense_3_loss: 2.1131 - dense_3_acc: 0.9727 - dense_3_acc_1: 0.9729 - dense_3_acc_2: 0.6790 - dense_3_acc_3: 0.2861 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9549 - dense_3_acc_6: 0.3699 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4468 - dense_3_acc_9: 0.22 - ETA: 2s - loss: 8.0881 - dense_3_loss: 2.1129 - dense_3_acc: 0.9727 - dense_3_acc_1: 0.9729 - dense_3_acc_2: 0.6779 - dense_3_acc_3: 0.2864 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9547 - dense_3_acc_6: 0.3709 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4468 - dense_3_acc_9: 0.22 - ETA: 2s - loss: 8.0837 - dense_3_loss: 2.1119 - dense_3_acc: 0.9727 - dense_3_acc_1: 0.9728 - dense_3_acc_2: 0.6786 - dense_3_acc_3: 0.2867 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9548 - dense_3_acc_6: 0.3704 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4472 - dense_3_acc_9: 0.22 - ETA: 2s - loss: 8.0782 - dense_3_loss: 2.1117 - dense_3_acc: 0.9728 - dense_3_acc_1: 0.9729 - dense_3_acc_2: 0.6793 - dense_3_acc_3: 0.2879 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9546 - dense_3_acc_6: 0.3695 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4487 - dense_3_acc_9: 0.22 - ETA: 2s - loss: 8.0736 - dense_3_loss: 2.1113 - dense_3_acc: 0.9726 - dense_3_acc_1: 0.9726 - dense_3_acc_2: 0.6805 - dense_3_acc_3: 0.2891 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9549 - dense_3_acc_6: 0.3691 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4479 - dense_3_acc_9: 0.22 - ETA: 2s - loss: 8.0697 - dense_3_loss: 2.1100 - dense_3_acc: 0.9728 - dense_3_acc_1: 0.9728 - dense_3_acc_2: 0.6805 - dense_3_acc_3: 0.2898 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9552 - dense_3_acc_6: 0.3699 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4483 - dense_3_acc_9: 0.22 - ETA: 2s - loss: 8.0641 - dense_3_loss: 2.1083 - dense_3_acc: 0.9729 - dense_3_acc_1: 0.9728 - dense_3_acc_2: 0.6804 - dense_3_acc_3: 0.2904 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9553 - dense_3_acc_6: 0.3704 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4492 - dense_3_acc_9: 0.22 - ETA: 1s - loss: 8.0594 - dense_3_loss: 2.1066 - dense_3_acc: 0.9727 - dense_3_acc_1: 0.9726 - dense_3_acc_2: 0.6806 - dense_3_acc_3: 0.2907 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9555 - dense_3_acc_6: 0.3718 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4482 - dense_3_acc_9: 0.22 - ETA: 1s - loss: 8.0548 - dense_3_loss: 2.1059 - dense_3_acc: 0.9727 - dense_3_acc_1: 0.9727 - dense_3_acc_2: 0.6819 - dense_3_acc_3: 0.2907 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9554 - dense_3_acc_6: 0.3720 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4478 - dense_3_acc_9: 0.22 - ETA: 1s - loss: 8.0536 - dense_3_loss: 2.1062 - dense_3_acc: 0.9727 - dense_3_acc_1: 0.9728 - dense_3_acc_2: 0.6828 - dense_3_acc_3: 0.2897 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9556 - dense_3_acc_6: 0.3723 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4476 - dense_3_acc_9: 0.22 - ETA: 1s - loss: 8.0508 - dense_3_loss: 2.1063 - dense_3_acc: 0.9729 - dense_3_acc_1: 0.9730 - dense_3_acc_2: 0.6831 - dense_3_acc_3: 0.2894 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9560 - dense_3_acc_6: 0.3729 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4470 - dense_3_acc_9: 0.2263"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - ETA: 1s - loss: 8.0487 - dense_3_loss: 2.1053 - dense_3_acc: 0.9730 - dense_3_acc_1: 0.9731 - dense_3_acc_2: 0.6832 - dense_3_acc_3: 0.2886 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9561 - dense_3_acc_6: 0.3733 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4474 - dense_3_acc_9: 0.22 - ETA: 1s - loss: 8.0452 - dense_3_loss: 2.1042 - dense_3_acc: 0.9730 - dense_3_acc_1: 0.9730 - dense_3_acc_2: 0.6834 - dense_3_acc_3: 0.2892 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9562 - dense_3_acc_6: 0.3726 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4473 - dense_3_acc_9: 0.22 - ETA: 1s - loss: 8.0404 - dense_3_loss: 2.1037 - dense_3_acc: 0.9733 - dense_3_acc_1: 0.9733 - dense_3_acc_2: 0.6838 - dense_3_acc_3: 0.2899 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9566 - dense_3_acc_6: 0.3730 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4471 - dense_3_acc_9: 0.22 - ETA: 1s - loss: 8.0380 - dense_3_loss: 2.1043 - dense_3_acc: 0.9735 - dense_3_acc_1: 0.9735 - dense_3_acc_2: 0.6838 - dense_3_acc_3: 0.2908 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9562 - dense_3_acc_6: 0.3724 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4464 - dense_3_acc_9: 0.22 - ETA: 0s - loss: 8.0356 - dense_3_loss: 2.1027 - dense_3_acc: 0.9734 - dense_3_acc_1: 0.9735 - dense_3_acc_2: 0.6838 - dense_3_acc_3: 0.2913 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9563 - dense_3_acc_6: 0.3724 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4458 - dense_3_acc_9: 0.22 - ETA: 0s - loss: 8.0294 - dense_3_loss: 2.1010 - dense_3_acc: 0.9734 - dense_3_acc_1: 0.9737 - dense_3_acc_2: 0.6833 - dense_3_acc_3: 0.2915 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9566 - dense_3_acc_6: 0.3730 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4461 - dense_3_acc_9: 0.22 - ETA: 0s - loss: 8.0247 - dense_3_loss: 2.1000 - dense_3_acc: 0.9735 - dense_3_acc_1: 0.9738 - dense_3_acc_2: 0.6835 - dense_3_acc_3: 0.2928 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9566 - dense_3_acc_6: 0.3720 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4471 - dense_3_acc_9: 0.22 - ETA: 0s - loss: 8.0211 - dense_3_loss: 2.0988 - dense_3_acc: 0.9736 - dense_3_acc_1: 0.9738 - dense_3_acc_2: 0.6835 - dense_3_acc_3: 0.2936 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9563 - dense_3_acc_6: 0.3728 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4481 - dense_3_acc_9: 0.22 - ETA: 0s - loss: 8.0137 - dense_3_loss: 2.0976 - dense_3_acc: 0.9735 - dense_3_acc_1: 0.9738 - dense_3_acc_2: 0.6828 - dense_3_acc_3: 0.2948 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9567 - dense_3_acc_6: 0.3728 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4489 - dense_3_acc_9: 0.23 - ETA: 0s - loss: 8.0100 - dense_3_loss: 2.0960 - dense_3_acc: 0.9735 - dense_3_acc_1: 0.9738 - dense_3_acc_2: 0.6842 - dense_3_acc_3: 0.2952 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9568 - dense_3_acc_6: 0.3731 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4491 - dense_3_acc_9: 0.22 - ETA: 0s - loss: 8.0098 - dense_3_loss: 2.0952 - dense_3_acc: 0.9733 - dense_3_acc_1: 0.9738 - dense_3_acc_2: 0.6843 - dense_3_acc_3: 0.2955 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9561 - dense_3_acc_6: 0.3721 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4492 - dense_3_acc_9: 0.23 - ETA: 0s - loss: 8.0070 - dense_3_loss: 2.0946 - dense_3_acc: 0.9731 - dense_3_acc_1: 0.9734 - dense_3_acc_2: 0.6842 - dense_3_acc_3: 0.2960 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9560 - dense_3_acc_6: 0.3721 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4500 - dense_3_acc_9: 0.23 - 12s 1ms/step - loss: 8.0023 - dense_3_loss: 2.0941 - dense_3_acc: 0.9732 - dense_3_acc_1: 0.9735 - dense_3_acc_2: 0.6846 - dense_3_acc_3: 0.2962 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9563 - dense_3_acc_6: 0.3723 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4506 - dense_3_acc_9: 0.2309\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2900/10000 [=======>......................] - ETA: 12s - loss: 7.3262 - dense_3_loss: 2.0194 - dense_3_acc: 0.9700 - dense_3_acc_1: 0.9900 - dense_3_acc_2: 0.7300 - dense_3_acc_3: 0.4200 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 1.0000 - dense_3_acc_6: 0.4000 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4400 - dense_3_acc_9: 0.230 - ETA: 12s - loss: 7.4660 - dense_3_loss: 1.9991 - dense_3_acc: 0.9800 - dense_3_acc_1: 0.9900 - dense_3_acc_2: 0.7350 - dense_3_acc_3: 0.3400 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9700 - dense_3_acc_6: 0.4200 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4700 - dense_3_acc_9: 0.280 - ETA: 12s - loss: 7.5139 - dense_3_loss: 2.0057 - dense_3_acc: 0.9833 - dense_3_acc_1: 0.9900 - dense_3_acc_2: 0.7200 - dense_3_acc_3: 0.3267 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9700 - dense_3_acc_6: 0.4167 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4733 - dense_3_acc_9: 0.273 - ETA: 12s - loss: 7.5658 - dense_3_loss: 1.9927 - dense_3_acc: 0.9775 - dense_3_acc_1: 0.9850 - dense_3_acc_2: 0.7175 - dense_3_acc_3: 0.3225 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9700 - dense_3_acc_6: 0.4150 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4750 - dense_3_acc_9: 0.285 - ETA: 11s - loss: 7.5529 - dense_3_loss: 1.9914 - dense_3_acc: 0.9800 - dense_3_acc_1: 0.9860 - dense_3_acc_2: 0.7040 - dense_3_acc_3: 0.3260 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9700 - dense_3_acc_6: 0.4220 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4700 - dense_3_acc_9: 0.282 - ETA: 11s - loss: 7.5569 - dense_3_loss: 1.9858 - dense_3_acc: 0.9817 - dense_3_acc_1: 0.9867 - dense_3_acc_2: 0.7017 - dense_3_acc_3: 0.3217 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9733 - dense_3_acc_6: 0.4183 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4700 - dense_3_acc_9: 0.281 - ETA: 11s - loss: 7.5518 - dense_3_loss: 1.9926 - dense_3_acc: 0.9843 - dense_3_acc_1: 0.9886 - dense_3_acc_2: 0.7100 - dense_3_acc_3: 0.3143 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9757 - dense_3_acc_6: 0.4214 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4729 - dense_3_acc_9: 0.275 - ETA: 11s - loss: 7.5675 - dense_3_loss: 1.9976 - dense_3_acc: 0.9813 - dense_3_acc_1: 0.9863 - dense_3_acc_2: 0.7075 - dense_3_acc_3: 0.3188 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9713 - dense_3_acc_6: 0.4262 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4687 - dense_3_acc_9: 0.271 - ETA: 11s - loss: 7.5956 - dense_3_loss: 2.0007 - dense_3_acc: 0.9767 - dense_3_acc_1: 0.9822 - dense_3_acc_2: 0.7011 - dense_3_acc_3: 0.3244 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9711 - dense_3_acc_6: 0.4178 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4711 - dense_3_acc_9: 0.272 - ETA: 11s - loss: 7.5909 - dense_3_loss: 2.0087 - dense_3_acc: 0.9790 - dense_3_acc_1: 0.9840 - dense_3_acc_2: 0.7010 - dense_3_acc_3: 0.3360 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9740 - dense_3_acc_6: 0.4140 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4660 - dense_3_acc_9: 0.275 - ETA: 11s - loss: 7.6001 - dense_3_loss: 2.0074 - dense_3_acc: 0.9782 - dense_3_acc_1: 0.9827 - dense_3_acc_2: 0.7018 - dense_3_acc_3: 0.3391 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9745 - dense_3_acc_6: 0.4036 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4700 - dense_3_acc_9: 0.273 - ETA: 10s - loss: 7.6042 - dense_3_loss: 2.0139 - dense_3_acc: 0.9792 - dense_3_acc_1: 0.9833 - dense_3_acc_2: 0.7058 - dense_3_acc_3: 0.3408 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9758 - dense_3_acc_6: 0.4058 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4642 - dense_3_acc_9: 0.272 - ETA: 10s - loss: 7.6011 - dense_3_loss: 2.0066 - dense_3_acc: 0.9785 - dense_3_acc_1: 0.9815 - dense_3_acc_2: 0.7108 - dense_3_acc_3: 0.3415 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9746 - dense_3_acc_6: 0.4069 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4631 - dense_3_acc_9: 0.277 - ETA: 10s - loss: 7.5879 - dense_3_loss: 1.9965 - dense_3_acc: 0.9771 - dense_3_acc_1: 0.9814 - dense_3_acc_2: 0.7057 - dense_3_acc_3: 0.3457 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9743 - dense_3_acc_6: 0.4057 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4700 - dense_3_acc_9: 0.280 - ETA: 10s - loss: 7.5621 - dense_3_loss: 1.9900 - dense_3_acc: 0.9780 - dense_3_acc_1: 0.9820 - dense_3_acc_2: 0.7060 - dense_3_acc_3: 0.3427 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9753 - dense_3_acc_6: 0.4120 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4773 - dense_3_acc_9: 0.284 - ETA: 10s - loss: 7.5761 - dense_3_loss: 1.9916 - dense_3_acc: 0.9775 - dense_3_acc_1: 0.9813 - dense_3_acc_2: 0.7075 - dense_3_acc_3: 0.3500 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9744 - dense_3_acc_6: 0.4056 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4725 - dense_3_acc_9: 0.281 - ETA: 10s - loss: 7.5618 - dense_3_loss: 1.9864 - dense_3_acc: 0.9782 - dense_3_acc_1: 0.9824 - dense_3_acc_2: 0.7082 - dense_3_acc_3: 0.3518 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9747 - dense_3_acc_6: 0.4059 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4694 - dense_3_acc_9: 0.284 - ETA: 10s - loss: 7.5564 - dense_3_loss: 1.9868 - dense_3_acc: 0.9789 - dense_3_acc_1: 0.9833 - dense_3_acc_2: 0.7111 - dense_3_acc_3: 0.3506 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9744 - dense_3_acc_6: 0.4061 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4711 - dense_3_acc_9: 0.286 - ETA: 10s - loss: 7.5527 - dense_3_loss: 1.9832 - dense_3_acc: 0.9768 - dense_3_acc_1: 0.9811 - dense_3_acc_2: 0.7100 - dense_3_acc_3: 0.3500 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9742 - dense_3_acc_6: 0.4079 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4679 - dense_3_acc_9: 0.290 - ETA: 9s - loss: 7.5439 - dense_3_loss: 1.9766 - dense_3_acc: 0.9775 - dense_3_acc_1: 0.9815 - dense_3_acc_2: 0.7120 - dense_3_acc_3: 0.3505 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9740 - dense_3_acc_6: 0.4070 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4650 - dense_3_acc_9: 0.292 - ETA: 9s - loss: 7.5351 - dense_3_loss: 1.9728 - dense_3_acc: 0.9776 - dense_3_acc_1: 0.9814 - dense_3_acc_2: 0.7110 - dense_3_acc_3: 0.3524 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9743 - dense_3_acc_6: 0.4043 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4633 - dense_3_acc_9: 0.29 - ETA: 9s - loss: 7.5399 - dense_3_loss: 1.9746 - dense_3_acc: 0.9768 - dense_3_acc_1: 0.9809 - dense_3_acc_2: 0.7095 - dense_3_acc_3: 0.3527 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9736 - dense_3_acc_6: 0.4050 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4659 - dense_3_acc_9: 0.29 - ETA: 9s - loss: 7.5335 - dense_3_loss: 1.9731 - dense_3_acc: 0.9774 - dense_3_acc_1: 0.9813 - dense_3_acc_2: 0.7104 - dense_3_acc_3: 0.3504 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9722 - dense_3_acc_6: 0.4052 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4661 - dense_3_acc_9: 0.29 - ETA: 9s - loss: 7.5262 - dense_3_loss: 1.9691 - dense_3_acc: 0.9771 - dense_3_acc_1: 0.9813 - dense_3_acc_2: 0.7092 - dense_3_acc_3: 0.3517 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9725 - dense_3_acc_6: 0.4037 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4667 - dense_3_acc_9: 0.29 - ETA: 9s - loss: 7.5215 - dense_3_loss: 1.9713 - dense_3_acc: 0.9768 - dense_3_acc_1: 0.9816 - dense_3_acc_2: 0.7096 - dense_3_acc_3: 0.3536 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9716 - dense_3_acc_6: 0.4020 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4672 - dense_3_acc_9: 0.29 - ETA: 9s - loss: 7.5136 - dense_3_loss: 1.9717 - dense_3_acc: 0.9773 - dense_3_acc_1: 0.9823 - dense_3_acc_2: 0.7112 - dense_3_acc_3: 0.3562 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9719 - dense_3_acc_6: 0.4008 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4677 - dense_3_acc_9: 0.29 - ETA: 9s - loss: 7.4976 - dense_3_loss: 1.9683 - dense_3_acc: 0.9778 - dense_3_acc_1: 0.9826 - dense_3_acc_2: 0.7133 - dense_3_acc_3: 0.3581 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9726 - dense_3_acc_6: 0.4004 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4674 - dense_3_acc_9: 0.29 - ETA: 8s - loss: 7.4946 - dense_3_loss: 1.9689 - dense_3_acc: 0.9775 - dense_3_acc_1: 0.9821 - dense_3_acc_2: 0.7129 - dense_3_acc_3: 0.3561 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9718 - dense_3_acc_6: 0.4036 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4686 - dense_3_acc_9: 0.29 - ETA: 8s - loss: 7.4934 - dense_3_loss: 1.9702 - dense_3_acc: 0.9779 - dense_3_acc_1: 0.9821 - dense_3_acc_2: 0.7110 - dense_3_acc_3: 0.3572 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9707 - dense_3_acc_6: 0.4034 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4686 - dense_3_acc_9: 0.2941"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5800/10000 [================>.............] - ETA: 8s - loss: 7.4886 - dense_3_loss: 1.9674 - dense_3_acc: 0.9780 - dense_3_acc_1: 0.9820 - dense_3_acc_2: 0.7100 - dense_3_acc_3: 0.3553 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9710 - dense_3_acc_6: 0.4013 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4690 - dense_3_acc_9: 0.29 - ETA: 8s - loss: 7.4822 - dense_3_loss: 1.9660 - dense_3_acc: 0.9777 - dense_3_acc_1: 0.9816 - dense_3_acc_2: 0.7100 - dense_3_acc_3: 0.3548 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9710 - dense_3_acc_6: 0.4006 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4700 - dense_3_acc_9: 0.29 - ETA: 8s - loss: 7.4731 - dense_3_loss: 1.9649 - dense_3_acc: 0.9784 - dense_3_acc_1: 0.9822 - dense_3_acc_2: 0.7112 - dense_3_acc_3: 0.3559 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9709 - dense_3_acc_6: 0.4044 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4703 - dense_3_acc_9: 0.29 - ETA: 8s - loss: 7.4776 - dense_3_loss: 1.9634 - dense_3_acc: 0.9776 - dense_3_acc_1: 0.9812 - dense_3_acc_2: 0.7133 - dense_3_acc_3: 0.3552 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9703 - dense_3_acc_6: 0.4042 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4703 - dense_3_acc_9: 0.29 - ETA: 8s - loss: 7.4755 - dense_3_loss: 1.9636 - dense_3_acc: 0.9774 - dense_3_acc_1: 0.9812 - dense_3_acc_2: 0.7162 - dense_3_acc_3: 0.3562 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9706 - dense_3_acc_6: 0.4024 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4715 - dense_3_acc_9: 0.29 - ETA: 7s - loss: 7.4781 - dense_3_loss: 1.9644 - dense_3_acc: 0.9774 - dense_3_acc_1: 0.9811 - dense_3_acc_2: 0.7157 - dense_3_acc_3: 0.3571 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9700 - dense_3_acc_6: 0.4006 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4709 - dense_3_acc_9: 0.29 - ETA: 7s - loss: 7.4786 - dense_3_loss: 1.9632 - dense_3_acc: 0.9772 - dense_3_acc_1: 0.9814 - dense_3_acc_2: 0.7147 - dense_3_acc_3: 0.3567 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9697 - dense_3_acc_6: 0.4028 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4719 - dense_3_acc_9: 0.29 - ETA: 7s - loss: 7.4722 - dense_3_loss: 1.9598 - dense_3_acc: 0.9776 - dense_3_acc_1: 0.9814 - dense_3_acc_2: 0.7151 - dense_3_acc_3: 0.3584 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9703 - dense_3_acc_6: 0.4019 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4727 - dense_3_acc_9: 0.29 - ETA: 7s - loss: 7.4686 - dense_3_loss: 1.9591 - dense_3_acc: 0.9782 - dense_3_acc_1: 0.9818 - dense_3_acc_2: 0.7163 - dense_3_acc_3: 0.3595 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9708 - dense_3_acc_6: 0.4013 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4697 - dense_3_acc_9: 0.29 - ETA: 7s - loss: 7.4652 - dense_3_loss: 1.9582 - dense_3_acc: 0.9777 - dense_3_acc_1: 0.9815 - dense_3_acc_2: 0.7167 - dense_3_acc_3: 0.3597 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9708 - dense_3_acc_6: 0.4021 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4718 - dense_3_acc_9: 0.29 - ETA: 7s - loss: 7.4684 - dense_3_loss: 1.9564 - dense_3_acc: 0.9768 - dense_3_acc_1: 0.9808 - dense_3_acc_2: 0.7182 - dense_3_acc_3: 0.3625 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9705 - dense_3_acc_6: 0.4005 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4732 - dense_3_acc_9: 0.29 - ETA: 7s - loss: 7.4699 - dense_3_loss: 1.9590 - dense_3_acc: 0.9766 - dense_3_acc_1: 0.9805 - dense_3_acc_2: 0.7176 - dense_3_acc_3: 0.3612 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9700 - dense_3_acc_6: 0.4020 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4756 - dense_3_acc_9: 0.29 - ETA: 7s - loss: 7.4671 - dense_3_loss: 1.9560 - dense_3_acc: 0.9762 - dense_3_acc_1: 0.9800 - dense_3_acc_2: 0.7157 - dense_3_acc_3: 0.3605 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9700 - dense_3_acc_6: 0.4029 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4757 - dense_3_acc_9: 0.30 - ETA: 6s - loss: 7.4645 - dense_3_loss: 1.9553 - dense_3_acc: 0.9751 - dense_3_acc_1: 0.9793 - dense_3_acc_2: 0.7160 - dense_3_acc_3: 0.3602 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9695 - dense_3_acc_6: 0.4033 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4779 - dense_3_acc_9: 0.29 - ETA: 6s - loss: 7.4580 - dense_3_loss: 1.9545 - dense_3_acc: 0.9752 - dense_3_acc_1: 0.9795 - dense_3_acc_2: 0.7186 - dense_3_acc_3: 0.3618 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9684 - dense_3_acc_6: 0.4036 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4800 - dense_3_acc_9: 0.29 - ETA: 6s - loss: 7.4547 - dense_3_loss: 1.9526 - dense_3_acc: 0.9749 - dense_3_acc_1: 0.9791 - dense_3_acc_2: 0.7171 - dense_3_acc_3: 0.3629 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9680 - dense_3_acc_6: 0.4051 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4807 - dense_3_acc_9: 0.30 - ETA: 6s - loss: 7.4492 - dense_3_loss: 1.9528 - dense_3_acc: 0.9752 - dense_3_acc_1: 0.9793 - dense_3_acc_2: 0.7180 - dense_3_acc_3: 0.3630 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9674 - dense_3_acc_6: 0.4043 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4822 - dense_3_acc_9: 0.30 - ETA: 6s - loss: 7.4476 - dense_3_loss: 1.9511 - dense_3_acc: 0.9753 - dense_3_acc_1: 0.9794 - dense_3_acc_2: 0.7183 - dense_3_acc_3: 0.3638 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9670 - dense_3_acc_6: 0.4026 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4821 - dense_3_acc_9: 0.30 - ETA: 6s - loss: 7.4435 - dense_3_loss: 1.9489 - dense_3_acc: 0.9754 - dense_3_acc_1: 0.9794 - dense_3_acc_2: 0.7196 - dense_3_acc_3: 0.3625 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9675 - dense_3_acc_6: 0.4033 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4819 - dense_3_acc_9: 0.30 - ETA: 6s - loss: 7.4389 - dense_3_loss: 1.9461 - dense_3_acc: 0.9751 - dense_3_acc_1: 0.9794 - dense_3_acc_2: 0.7194 - dense_3_acc_3: 0.3631 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9669 - dense_3_acc_6: 0.4037 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4820 - dense_3_acc_9: 0.30 - ETA: 6s - loss: 7.4295 - dense_3_loss: 1.9466 - dense_3_acc: 0.9750 - dense_3_acc_1: 0.9794 - dense_3_acc_2: 0.7202 - dense_3_acc_3: 0.3654 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9662 - dense_3_acc_6: 0.4060 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4844 - dense_3_acc_9: 0.30 - ETA: 5s - loss: 7.4259 - dense_3_loss: 1.9482 - dense_3_acc: 0.9753 - dense_3_acc_1: 0.9798 - dense_3_acc_2: 0.7208 - dense_3_acc_3: 0.3653 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9663 - dense_3_acc_6: 0.4067 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4849 - dense_3_acc_9: 0.30 - ETA: 5s - loss: 7.4231 - dense_3_loss: 1.9479 - dense_3_acc: 0.9754 - dense_3_acc_1: 0.9798 - dense_3_acc_2: 0.7210 - dense_3_acc_3: 0.3658 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9658 - dense_3_acc_6: 0.4079 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4852 - dense_3_acc_9: 0.30 - ETA: 5s - loss: 7.4143 - dense_3_loss: 1.9460 - dense_3_acc: 0.9757 - dense_3_acc_1: 0.9800 - dense_3_acc_2: 0.7221 - dense_3_acc_3: 0.3657 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9660 - dense_3_acc_6: 0.4083 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4870 - dense_3_acc_9: 0.30 - ETA: 5s - loss: 7.4165 - dense_3_loss: 1.9462 - dense_3_acc: 0.9756 - dense_3_acc_1: 0.9798 - dense_3_acc_2: 0.7209 - dense_3_acc_3: 0.3646 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9659 - dense_3_acc_6: 0.4094 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4876 - dense_3_acc_9: 0.30 - ETA: 5s - loss: 7.4083 - dense_3_loss: 1.9457 - dense_3_acc: 0.9760 - dense_3_acc_1: 0.9802 - dense_3_acc_2: 0.7211 - dense_3_acc_3: 0.3664 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9660 - dense_3_acc_6: 0.4087 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4902 - dense_3_acc_9: 0.30 - ETA: 5s - loss: 7.4063 - dense_3_loss: 1.9459 - dense_3_acc: 0.9754 - dense_3_acc_1: 0.9798 - dense_3_acc_2: 0.7214 - dense_3_acc_3: 0.3673 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9657 - dense_3_acc_6: 0.4098 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4904 - dense_3_acc_9: 0.30 - ETA: 5s - loss: 7.4060 - dense_3_loss: 1.9451 - dense_3_acc: 0.9753 - dense_3_acc_1: 0.9796 - dense_3_acc_2: 0.7214 - dense_3_acc_3: 0.3656 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9660 - dense_3_acc_6: 0.4098 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4909 - dense_3_acc_9: 0.30 - ETA: 5s - loss: 7.4014 - dense_3_loss: 1.9432 - dense_3_acc: 0.9753 - dense_3_acc_1: 0.9797 - dense_3_acc_2: 0.7231 - dense_3_acc_3: 0.3662 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9662 - dense_3_acc_6: 0.4079 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4916 - dense_3_acc_9: 0.3021"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8700/10000 [=========================>....] - ETA: 4s - loss: 7.3982 - dense_3_loss: 1.9437 - dense_3_acc: 0.9758 - dense_3_acc_1: 0.9800 - dense_3_acc_2: 0.7232 - dense_3_acc_3: 0.3658 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9659 - dense_3_acc_6: 0.4081 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4915 - dense_3_acc_9: 0.30 - ETA: 4s - loss: 7.3963 - dense_3_loss: 1.9449 - dense_3_acc: 0.9757 - dense_3_acc_1: 0.9798 - dense_3_acc_2: 0.7233 - dense_3_acc_3: 0.3657 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9660 - dense_3_acc_6: 0.4098 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4927 - dense_3_acc_9: 0.30 - ETA: 4s - loss: 7.3970 - dense_3_loss: 1.9449 - dense_3_acc: 0.9757 - dense_3_acc_1: 0.9798 - dense_3_acc_2: 0.7238 - dense_3_acc_3: 0.3643 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9659 - dense_3_acc_6: 0.4102 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4934 - dense_3_acc_9: 0.30 - ETA: 4s - loss: 7.3894 - dense_3_loss: 1.9432 - dense_3_acc: 0.9758 - dense_3_acc_1: 0.9798 - dense_3_acc_2: 0.7237 - dense_3_acc_3: 0.3645 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9661 - dense_3_acc_6: 0.4108 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4945 - dense_3_acc_9: 0.30 - ETA: 4s - loss: 7.3887 - dense_3_loss: 1.9425 - dense_3_acc: 0.9760 - dense_3_acc_1: 0.9795 - dense_3_acc_2: 0.7235 - dense_3_acc_3: 0.3644 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9662 - dense_3_acc_6: 0.4089 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4963 - dense_3_acc_9: 0.30 - ETA: 4s - loss: 7.3866 - dense_3_loss: 1.9417 - dense_3_acc: 0.9761 - dense_3_acc_1: 0.9795 - dense_3_acc_2: 0.7231 - dense_3_acc_3: 0.3638 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9661 - dense_3_acc_6: 0.4098 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4969 - dense_3_acc_9: 0.30 - ETA: 4s - loss: 7.3849 - dense_3_loss: 1.9409 - dense_3_acc: 0.9762 - dense_3_acc_1: 0.9794 - dense_3_acc_2: 0.7225 - dense_3_acc_3: 0.3632 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9657 - dense_3_acc_6: 0.4114 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4963 - dense_3_acc_9: 0.30 - ETA: 4s - loss: 7.3839 - dense_3_loss: 1.9405 - dense_3_acc: 0.9759 - dense_3_acc_1: 0.9794 - dense_3_acc_2: 0.7232 - dense_3_acc_3: 0.3642 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9659 - dense_3_acc_6: 0.4112 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4955 - dense_3_acc_9: 0.30 - ETA: 4s - loss: 7.3839 - dense_3_loss: 1.9410 - dense_3_acc: 0.9760 - dense_3_acc_1: 0.9794 - dense_3_acc_2: 0.7233 - dense_3_acc_3: 0.3643 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9657 - dense_3_acc_6: 0.4122 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4940 - dense_3_acc_9: 0.30 - ETA: 3s - loss: 7.3793 - dense_3_loss: 1.9395 - dense_3_acc: 0.9759 - dense_3_acc_1: 0.9796 - dense_3_acc_2: 0.7234 - dense_3_acc_3: 0.3654 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9654 - dense_3_acc_6: 0.4122 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4947 - dense_3_acc_9: 0.30 - ETA: 3s - loss: 7.3810 - dense_3_loss: 1.9396 - dense_3_acc: 0.9755 - dense_3_acc_1: 0.9793 - dense_3_acc_2: 0.7232 - dense_3_acc_3: 0.3657 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9648 - dense_3_acc_6: 0.4122 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4959 - dense_3_acc_9: 0.30 - ETA: 3s - loss: 7.3765 - dense_3_loss: 1.9388 - dense_3_acc: 0.9759 - dense_3_acc_1: 0.9796 - dense_3_acc_2: 0.7234 - dense_3_acc_3: 0.3660 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9651 - dense_3_acc_6: 0.4124 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4966 - dense_3_acc_9: 0.30 - ETA: 3s - loss: 7.3768 - dense_3_loss: 1.9384 - dense_3_acc: 0.9758 - dense_3_acc_1: 0.9796 - dense_3_acc_2: 0.7234 - dense_3_acc_3: 0.3655 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9649 - dense_3_acc_6: 0.4128 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4975 - dense_3_acc_9: 0.30 - ETA: 3s - loss: 7.3713 - dense_3_loss: 1.9375 - dense_3_acc: 0.9760 - dense_3_acc_1: 0.9797 - dense_3_acc_2: 0.7237 - dense_3_acc_3: 0.3651 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9653 - dense_3_acc_6: 0.4131 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4975 - dense_3_acc_9: 0.30 - ETA: 3s - loss: 7.3711 - dense_3_loss: 1.9367 - dense_3_acc: 0.9759 - dense_3_acc_1: 0.9795 - dense_3_acc_2: 0.7242 - dense_3_acc_3: 0.3658 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9658 - dense_3_acc_6: 0.4129 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4967 - dense_3_acc_9: 0.30 - ETA: 3s - loss: 7.3686 - dense_3_loss: 1.9358 - dense_3_acc: 0.9755 - dense_3_acc_1: 0.9795 - dense_3_acc_2: 0.7251 - dense_3_acc_3: 0.3650 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9655 - dense_3_acc_6: 0.4143 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4976 - dense_3_acc_9: 0.30 - ETA: 3s - loss: 7.3648 - dense_3_loss: 1.9356 - dense_3_acc: 0.9757 - dense_3_acc_1: 0.9796 - dense_3_acc_2: 0.7260 - dense_3_acc_3: 0.3648 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9659 - dense_3_acc_6: 0.4145 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4980 - dense_3_acc_9: 0.30 - ETA: 2s - loss: 7.3601 - dense_3_loss: 1.9350 - dense_3_acc: 0.9758 - dense_3_acc_1: 0.9796 - dense_3_acc_2: 0.7254 - dense_3_acc_3: 0.3657 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9658 - dense_3_acc_6: 0.4154 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4992 - dense_3_acc_9: 0.30 - ETA: 2s - loss: 7.3583 - dense_3_loss: 1.9342 - dense_3_acc: 0.9758 - dense_3_acc_1: 0.9797 - dense_3_acc_2: 0.7258 - dense_3_acc_3: 0.3661 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9656 - dense_3_acc_6: 0.4156 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4984 - dense_3_acc_9: 0.30 - ETA: 2s - loss: 7.3562 - dense_3_loss: 1.9330 - dense_3_acc: 0.9762 - dense_3_acc_1: 0.9800 - dense_3_acc_2: 0.7259 - dense_3_acc_3: 0.3672 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9650 - dense_3_acc_6: 0.4165 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4996 - dense_3_acc_9: 0.30 - ETA: 2s - loss: 7.3552 - dense_3_loss: 1.9310 - dense_3_acc: 0.9759 - dense_3_acc_1: 0.9797 - dense_3_acc_2: 0.7261 - dense_3_acc_3: 0.3682 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9649 - dense_3_acc_6: 0.4162 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.5000 - dense_3_acc_9: 0.30 - ETA: 2s - loss: 7.3516 - dense_3_loss: 1.9302 - dense_3_acc: 0.9756 - dense_3_acc_1: 0.9795 - dense_3_acc_2: 0.7270 - dense_3_acc_3: 0.3695 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9654 - dense_3_acc_6: 0.4170 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.5010 - dense_3_acc_9: 0.30 - ETA: 2s - loss: 7.3490 - dense_3_loss: 1.9285 - dense_3_acc: 0.9756 - dense_3_acc_1: 0.9795 - dense_3_acc_2: 0.7279 - dense_3_acc_3: 0.3702 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9652 - dense_3_acc_6: 0.4177 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.5010 - dense_3_acc_9: 0.30 - ETA: 2s - loss: 7.3445 - dense_3_loss: 1.9275 - dense_3_acc: 0.9756 - dense_3_acc_1: 0.9795 - dense_3_acc_2: 0.7290 - dense_3_acc_3: 0.3711 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9652 - dense_3_acc_6: 0.4172 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.5013 - dense_3_acc_9: 0.31 - ETA: 2s - loss: 7.3379 - dense_3_loss: 1.9272 - dense_3_acc: 0.9758 - dense_3_acc_1: 0.9796 - dense_3_acc_2: 0.7304 - dense_3_acc_3: 0.3722 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9653 - dense_3_acc_6: 0.4175 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.5023 - dense_3_acc_9: 0.30 - ETA: 1s - loss: 7.3314 - dense_3_loss: 1.9262 - dense_3_acc: 0.9760 - dense_3_acc_1: 0.9798 - dense_3_acc_2: 0.7312 - dense_3_acc_3: 0.3731 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9654 - dense_3_acc_6: 0.4179 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.5026 - dense_3_acc_9: 0.31 - ETA: 1s - loss: 7.3253 - dense_3_loss: 1.9242 - dense_3_acc: 0.9760 - dense_3_acc_1: 0.9800 - dense_3_acc_2: 0.7322 - dense_3_acc_3: 0.3736 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9655 - dense_3_acc_6: 0.4175 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.5031 - dense_3_acc_9: 0.31 - ETA: 1s - loss: 7.3175 - dense_3_loss: 1.9217 - dense_3_acc: 0.9760 - dense_3_acc_1: 0.9800 - dense_3_acc_2: 0.7322 - dense_3_acc_3: 0.3742 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9658 - dense_3_acc_6: 0.4180 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.5038 - dense_3_acc_9: 0.31 - ETA: 1s - loss: 7.3126 - dense_3_loss: 1.9194 - dense_3_acc: 0.9760 - dense_3_acc_1: 0.9800 - dense_3_acc_2: 0.7326 - dense_3_acc_3: 0.3751 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9659 - dense_3_acc_6: 0.4190 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.5044 - dense_3_acc_9: 0.3129"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - ETA: 1s - loss: 7.3084 - dense_3_loss: 1.9174 - dense_3_acc: 0.9759 - dense_3_acc_1: 0.9799 - dense_3_acc_2: 0.7330 - dense_3_acc_3: 0.3752 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9660 - dense_3_acc_6: 0.4184 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.5045 - dense_3_acc_9: 0.31 - ETA: 1s - loss: 7.3031 - dense_3_loss: 1.9165 - dense_3_acc: 0.9758 - dense_3_acc_1: 0.9798 - dense_3_acc_2: 0.7330 - dense_3_acc_3: 0.3757 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9662 - dense_3_acc_6: 0.4200 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.5051 - dense_3_acc_9: 0.31 - ETA: 1s - loss: 7.3005 - dense_3_loss: 1.9171 - dense_3_acc: 0.9756 - dense_3_acc_1: 0.9796 - dense_3_acc_2: 0.7329 - dense_3_acc_3: 0.3762 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9661 - dense_3_acc_6: 0.4209 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.5049 - dense_3_acc_9: 0.31 - ETA: 1s - loss: 7.2980 - dense_3_loss: 1.9150 - dense_3_acc: 0.9753 - dense_3_acc_1: 0.9791 - dense_3_acc_2: 0.7335 - dense_3_acc_3: 0.3770 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9660 - dense_3_acc_6: 0.4209 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.5054 - dense_3_acc_9: 0.31 - ETA: 0s - loss: 7.2952 - dense_3_loss: 1.9130 - dense_3_acc: 0.9751 - dense_3_acc_1: 0.9790 - dense_3_acc_2: 0.7337 - dense_3_acc_3: 0.3775 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9662 - dense_3_acc_6: 0.4210 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.5052 - dense_3_acc_9: 0.31 - ETA: 0s - loss: 7.2957 - dense_3_loss: 1.9123 - dense_3_acc: 0.9748 - dense_3_acc_1: 0.9786 - dense_3_acc_2: 0.7338 - dense_3_acc_3: 0.3770 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9658 - dense_3_acc_6: 0.4211 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.5056 - dense_3_acc_9: 0.31 - ETA: 0s - loss: 7.2934 - dense_3_loss: 1.9123 - dense_3_acc: 0.9747 - dense_3_acc_1: 0.9785 - dense_3_acc_2: 0.7341 - dense_3_acc_3: 0.3767 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9661 - dense_3_acc_6: 0.4222 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.5057 - dense_3_acc_9: 0.31 - ETA: 0s - loss: 7.2914 - dense_3_loss: 1.9103 - dense_3_acc: 0.9747 - dense_3_acc_1: 0.9785 - dense_3_acc_2: 0.7337 - dense_3_acc_3: 0.3765 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9661 - dense_3_acc_6: 0.4213 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.5061 - dense_3_acc_9: 0.31 - ETA: 0s - loss: 7.2881 - dense_3_loss: 1.9101 - dense_3_acc: 0.9746 - dense_3_acc_1: 0.9785 - dense_3_acc_2: 0.7336 - dense_3_acc_3: 0.3773 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9665 - dense_3_acc_6: 0.4217 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.5067 - dense_3_acc_9: 0.31 - ETA: 0s - loss: 7.2842 - dense_3_loss: 1.9091 - dense_3_acc: 0.9745 - dense_3_acc_1: 0.9786 - dense_3_acc_2: 0.7336 - dense_3_acc_3: 0.3780 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9667 - dense_3_acc_6: 0.4220 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.5069 - dense_3_acc_9: 0.31 - ETA: 0s - loss: 7.2792 - dense_3_loss: 1.9080 - dense_3_acc: 0.9747 - dense_3_acc_1: 0.9787 - dense_3_acc_2: 0.7341 - dense_3_acc_3: 0.3782 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9666 - dense_3_acc_6: 0.4229 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.5069 - dense_3_acc_9: 0.31 - ETA: 0s - loss: 7.2769 - dense_3_loss: 1.9068 - dense_3_acc: 0.9746 - dense_3_acc_1: 0.9786 - dense_3_acc_2: 0.7344 - dense_3_acc_3: 0.3784 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9668 - dense_3_acc_6: 0.4226 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.5066 - dense_3_acc_9: 0.31 - 12s 1ms/step - loss: 7.2721 - dense_3_loss: 1.9067 - dense_3_acc: 0.9745 - dense_3_acc_1: 0.9786 - dense_3_acc_2: 0.7347 - dense_3_acc_3: 0.3798 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9668 - dense_3_acc_6: 0.4229 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.5067 - dense_3_acc_9: 0.3154\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2900/10000 [=======>......................] - ETA: 11s - loss: 6.8578 - dense_3_loss: 1.8146 - dense_3_acc: 0.9900 - dense_3_acc_1: 0.9900 - dense_3_acc_2: 0.8200 - dense_3_acc_3: 0.4100 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9500 - dense_3_acc_6: 0.4800 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.5200 - dense_3_acc_9: 0.340 - ETA: 12s - loss: 6.8462 - dense_3_loss: 1.8254 - dense_3_acc: 0.9800 - dense_3_acc_1: 0.9800 - dense_3_acc_2: 0.7950 - dense_3_acc_3: 0.4100 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9700 - dense_3_acc_6: 0.4550 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.5200 - dense_3_acc_9: 0.350 - ETA: 11s - loss: 6.7844 - dense_3_loss: 1.7862 - dense_3_acc: 0.9800 - dense_3_acc_1: 0.9833 - dense_3_acc_2: 0.8067 - dense_3_acc_3: 0.4100 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9767 - dense_3_acc_6: 0.4567 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.5433 - dense_3_acc_9: 0.370 - ETA: 11s - loss: 6.8035 - dense_3_loss: 1.7642 - dense_3_acc: 0.9775 - dense_3_acc_1: 0.9850 - dense_3_acc_2: 0.7800 - dense_3_acc_3: 0.4100 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9675 - dense_3_acc_6: 0.4500 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.5200 - dense_3_acc_9: 0.380 - ETA: 11s - loss: 6.8333 - dense_3_loss: 1.7557 - dense_3_acc: 0.9760 - dense_3_acc_1: 0.9820 - dense_3_acc_2: 0.7640 - dense_3_acc_3: 0.4160 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9740 - dense_3_acc_6: 0.4240 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.5360 - dense_3_acc_9: 0.388 - ETA: 11s - loss: 6.8379 - dense_3_loss: 1.7763 - dense_3_acc: 0.9733 - dense_3_acc_1: 0.9783 - dense_3_acc_2: 0.7683 - dense_3_acc_3: 0.4100 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9683 - dense_3_acc_6: 0.4400 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.5517 - dense_3_acc_9: 0.371 - ETA: 11s - loss: 6.8370 - dense_3_loss: 1.7749 - dense_3_acc: 0.9729 - dense_3_acc_1: 0.9771 - dense_3_acc_2: 0.7714 - dense_3_acc_3: 0.4171 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9686 - dense_3_acc_6: 0.4386 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.5500 - dense_3_acc_9: 0.382 - ETA: 10s - loss: 6.8350 - dense_3_loss: 1.7771 - dense_3_acc: 0.9725 - dense_3_acc_1: 0.9750 - dense_3_acc_2: 0.7762 - dense_3_acc_3: 0.4212 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9713 - dense_3_acc_6: 0.4425 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.5437 - dense_3_acc_9: 0.370 - ETA: 10s - loss: 6.8470 - dense_3_loss: 1.7729 - dense_3_acc: 0.9744 - dense_3_acc_1: 0.9756 - dense_3_acc_2: 0.7756 - dense_3_acc_3: 0.4133 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9700 - dense_3_acc_6: 0.4389 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.5478 - dense_3_acc_9: 0.373 - ETA: 10s - loss: 6.8307 - dense_3_loss: 1.7703 - dense_3_acc: 0.9770 - dense_3_acc_1: 0.9780 - dense_3_acc_2: 0.7790 - dense_3_acc_3: 0.4060 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9720 - dense_3_acc_6: 0.4460 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.5440 - dense_3_acc_9: 0.374 - ETA: 10s - loss: 6.8324 - dense_3_loss: 1.7706 - dense_3_acc: 0.9773 - dense_3_acc_1: 0.9791 - dense_3_acc_2: 0.7736 - dense_3_acc_3: 0.4109 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9736 - dense_3_acc_6: 0.4473 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.5418 - dense_3_acc_9: 0.370 - ETA: 10s - loss: 6.8271 - dense_3_loss: 1.7710 - dense_3_acc: 0.9783 - dense_3_acc_1: 0.9800 - dense_3_acc_2: 0.7733 - dense_3_acc_3: 0.4175 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9750 - dense_3_acc_6: 0.4458 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.5367 - dense_3_acc_9: 0.370 - ETA: 10s - loss: 6.8207 - dense_3_loss: 1.7708 - dense_3_acc: 0.9792 - dense_3_acc_1: 0.9808 - dense_3_acc_2: 0.7777 - dense_3_acc_3: 0.4192 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9762 - dense_3_acc_6: 0.4477 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.5377 - dense_3_acc_9: 0.369 - ETA: 10s - loss: 6.7943 - dense_3_loss: 1.7664 - dense_3_acc: 0.9800 - dense_3_acc_1: 0.9814 - dense_3_acc_2: 0.7814 - dense_3_acc_3: 0.4207 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9757 - dense_3_acc_6: 0.4479 - dense_3_acc_7: 0.9993 - dense_3_acc_8: 0.5407 - dense_3_acc_9: 0.370 - ETA: 10s - loss: 6.8037 - dense_3_loss: 1.7645 - dense_3_acc: 0.9807 - dense_3_acc_1: 0.9820 - dense_3_acc_2: 0.7753 - dense_3_acc_3: 0.4233 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9760 - dense_3_acc_6: 0.4453 - dense_3_acc_7: 0.9993 - dense_3_acc_8: 0.5347 - dense_3_acc_9: 0.373 - ETA: 10s - loss: 6.7860 - dense_3_loss: 1.7605 - dense_3_acc: 0.9813 - dense_3_acc_1: 0.9831 - dense_3_acc_2: 0.7756 - dense_3_acc_3: 0.4175 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9744 - dense_3_acc_6: 0.4519 - dense_3_acc_7: 0.9994 - dense_3_acc_8: 0.5394 - dense_3_acc_9: 0.376 - ETA: 9s - loss: 6.7864 - dense_3_loss: 1.7635 - dense_3_acc: 0.9812 - dense_3_acc_1: 0.9824 - dense_3_acc_2: 0.7741 - dense_3_acc_3: 0.4176 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9741 - dense_3_acc_6: 0.4518 - dense_3_acc_7: 0.9994 - dense_3_acc_8: 0.5406 - dense_3_acc_9: 0.370 - ETA: 9s - loss: 6.8015 - dense_3_loss: 1.7611 - dense_3_acc: 0.9806 - dense_3_acc_1: 0.9811 - dense_3_acc_2: 0.7744 - dense_3_acc_3: 0.4189 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9733 - dense_3_acc_6: 0.4533 - dense_3_acc_7: 0.9994 - dense_3_acc_8: 0.5406 - dense_3_acc_9: 0.37 - ETA: 9s - loss: 6.7891 - dense_3_loss: 1.7612 - dense_3_acc: 0.9811 - dense_3_acc_1: 0.9816 - dense_3_acc_2: 0.7763 - dense_3_acc_3: 0.4205 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9742 - dense_3_acc_6: 0.4547 - dense_3_acc_7: 0.9995 - dense_3_acc_8: 0.5426 - dense_3_acc_9: 0.37 - ETA: 9s - loss: 6.7896 - dense_3_loss: 1.7636 - dense_3_acc: 0.9795 - dense_3_acc_1: 0.9795 - dense_3_acc_2: 0.7760 - dense_3_acc_3: 0.4255 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9730 - dense_3_acc_6: 0.4540 - dense_3_acc_7: 0.9995 - dense_3_acc_8: 0.5400 - dense_3_acc_9: 0.36 - ETA: 9s - loss: 6.7805 - dense_3_loss: 1.7626 - dense_3_acc: 0.9800 - dense_3_acc_1: 0.9800 - dense_3_acc_2: 0.7776 - dense_3_acc_3: 0.4248 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9738 - dense_3_acc_6: 0.4529 - dense_3_acc_7: 0.9995 - dense_3_acc_8: 0.5414 - dense_3_acc_9: 0.36 - ETA: 9s - loss: 6.7595 - dense_3_loss: 1.7643 - dense_3_acc: 0.9809 - dense_3_acc_1: 0.9809 - dense_3_acc_2: 0.7818 - dense_3_acc_3: 0.4286 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9727 - dense_3_acc_6: 0.4545 - dense_3_acc_7: 0.9995 - dense_3_acc_8: 0.5473 - dense_3_acc_9: 0.36 - ETA: 9s - loss: 6.7655 - dense_3_loss: 1.7628 - dense_3_acc: 0.9800 - dense_3_acc_1: 0.9804 - dense_3_acc_2: 0.7817 - dense_3_acc_3: 0.4283 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9726 - dense_3_acc_6: 0.4526 - dense_3_acc_7: 0.9996 - dense_3_acc_8: 0.5465 - dense_3_acc_9: 0.36 - ETA: 9s - loss: 6.7713 - dense_3_loss: 1.7643 - dense_3_acc: 0.9788 - dense_3_acc_1: 0.9796 - dense_3_acc_2: 0.7787 - dense_3_acc_3: 0.4317 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9721 - dense_3_acc_6: 0.4521 - dense_3_acc_7: 0.9996 - dense_3_acc_8: 0.5492 - dense_3_acc_9: 0.36 - ETA: 8s - loss: 6.7759 - dense_3_loss: 1.7645 - dense_3_acc: 0.9788 - dense_3_acc_1: 0.9796 - dense_3_acc_2: 0.7792 - dense_3_acc_3: 0.4320 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9704 - dense_3_acc_6: 0.4500 - dense_3_acc_7: 0.9996 - dense_3_acc_8: 0.5472 - dense_3_acc_9: 0.36 - ETA: 8s - loss: 6.7719 - dense_3_loss: 1.7625 - dense_3_acc: 0.9792 - dense_3_acc_1: 0.9796 - dense_3_acc_2: 0.7785 - dense_3_acc_3: 0.4296 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9712 - dense_3_acc_6: 0.4485 - dense_3_acc_7: 0.9996 - dense_3_acc_8: 0.5454 - dense_3_acc_9: 0.36 - ETA: 8s - loss: 6.7776 - dense_3_loss: 1.7634 - dense_3_acc: 0.9785 - dense_3_acc_1: 0.9793 - dense_3_acc_2: 0.7785 - dense_3_acc_3: 0.4274 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9707 - dense_3_acc_6: 0.4519 - dense_3_acc_7: 0.9996 - dense_3_acc_8: 0.5433 - dense_3_acc_9: 0.36 - ETA: 8s - loss: 6.7803 - dense_3_loss: 1.7622 - dense_3_acc: 0.9779 - dense_3_acc_1: 0.9786 - dense_3_acc_2: 0.7786 - dense_3_acc_3: 0.4257 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9707 - dense_3_acc_6: 0.4543 - dense_3_acc_7: 0.9996 - dense_3_acc_8: 0.5439 - dense_3_acc_9: 0.36 - ETA: 8s - loss: 6.7668 - dense_3_loss: 1.7562 - dense_3_acc: 0.9772 - dense_3_acc_1: 0.9786 - dense_3_acc_2: 0.7793 - dense_3_acc_3: 0.4279 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9714 - dense_3_acc_6: 0.4566 - dense_3_acc_7: 0.9997 - dense_3_acc_8: 0.5452 - dense_3_acc_9: 0.3700"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5800/10000 [================>.............] - ETA: 8s - loss: 6.7553 - dense_3_loss: 1.7532 - dense_3_acc: 0.9767 - dense_3_acc_1: 0.9783 - dense_3_acc_2: 0.7810 - dense_3_acc_3: 0.4277 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9713 - dense_3_acc_6: 0.4577 - dense_3_acc_7: 0.9997 - dense_3_acc_8: 0.5470 - dense_3_acc_9: 0.36 - ETA: 8s - loss: 6.7545 - dense_3_loss: 1.7552 - dense_3_acc: 0.9761 - dense_3_acc_1: 0.9777 - dense_3_acc_2: 0.7819 - dense_3_acc_3: 0.4297 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9716 - dense_3_acc_6: 0.4571 - dense_3_acc_7: 0.9997 - dense_3_acc_8: 0.5471 - dense_3_acc_9: 0.36 - ETA: 8s - loss: 6.7463 - dense_3_loss: 1.7540 - dense_3_acc: 0.9763 - dense_3_acc_1: 0.9778 - dense_3_acc_2: 0.7847 - dense_3_acc_3: 0.4309 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9716 - dense_3_acc_6: 0.4553 - dense_3_acc_7: 0.9997 - dense_3_acc_8: 0.5484 - dense_3_acc_9: 0.36 - ETA: 8s - loss: 6.7457 - dense_3_loss: 1.7542 - dense_3_acc: 0.9764 - dense_3_acc_1: 0.9779 - dense_3_acc_2: 0.7852 - dense_3_acc_3: 0.4303 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9721 - dense_3_acc_6: 0.4552 - dense_3_acc_7: 0.9994 - dense_3_acc_8: 0.5509 - dense_3_acc_9: 0.36 - ETA: 7s - loss: 6.7472 - dense_3_loss: 1.7530 - dense_3_acc: 0.9762 - dense_3_acc_1: 0.9774 - dense_3_acc_2: 0.7853 - dense_3_acc_3: 0.4312 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9724 - dense_3_acc_6: 0.4559 - dense_3_acc_7: 0.9994 - dense_3_acc_8: 0.5512 - dense_3_acc_9: 0.36 - ETA: 7s - loss: 6.7374 - dense_3_loss: 1.7508 - dense_3_acc: 0.9766 - dense_3_acc_1: 0.9780 - dense_3_acc_2: 0.7860 - dense_3_acc_3: 0.4334 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9723 - dense_3_acc_6: 0.4554 - dense_3_acc_7: 0.9994 - dense_3_acc_8: 0.5503 - dense_3_acc_9: 0.36 - ETA: 7s - loss: 6.7368 - dense_3_loss: 1.7473 - dense_3_acc: 0.9764 - dense_3_acc_1: 0.9781 - dense_3_acc_2: 0.7844 - dense_3_acc_3: 0.4333 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9722 - dense_3_acc_6: 0.4550 - dense_3_acc_7: 0.9994 - dense_3_acc_8: 0.5503 - dense_3_acc_9: 0.36 - ETA: 7s - loss: 6.7263 - dense_3_loss: 1.7452 - dense_3_acc: 0.9768 - dense_3_acc_1: 0.9784 - dense_3_acc_2: 0.7841 - dense_3_acc_3: 0.4362 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9724 - dense_3_acc_6: 0.4559 - dense_3_acc_7: 0.9995 - dense_3_acc_8: 0.5503 - dense_3_acc_9: 0.36 - ETA: 7s - loss: 6.7231 - dense_3_loss: 1.7407 - dense_3_acc: 0.9763 - dense_3_acc_1: 0.9776 - dense_3_acc_2: 0.7816 - dense_3_acc_3: 0.4358 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9724 - dense_3_acc_6: 0.4550 - dense_3_acc_7: 0.9995 - dense_3_acc_8: 0.5511 - dense_3_acc_9: 0.37 - ETA: 7s - loss: 6.7205 - dense_3_loss: 1.7373 - dense_3_acc: 0.9762 - dense_3_acc_1: 0.9774 - dense_3_acc_2: 0.7831 - dense_3_acc_3: 0.4367 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9726 - dense_3_acc_6: 0.4551 - dense_3_acc_7: 0.9995 - dense_3_acc_8: 0.5508 - dense_3_acc_9: 0.37 - ETA: 7s - loss: 6.7137 - dense_3_loss: 1.7380 - dense_3_acc: 0.9768 - dense_3_acc_1: 0.9780 - dense_3_acc_2: 0.7822 - dense_3_acc_3: 0.4370 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9725 - dense_3_acc_6: 0.4570 - dense_3_acc_7: 0.9995 - dense_3_acc_8: 0.5507 - dense_3_acc_9: 0.37 - ETA: 7s - loss: 6.7089 - dense_3_loss: 1.7387 - dense_3_acc: 0.9768 - dense_3_acc_1: 0.9780 - dense_3_acc_2: 0.7846 - dense_3_acc_3: 0.4371 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9724 - dense_3_acc_6: 0.4593 - dense_3_acc_7: 0.9995 - dense_3_acc_8: 0.5502 - dense_3_acc_9: 0.37 - ETA: 7s - loss: 6.7048 - dense_3_loss: 1.7390 - dense_3_acc: 0.9769 - dense_3_acc_1: 0.9783 - dense_3_acc_2: 0.7848 - dense_3_acc_3: 0.4398 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9721 - dense_3_acc_6: 0.4607 - dense_3_acc_7: 0.9995 - dense_3_acc_8: 0.5512 - dense_3_acc_9: 0.37 - ETA: 7s - loss: 6.7031 - dense_3_loss: 1.7396 - dense_3_acc: 0.9763 - dense_3_acc_1: 0.9781 - dense_3_acc_2: 0.7860 - dense_3_acc_3: 0.4407 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9721 - dense_3_acc_6: 0.4600 - dense_3_acc_7: 0.9995 - dense_3_acc_8: 0.5479 - dense_3_acc_9: 0.37 - ETA: 6s - loss: 6.7043 - dense_3_loss: 1.7366 - dense_3_acc: 0.9759 - dense_3_acc_1: 0.9780 - dense_3_acc_2: 0.7866 - dense_3_acc_3: 0.4432 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9718 - dense_3_acc_6: 0.4598 - dense_3_acc_7: 0.9995 - dense_3_acc_8: 0.5468 - dense_3_acc_9: 0.37 - ETA: 6s - loss: 6.6914 - dense_3_loss: 1.7318 - dense_3_acc: 0.9760 - dense_3_acc_1: 0.9780 - dense_3_acc_2: 0.7862 - dense_3_acc_3: 0.4447 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9713 - dense_3_acc_6: 0.4600 - dense_3_acc_7: 0.9996 - dense_3_acc_8: 0.5496 - dense_3_acc_9: 0.37 - ETA: 6s - loss: 6.6884 - dense_3_loss: 1.7292 - dense_3_acc: 0.9759 - dense_3_acc_1: 0.9780 - dense_3_acc_2: 0.7863 - dense_3_acc_3: 0.4437 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9707 - dense_3_acc_6: 0.4589 - dense_3_acc_7: 0.9996 - dense_3_acc_8: 0.5498 - dense_3_acc_9: 0.37 - ETA: 6s - loss: 6.6885 - dense_3_loss: 1.7300 - dense_3_acc: 0.9757 - dense_3_acc_1: 0.9779 - dense_3_acc_2: 0.7864 - dense_3_acc_3: 0.4451 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9702 - dense_3_acc_6: 0.4579 - dense_3_acc_7: 0.9996 - dense_3_acc_8: 0.5496 - dense_3_acc_9: 0.37 - ETA: 6s - loss: 6.6861 - dense_3_loss: 1.7294 - dense_3_acc: 0.9756 - dense_3_acc_1: 0.9777 - dense_3_acc_2: 0.7869 - dense_3_acc_3: 0.4477 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9694 - dense_3_acc_6: 0.4569 - dense_3_acc_7: 0.9996 - dense_3_acc_8: 0.5496 - dense_3_acc_9: 0.37 - ETA: 6s - loss: 6.6796 - dense_3_loss: 1.7262 - dense_3_acc: 0.9757 - dense_3_acc_1: 0.9778 - dense_3_acc_2: 0.7873 - dense_3_acc_3: 0.4480 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9692 - dense_3_acc_6: 0.4573 - dense_3_acc_7: 0.9996 - dense_3_acc_8: 0.5494 - dense_3_acc_9: 0.37 - ETA: 6s - loss: 6.6711 - dense_3_loss: 1.7242 - dense_3_acc: 0.9758 - dense_3_acc_1: 0.9782 - dense_3_acc_2: 0.7880 - dense_3_acc_3: 0.4504 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9684 - dense_3_acc_6: 0.4568 - dense_3_acc_7: 0.9996 - dense_3_acc_8: 0.5502 - dense_3_acc_9: 0.37 - ETA: 6s - loss: 6.6639 - dense_3_loss: 1.7205 - dense_3_acc: 0.9757 - dense_3_acc_1: 0.9780 - dense_3_acc_2: 0.7892 - dense_3_acc_3: 0.4504 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9684 - dense_3_acc_6: 0.4582 - dense_3_acc_7: 0.9996 - dense_3_acc_8: 0.5496 - dense_3_acc_9: 0.38 - ETA: 5s - loss: 6.6571 - dense_3_loss: 1.7194 - dense_3_acc: 0.9760 - dense_3_acc_1: 0.9783 - dense_3_acc_2: 0.7902 - dense_3_acc_3: 0.4502 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9687 - dense_3_acc_6: 0.4581 - dense_3_acc_7: 0.9996 - dense_3_acc_8: 0.5502 - dense_3_acc_9: 0.38 - ETA: 5s - loss: 6.6524 - dense_3_loss: 1.7189 - dense_3_acc: 0.9760 - dense_3_acc_1: 0.9783 - dense_3_acc_2: 0.7908 - dense_3_acc_3: 0.4517 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9683 - dense_3_acc_6: 0.4579 - dense_3_acc_7: 0.9996 - dense_3_acc_8: 0.5508 - dense_3_acc_9: 0.38 - ETA: 5s - loss: 6.6511 - dense_3_loss: 1.7181 - dense_3_acc: 0.9756 - dense_3_acc_1: 0.9780 - dense_3_acc_2: 0.7915 - dense_3_acc_3: 0.4530 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9678 - dense_3_acc_6: 0.4570 - dense_3_acc_7: 0.9996 - dense_3_acc_8: 0.5530 - dense_3_acc_9: 0.38 - ETA: 5s - loss: 6.6477 - dense_3_loss: 1.7184 - dense_3_acc: 0.9755 - dense_3_acc_1: 0.9780 - dense_3_acc_2: 0.7942 - dense_3_acc_3: 0.4525 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9680 - dense_3_acc_6: 0.4580 - dense_3_acc_7: 0.9996 - dense_3_acc_8: 0.5544 - dense_3_acc_9: 0.38 - ETA: 5s - loss: 6.6440 - dense_3_loss: 1.7168 - dense_3_acc: 0.9754 - dense_3_acc_1: 0.9777 - dense_3_acc_2: 0.7948 - dense_3_acc_3: 0.4518 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9677 - dense_3_acc_6: 0.4589 - dense_3_acc_7: 0.9996 - dense_3_acc_8: 0.5546 - dense_3_acc_9: 0.38 - ETA: 5s - loss: 6.6430 - dense_3_loss: 1.7157 - dense_3_acc: 0.9753 - dense_3_acc_1: 0.9777 - dense_3_acc_2: 0.7937 - dense_3_acc_3: 0.4523 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9674 - dense_3_acc_6: 0.4577 - dense_3_acc_7: 0.9996 - dense_3_acc_8: 0.5549 - dense_3_acc_9: 0.38 - ETA: 5s - loss: 6.6385 - dense_3_loss: 1.7127 - dense_3_acc: 0.9752 - dense_3_acc_1: 0.9778 - dense_3_acc_2: 0.7940 - dense_3_acc_3: 0.4536 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9671 - dense_3_acc_6: 0.4579 - dense_3_acc_7: 0.9997 - dense_3_acc_8: 0.5538 - dense_3_acc_9: 0.3850"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8700/10000 [=========================>....] - ETA: 5s - loss: 6.6369 - dense_3_loss: 1.7129 - dense_3_acc: 0.9749 - dense_3_acc_1: 0.9776 - dense_3_acc_2: 0.7946 - dense_3_acc_3: 0.4546 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9671 - dense_3_acc_6: 0.4569 - dense_3_acc_7: 0.9997 - dense_3_acc_8: 0.5531 - dense_3_acc_9: 0.38 - ETA: 4s - loss: 6.6350 - dense_3_loss: 1.7109 - dense_3_acc: 0.9750 - dense_3_acc_1: 0.9777 - dense_3_acc_2: 0.7942 - dense_3_acc_3: 0.4537 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9670 - dense_3_acc_6: 0.4582 - dense_3_acc_7: 0.9997 - dense_3_acc_8: 0.5522 - dense_3_acc_9: 0.38 - ETA: 4s - loss: 6.6276 - dense_3_loss: 1.7100 - dense_3_acc: 0.9749 - dense_3_acc_1: 0.9774 - dense_3_acc_2: 0.7949 - dense_3_acc_3: 0.4536 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9674 - dense_3_acc_6: 0.4589 - dense_3_acc_7: 0.9997 - dense_3_acc_8: 0.5531 - dense_3_acc_9: 0.38 - ETA: 4s - loss: 6.6282 - dense_3_loss: 1.7106 - dense_3_acc: 0.9745 - dense_3_acc_1: 0.9769 - dense_3_acc_2: 0.7948 - dense_3_acc_3: 0.4547 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9677 - dense_3_acc_6: 0.4595 - dense_3_acc_7: 0.9997 - dense_3_acc_8: 0.5542 - dense_3_acc_9: 0.38 - ETA: 4s - loss: 6.6187 - dense_3_loss: 1.7085 - dense_3_acc: 0.9748 - dense_3_acc_1: 0.9773 - dense_3_acc_2: 0.7951 - dense_3_acc_3: 0.4552 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9679 - dense_3_acc_6: 0.4592 - dense_3_acc_7: 0.9997 - dense_3_acc_8: 0.5557 - dense_3_acc_9: 0.38 - ETA: 4s - loss: 6.6107 - dense_3_loss: 1.7055 - dense_3_acc: 0.9748 - dense_3_acc_1: 0.9775 - dense_3_acc_2: 0.7948 - dense_3_acc_3: 0.4555 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9678 - dense_3_acc_6: 0.4602 - dense_3_acc_7: 0.9997 - dense_3_acc_8: 0.5558 - dense_3_acc_9: 0.38 - ETA: 4s - loss: 6.6059 - dense_3_loss: 1.7041 - dense_3_acc: 0.9742 - dense_3_acc_1: 0.9772 - dense_3_acc_2: 0.7952 - dense_3_acc_3: 0.4555 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9677 - dense_3_acc_6: 0.4606 - dense_3_acc_7: 0.9997 - dense_3_acc_8: 0.5555 - dense_3_acc_9: 0.38 - ETA: 4s - loss: 6.5988 - dense_3_loss: 1.7035 - dense_3_acc: 0.9742 - dense_3_acc_1: 0.9776 - dense_3_acc_2: 0.7965 - dense_3_acc_3: 0.4562 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9680 - dense_3_acc_6: 0.4614 - dense_3_acc_7: 0.9997 - dense_3_acc_8: 0.5562 - dense_3_acc_9: 0.38 - ETA: 4s - loss: 6.5919 - dense_3_loss: 1.7017 - dense_3_acc: 0.9745 - dense_3_acc_1: 0.9778 - dense_3_acc_2: 0.7969 - dense_3_acc_3: 0.4564 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9681 - dense_3_acc_6: 0.4609 - dense_3_acc_7: 0.9997 - dense_3_acc_8: 0.5575 - dense_3_acc_9: 0.38 - ETA: 3s - loss: 6.5837 - dense_3_loss: 1.6982 - dense_3_acc: 0.9744 - dense_3_acc_1: 0.9778 - dense_3_acc_2: 0.7971 - dense_3_acc_3: 0.4569 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9685 - dense_3_acc_6: 0.4607 - dense_3_acc_7: 0.9997 - dense_3_acc_8: 0.5588 - dense_3_acc_9: 0.39 - ETA: 3s - loss: 6.5767 - dense_3_loss: 1.6961 - dense_3_acc: 0.9745 - dense_3_acc_1: 0.9777 - dense_3_acc_2: 0.7968 - dense_3_acc_3: 0.4580 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9688 - dense_3_acc_6: 0.4613 - dense_3_acc_7: 0.9997 - dense_3_acc_8: 0.5593 - dense_3_acc_9: 0.39 - ETA: 3s - loss: 6.5707 - dense_3_loss: 1.6960 - dense_3_acc: 0.9744 - dense_3_acc_1: 0.9776 - dense_3_acc_2: 0.7969 - dense_3_acc_3: 0.4599 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9690 - dense_3_acc_6: 0.4621 - dense_3_acc_7: 0.9997 - dense_3_acc_8: 0.5596 - dense_3_acc_9: 0.39 - ETA: 3s - loss: 6.5674 - dense_3_loss: 1.6954 - dense_3_acc: 0.9746 - dense_3_acc_1: 0.9777 - dense_3_acc_2: 0.7975 - dense_3_acc_3: 0.4594 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9686 - dense_3_acc_6: 0.4627 - dense_3_acc_7: 0.9997 - dense_3_acc_8: 0.5597 - dense_3_acc_9: 0.39 - ETA: 3s - loss: 6.5671 - dense_3_loss: 1.6942 - dense_3_acc: 0.9742 - dense_3_acc_1: 0.9771 - dense_3_acc_2: 0.7967 - dense_3_acc_3: 0.4594 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9686 - dense_3_acc_6: 0.4632 - dense_3_acc_7: 0.9997 - dense_3_acc_8: 0.5600 - dense_3_acc_9: 0.39 - ETA: 3s - loss: 6.5627 - dense_3_loss: 1.6931 - dense_3_acc: 0.9744 - dense_3_acc_1: 0.9773 - dense_3_acc_2: 0.7974 - dense_3_acc_3: 0.4603 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9686 - dense_3_acc_6: 0.4638 - dense_3_acc_7: 0.9997 - dense_3_acc_8: 0.5601 - dense_3_acc_9: 0.39 - ETA: 3s - loss: 6.5633 - dense_3_loss: 1.6944 - dense_3_acc: 0.9742 - dense_3_acc_1: 0.9770 - dense_3_acc_2: 0.7982 - dense_3_acc_3: 0.4611 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9688 - dense_3_acc_6: 0.4646 - dense_3_acc_7: 0.9997 - dense_3_acc_8: 0.5597 - dense_3_acc_9: 0.39 - ETA: 3s - loss: 6.5583 - dense_3_loss: 1.6914 - dense_3_acc: 0.9743 - dense_3_acc_1: 0.9771 - dense_3_acc_2: 0.7987 - dense_3_acc_3: 0.4631 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9688 - dense_3_acc_6: 0.4656 - dense_3_acc_7: 0.9997 - dense_3_acc_8: 0.5595 - dense_3_acc_9: 0.39 - ETA: 2s - loss: 6.5511 - dense_3_loss: 1.6899 - dense_3_acc: 0.9745 - dense_3_acc_1: 0.9772 - dense_3_acc_2: 0.7993 - dense_3_acc_3: 0.4636 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9688 - dense_3_acc_6: 0.4659 - dense_3_acc_7: 0.9997 - dense_3_acc_8: 0.5601 - dense_3_acc_9: 0.39 - ETA: 2s - loss: 6.5484 - dense_3_loss: 1.6879 - dense_3_acc: 0.9744 - dense_3_acc_1: 0.9771 - dense_3_acc_2: 0.8004 - dense_3_acc_3: 0.4619 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9688 - dense_3_acc_6: 0.4661 - dense_3_acc_7: 0.9997 - dense_3_acc_8: 0.5603 - dense_3_acc_9: 0.39 - ETA: 2s - loss: 6.5448 - dense_3_loss: 1.6863 - dense_3_acc: 0.9741 - dense_3_acc_1: 0.9771 - dense_3_acc_2: 0.8005 - dense_3_acc_3: 0.4627 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9688 - dense_3_acc_6: 0.4668 - dense_3_acc_7: 0.9997 - dense_3_acc_8: 0.5599 - dense_3_acc_9: 0.39 - ETA: 2s - loss: 6.5446 - dense_3_loss: 1.6873 - dense_3_acc: 0.9742 - dense_3_acc_1: 0.9770 - dense_3_acc_2: 0.8000 - dense_3_acc_3: 0.4634 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9687 - dense_3_acc_6: 0.4671 - dense_3_acc_7: 0.9997 - dense_3_acc_8: 0.5604 - dense_3_acc_9: 0.39 - ETA: 2s - loss: 6.5375 - dense_3_loss: 1.6852 - dense_3_acc: 0.9743 - dense_3_acc_1: 0.9771 - dense_3_acc_2: 0.8001 - dense_3_acc_3: 0.4647 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9690 - dense_3_acc_6: 0.4669 - dense_3_acc_7: 0.9998 - dense_3_acc_8: 0.5602 - dense_3_acc_9: 0.39 - ETA: 2s - loss: 6.5323 - dense_3_loss: 1.6825 - dense_3_acc: 0.9742 - dense_3_acc_1: 0.9770 - dense_3_acc_2: 0.8002 - dense_3_acc_3: 0.4662 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9691 - dense_3_acc_6: 0.4667 - dense_3_acc_7: 0.9998 - dense_3_acc_8: 0.5599 - dense_3_acc_9: 0.39 - ETA: 2s - loss: 6.5261 - dense_3_loss: 1.6804 - dense_3_acc: 0.9739 - dense_3_acc_1: 0.9770 - dense_3_acc_2: 0.8007 - dense_3_acc_3: 0.4672 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9690 - dense_3_acc_6: 0.4665 - dense_3_acc_7: 0.9998 - dense_3_acc_8: 0.5606 - dense_3_acc_9: 0.39 - ETA: 2s - loss: 6.5227 - dense_3_loss: 1.6801 - dense_3_acc: 0.9740 - dense_3_acc_1: 0.9770 - dense_3_acc_2: 0.7999 - dense_3_acc_3: 0.4687 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9693 - dense_3_acc_6: 0.4680 - dense_3_acc_7: 0.9998 - dense_3_acc_8: 0.5604 - dense_3_acc_9: 0.39 - ETA: 1s - loss: 6.5173 - dense_3_loss: 1.6778 - dense_3_acc: 0.9743 - dense_3_acc_1: 0.9773 - dense_3_acc_2: 0.8005 - dense_3_acc_3: 0.4680 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9690 - dense_3_acc_6: 0.4670 - dense_3_acc_7: 0.9998 - dense_3_acc_8: 0.5614 - dense_3_acc_9: 0.39 - ETA: 1s - loss: 6.5135 - dense_3_loss: 1.6765 - dense_3_acc: 0.9742 - dense_3_acc_1: 0.9773 - dense_3_acc_2: 0.8007 - dense_3_acc_3: 0.4684 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9688 - dense_3_acc_6: 0.4669 - dense_3_acc_7: 0.9998 - dense_3_acc_8: 0.5620 - dense_3_acc_9: 0.40 - ETA: 1s - loss: 6.5076 - dense_3_loss: 1.6738 - dense_3_acc: 0.9743 - dense_3_acc_1: 0.9772 - dense_3_acc_2: 0.8014 - dense_3_acc_3: 0.4676 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9688 - dense_3_acc_6: 0.4678 - dense_3_acc_7: 0.9998 - dense_3_acc_8: 0.5624 - dense_3_acc_9: 0.40 - ETA: 1s - loss: 6.5043 - dense_3_loss: 1.6731 - dense_3_acc: 0.9744 - dense_3_acc_1: 0.9772 - dense_3_acc_2: 0.8008 - dense_3_acc_3: 0.4682 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9690 - dense_3_acc_6: 0.4690 - dense_3_acc_7: 0.9998 - dense_3_acc_8: 0.5633 - dense_3_acc_9: 0.4011"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - ETA: 1s - loss: 6.5025 - dense_3_loss: 1.6733 - dense_3_acc: 0.9740 - dense_3_acc_1: 0.9770 - dense_3_acc_2: 0.8014 - dense_3_acc_3: 0.4687 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9690 - dense_3_acc_6: 0.4692 - dense_3_acc_7: 0.9998 - dense_3_acc_8: 0.5642 - dense_3_acc_9: 0.40 - ETA: 1s - loss: 6.4984 - dense_3_loss: 1.6725 - dense_3_acc: 0.9742 - dense_3_acc_1: 0.9772 - dense_3_acc_2: 0.8016 - dense_3_acc_3: 0.4698 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9691 - dense_3_acc_6: 0.4696 - dense_3_acc_7: 0.9998 - dense_3_acc_8: 0.5637 - dense_3_acc_9: 0.40 - ETA: 1s - loss: 6.4950 - dense_3_loss: 1.6714 - dense_3_acc: 0.9742 - dense_3_acc_1: 0.9772 - dense_3_acc_2: 0.8013 - dense_3_acc_3: 0.4710 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9693 - dense_3_acc_6: 0.4701 - dense_3_acc_7: 0.9998 - dense_3_acc_8: 0.5649 - dense_3_acc_9: 0.40 - ETA: 1s - loss: 6.4896 - dense_3_loss: 1.6699 - dense_3_acc: 0.9742 - dense_3_acc_1: 0.9773 - dense_3_acc_2: 0.8020 - dense_3_acc_3: 0.4718 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9696 - dense_3_acc_6: 0.4703 - dense_3_acc_7: 0.9998 - dense_3_acc_8: 0.5648 - dense_3_acc_9: 0.40 - ETA: 0s - loss: 6.4859 - dense_3_loss: 1.6687 - dense_3_acc: 0.9741 - dense_3_acc_1: 0.9773 - dense_3_acc_2: 0.8016 - dense_3_acc_3: 0.4721 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9696 - dense_3_acc_6: 0.4722 - dense_3_acc_7: 0.9998 - dense_3_acc_8: 0.5646 - dense_3_acc_9: 0.40 - ETA: 0s - loss: 6.4785 - dense_3_loss: 1.6669 - dense_3_acc: 0.9744 - dense_3_acc_1: 0.9775 - dense_3_acc_2: 0.8027 - dense_3_acc_3: 0.4729 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9699 - dense_3_acc_6: 0.4719 - dense_3_acc_7: 0.9998 - dense_3_acc_8: 0.5653 - dense_3_acc_9: 0.40 - ETA: 0s - loss: 6.4752 - dense_3_loss: 1.6657 - dense_3_acc: 0.9741 - dense_3_acc_1: 0.9772 - dense_3_acc_2: 0.8032 - dense_3_acc_3: 0.4733 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9701 - dense_3_acc_6: 0.4722 - dense_3_acc_7: 0.9998 - dense_3_acc_8: 0.5651 - dense_3_acc_9: 0.40 - ETA: 0s - loss: 6.4685 - dense_3_loss: 1.6630 - dense_3_acc: 0.9741 - dense_3_acc_1: 0.9773 - dense_3_acc_2: 0.8036 - dense_3_acc_3: 0.4737 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9703 - dense_3_acc_6: 0.4732 - dense_3_acc_7: 0.9998 - dense_3_acc_8: 0.5661 - dense_3_acc_9: 0.40 - ETA: 0s - loss: 6.4628 - dense_3_loss: 1.6600 - dense_3_acc: 0.9743 - dense_3_acc_1: 0.9774 - dense_3_acc_2: 0.8037 - dense_3_acc_3: 0.4731 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9703 - dense_3_acc_6: 0.4739 - dense_3_acc_7: 0.9998 - dense_3_acc_8: 0.5667 - dense_3_acc_9: 0.40 - ETA: 0s - loss: 6.4589 - dense_3_loss: 1.6588 - dense_3_acc: 0.9744 - dense_3_acc_1: 0.9774 - dense_3_acc_2: 0.8041 - dense_3_acc_3: 0.4730 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9702 - dense_3_acc_6: 0.4738 - dense_3_acc_7: 0.9998 - dense_3_acc_8: 0.5666 - dense_3_acc_9: 0.40 - ETA: 0s - loss: 6.4520 - dense_3_loss: 1.6572 - dense_3_acc: 0.9744 - dense_3_acc_1: 0.9773 - dense_3_acc_2: 0.8046 - dense_3_acc_3: 0.4734 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9704 - dense_3_acc_6: 0.4746 - dense_3_acc_7: 0.9998 - dense_3_acc_8: 0.5670 - dense_3_acc_9: 0.40 - ETA: 0s - loss: 6.4489 - dense_3_loss: 1.6560 - dense_3_acc: 0.9742 - dense_3_acc_1: 0.9772 - dense_3_acc_2: 0.8045 - dense_3_acc_3: 0.4735 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9704 - dense_3_acc_6: 0.4751 - dense_3_acc_7: 0.9998 - dense_3_acc_8: 0.5667 - dense_3_acc_9: 0.40 - 12s 1ms/step - loss: 6.4463 - dense_3_loss: 1.6547 - dense_3_acc: 0.9744 - dense_3_acc_1: 0.9773 - dense_3_acc_2: 0.8044 - dense_3_acc_3: 0.4732 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9704 - dense_3_acc_6: 0.4750 - dense_3_acc_7: 0.9998 - dense_3_acc_8: 0.5679 - dense_3_acc_9: 0.4096\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c6ec8bbcc0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([Xoh, s0, c0], outputs, epochs=5, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While training you can see the loss as well as the accuracy on each of the 10 positions of the output. The table below gives you an example of what the accuracies could be if the batch had 2 examples: \n",
    "\n",
    "<img src=\"images/table.png\" style=\"width:700;height:200px;\"> <br>\n",
    "<caption><center>Thus, `dense_2_acc_8: 0.89` means that you are predicting the 7th character of the output correctly 89% of the time in the current batch of data. </center></caption>\n",
    "\n",
    "\n",
    "We have run this model for longer, and saved the weights. Run the next cell to load our weights. (By training a model for several minutes, you should be able to obtain a model of similar accuracy, but loading our model will save you time.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('models/model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now see the results on new examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source: 3 May 1979\n",
      "output: 1979-05-03\n",
      "source: 5 April 09\n",
      "output: 2009-05-05\n",
      "source: 21th of August 2016\n",
      "output: 2016-08-21\n",
      "source: Tue 10 Jul 2007\n",
      "output: 2007-07-10\n",
      "source: Saturday May 9 2018\n",
      "output: 2018-05-09\n",
      "source: March 3 2001\n",
      "output: 2001-03-03\n",
      "source: March 3rd 2001\n",
      "output: 2001-03-03\n",
      "source: 1 March 2001\n",
      "output: 2001-03-01\n"
     ]
    }
   ],
   "source": [
    "EXAMPLES = ['3 May 1979', '5 April 09', '21th of August 2016', 'Tue 10 Jul 2007', 'Saturday May 9 2018', 'March 3 2001', 'March 3rd 2001', '1 March 2001']\n",
    "for example in EXAMPLES:\n",
    "    \n",
    "    source = string_to_int(example, Tx, human_vocab)\n",
    "    #source = np.array(list(map(lambda x: to_categorical(x, num_classes=len(human_vocab)), source))).swapaxes(0,1)\n",
    "    source = np.array(list(map(lambda x: to_categorical(x, num_classes=len(human_vocab)), source)))\n",
    "    source  = source.reshape((1, source.shape[0], source.shape[1]))\n",
    "    prediction = model.predict([source, s0, c0])\n",
    "    prediction = np.argmax(prediction, axis = -1)\n",
    "    output = [inv_machine_vocab[int(i)] for i in prediction]\n",
    "    \n",
    "    print(\"source:\", example)\n",
    "    print(\"output:\", ''.join(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also change these examples to test with your own examples. The next part will give you a better sense on what the attention mechanism is doing--i.e., what part of the input the network is paying attention to when generating a particular output character. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Visualizing Attention (Optional / Ungraded)\n",
    "\n",
    "Since the problem has a fixed output length of 10, it is also possible to carry out this task using 10 different softmax units to generate the 10 characters of the output. But one advantage of the attention model is that each part of the output (say the month) knows it needs to depend only on a small part of the input (the characters in the input giving the month). We can  visualize what part of the output is looking at what part of the input.\n",
    "\n",
    "Consider the task of translating \"Saturday 9 May 2018\" to \"2018-05-09\". If we visualize the computed $\\alpha^{\\langle t, t' \\rangle}$ we get this: \n",
    "\n",
    "<img src=\"images/date_attention.png\" style=\"width:600;height:300px;\"> <br>\n",
    "<caption><center> **Figure 8**: Full Attention Map</center></caption>\n",
    "\n",
    "Notice how the output ignores the \"Saturday\" portion of the input. None of the output timesteps are paying much attention to that portion of the input. We see also that 9 has been translated as 09 and May has been correctly translated into 05, with the output paying attention to the parts of the input it needs to to make the translation. The year mostly requires it to pay attention to the input's \"18\" in order to generate \"2018.\" \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 - Getting the activations from the network\n",
    "\n",
    "Lets now visualize the attention values in your network. We'll propagate an example through the network, then visualize the values of $\\alpha^{\\langle t, t' \\rangle}$. \n",
    "\n",
    "To figure out where the attention values are located, let's start by printing a summary of the model ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 30, 37)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "s0 (InputLayer)                 (None, 64)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 30, 64)       17920       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_1 (RepeatVector)  (None, 30, 64)       0           s0[0][0]                         \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 lstm_1[1][0]                     \n",
      "                                                                 lstm_1[2][0]                     \n",
      "                                                                 lstm_1[3][0]                     \n",
      "                                                                 lstm_1[4][0]                     \n",
      "                                                                 lstm_1[5][0]                     \n",
      "                                                                 lstm_1[6][0]                     \n",
      "                                                                 lstm_1[7][0]                     \n",
      "                                                                 lstm_1[8][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 30, 128)      0           bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[0][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[1][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[2][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[3][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[4][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[5][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[6][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[7][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[8][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[9][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 30, 10)       1290        concatenate_1[0][0]              \n",
      "                                                                 concatenate_1[1][0]              \n",
      "                                                                 concatenate_1[2][0]              \n",
      "                                                                 concatenate_1[3][0]              \n",
      "                                                                 concatenate_1[4][0]              \n",
      "                                                                 concatenate_1[5][0]              \n",
      "                                                                 concatenate_1[6][0]              \n",
      "                                                                 concatenate_1[7][0]              \n",
      "                                                                 concatenate_1[8][0]              \n",
      "                                                                 concatenate_1[9][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 30, 1)        11          dense_1[0][0]                    \n",
      "                                                                 dense_1[1][0]                    \n",
      "                                                                 dense_1[2][0]                    \n",
      "                                                                 dense_1[3][0]                    \n",
      "                                                                 dense_1[4][0]                    \n",
      "                                                                 dense_1[5][0]                    \n",
      "                                                                 dense_1[6][0]                    \n",
      "                                                                 dense_1[7][0]                    \n",
      "                                                                 dense_1[8][0]                    \n",
      "                                                                 dense_1[9][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_weights (Activation)  (None, 30, 1)        0           dense_2[0][0]                    \n",
      "                                                                 dense_2[1][0]                    \n",
      "                                                                 dense_2[2][0]                    \n",
      "                                                                 dense_2[3][0]                    \n",
      "                                                                 dense_2[4][0]                    \n",
      "                                                                 dense_2[5][0]                    \n",
      "                                                                 dense_2[6][0]                    \n",
      "                                                                 dense_2[7][0]                    \n",
      "                                                                 dense_2[8][0]                    \n",
      "                                                                 dense_2[9][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 1, 64)        0           attention_weights[0][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[1][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[2][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[3][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 attention_weights[4][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[5][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[6][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[7][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[8][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[9][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "c0 (InputLayer)                 (None, 64)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 64), (None,  33024       dot_1[0][0]                      \n",
      "                                                                 s0[0][0]                         \n",
      "                                                                 c0[0][0]                         \n",
      "                                                                 dot_1[1][0]                      \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "                                                                 dot_1[2][0]                      \n",
      "                                                                 lstm_1[1][0]                     \n",
      "                                                                 lstm_1[1][2]                     \n",
      "                                                                 dot_1[3][0]                      \n",
      "                                                                 lstm_1[2][0]                     \n",
      "                                                                 lstm_1[2][2]                     \n",
      "                                                                 dot_1[4][0]                      \n",
      "                                                                 lstm_1[3][0]                     \n",
      "                                                                 lstm_1[3][2]                     \n",
      "                                                                 dot_1[5][0]                      \n",
      "                                                                 lstm_1[4][0]                     \n",
      "                                                                 lstm_1[4][2]                     \n",
      "                                                                 dot_1[6][0]                      \n",
      "                                                                 lstm_1[5][0]                     \n",
      "                                                                 lstm_1[5][2]                     \n",
      "                                                                 dot_1[7][0]                      \n",
      "                                                                 lstm_1[6][0]                     \n",
      "                                                                 lstm_1[6][2]                     \n",
      "                                                                 dot_1[8][0]                      \n",
      "                                                                 lstm_1[7][0]                     \n",
      "                                                                 lstm_1[7][2]                     \n",
      "                                                                 dot_1[9][0]                      \n",
      "                                                                 lstm_1[8][0]                     \n",
      "                                                                 lstm_1[8][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 11)           715         lstm_1[0][0]                     \n",
      "                                                                 lstm_1[1][0]                     \n",
      "                                                                 lstm_1[2][0]                     \n",
      "                                                                 lstm_1[3][0]                     \n",
      "                                                                 lstm_1[4][0]                     \n",
      "                                                                 lstm_1[5][0]                     \n",
      "                                                                 lstm_1[6][0]                     \n",
      "                                                                 lstm_1[7][0]                     \n",
      "                                                                 lstm_1[8][0]                     \n",
      "                                                                 lstm_1[9][0]                     \n",
      "==================================================================================================\n",
      "Total params: 52,960\n",
      "Trainable params: 52,960\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Navigate through the output of `model.summary()` above. You can see that the layer named `attention_weights` outputs the `alphas` of shape (m, 30, 1) before `dot_2` computes the context vector for every time step $t = 0, \\ldots, T_y-1$. Lets get the activations from this layer.\n",
    "\n",
    "The function `attention_map()` pulls out the attention values from your model and plots them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x612 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "attention_map = plot_attention_map(model, human_vocab, inv_machine_vocab, \"Tuesday 09 Oct 1993\", num = 7, n_s = 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the generated plot you can observe the values of the attention weights for each character of the predicted output. Examine this plot and check that where the network is paying attention makes sense to you.\n",
    "\n",
    "In the date translation application, you will observe that most of the time attention helps predict the year, and hasn't much impact on predicting the day/month."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congratulations!\n",
    "\n",
    "\n",
    "You have come to the end of this assignment \n",
    "\n",
    "<font color='blue'> **Here's what you should remember from this notebook**:\n",
    "\n",
    "- Machine translation models can be used to map from one sequence to another. They are useful not just for translating human languages (like French->English) but also for tasks like date format translation. \n",
    "- An attention mechanism allows a network to focus on the most relevant parts of the input when producing a specific part of the output. \n",
    "- A network using an attention mechanism can translate from inputs of length $T_x$ to outputs of length $T_y$, where $T_x$ and $T_y$ can be different. \n",
    "- You can visualize attention weights $\\alpha^{\\langle t,t' \\rangle}$ to see what the network is paying attention to while generating each output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations on finishing this assignment! You are now able to implement an attention model and use it to learn complex mappings from one sequence to another. "
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "nlp-sequence-models",
   "graded_item_id": "n16CQ",
   "launcher_item_id": "npjGi"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
